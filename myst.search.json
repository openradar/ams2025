{"version":"1","records":[{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses"},"type":"lvl1","url":"/#ams-2025-open-radar-science-short-courses","position":2},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses"},"content":"\n\n\n\n\n\n\n\nThis tutorial covers how to get started with the Open Radar Science stack!","type":"content","url":"/#ams-2025-open-radar-science-short-courses","position":3},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":4},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl2":"Motivation"},"content":"The course will take place on 24 August 2025, the day before the \n\n41st AMS International Radar Meeting (ams2025).\nThe course will discuss the principles of open science and provide an overview of the most mature and exciting software packages available for radar data processing\n(ex.\n\n\nLROSE,\n\n\nPy-ART,\n\n\npyrad,\n\n\nBALTRAD,\n\n\nwradlib\n) and how they connect with the scientific software stack.\n\nThe course will be built with Jupyter Notebooks as hands-on approach for interactive user experience. The main course programming language is Python, but also Command Line Tools are used.\n\nThe course will also highlight the\n\n\nxradar\npackage, implementing the newly adopted FM301/CfRadial2 WMO standard, as well as the\n\n\ngpm-api software, which facilitates the\ndownload and analysis of TRMM PR and GPM DPR spaceborne radars data. These two tools will be used to showcase how to harness the power of\n\n\nxarray and \n\ndask\nfor efficient, distributed radar data processing.\n\nThe course will cover operational use (e.g. in HPC environments or Cloud Infrastructure) as well as algorithm development, enabling the participants to implement their own algorithms.\n\nThe course will also show how to create workflows for different aspects of weather radar\ndata processing, using open datasets relevant to the attendees and ams2025.","type":"content","url":"/#motivation","position":5},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl2":"List of Instructors"},"type":"lvl2","url":"/#list-of-instructors","position":6},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl2":"List of Instructors"},"content":"Alfonso Ladino, University of Illinois at Urbana-Champaign (UIUC)\n\nAnna del Moral Méndez, National Center for Atmospheric Research (NCAR)\n\nBrenda Javornik, National Center for Atmospheric Research (NCAR)\n\nDaniel Michelson, Environment and Climate Change Canada (ECCC)\n\nDaniel Wolfensberger, MeteoSwiss (MCH)\n\nGionata Ghiggi, Ecole Polytechnique Fédérale de Lausanne (EPFL)\n\nJen DeHart, Colorado State University (CSU)\n\nJordi Figueras i Ventura, independent radar scientist\n\nJulian Giles, University of Bonn\n\nKai Mühlbauer, University of Bonn\n\nMaxwell Grover, Argonne National Laboratory\n\nMike Dixon, National Center for Atmospheric Research (NCAR)\n\nRobert Jackson, Argonne National Laboratory\n\nScott Collis, Argonne National Laboratory\n\nTing-Yu Cha, National Center for Atmospheric Research (NCAR)","type":"content","url":"/#list-of-instructors","position":7},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl3":"Contributors","lvl2":"List of Instructors"},"type":"lvl3","url":"/#contributors","position":8},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl3":"Contributors","lvl2":"List of Instructors"},"content":"","type":"content","url":"/#contributors","position":9},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl2":"Course program"},"type":"lvl2","url":"/#course-program","position":10},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl2":"Course program"},"content":"Please see the \n\nschedule","type":"content","url":"/#course-program","position":11},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":12},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl2":"Structure"},"content":"","type":"content","url":"/#structure","position":13},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl3":"Tool Foundations","lvl2":"Structure"},"type":"lvl3","url":"/#tool-foundations","position":14},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl3":"Tool Foundations","lvl2":"Structure"},"content":"Content relevant to each of the Open Radar packages (ex. Py-ART, wradlib, LROSE, BALTRAD).","type":"content","url":"/#tool-foundations","position":15},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl3":"Example Workflows","lvl2":"Structure"},"type":"lvl3","url":"/#example-workflows","position":16},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl3":"Example Workflows","lvl2":"Structure"},"content":"Workflows utilizing the various packages and open radar data.","type":"content","url":"/#example-workflows","position":17},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl2":"Things You Need to Prepare"},"type":"lvl2","url":"/#things-you-need-to-prepare","position":18},{"hierarchy":{"lvl1":"AMS 2025 Open Radar Science Short Courses","lvl2":"Things You Need to Prepare"},"content":"Participants need to bring their own 64-bit notebook (Linux, Windows, Mac).  The exercises will take place on a cloud server. On Windows, the use of a ssh-client such as \n\nPutty or \n\nMobaXterm will be necessary.","type":"content","url":"/#things-you-need-to-prepare","position":19},{"hierarchy":{"lvl1":"Notebook Execution"},"type":"lvl1","url":"/getting-started","position":0},{"hierarchy":{"lvl1":"Notebook Execution"},"content":"There are two options to work with this course, via Project Pythia Hub and locally on your machine.","type":"content","url":"/getting-started","position":1},{"hierarchy":{"lvl1":"Notebook Execution","lvl2":"Project Pythia Hub"},"type":"lvl2","url":"/getting-started#project-pythia-hub","position":2},{"hierarchy":{"lvl1":"Notebook Execution","lvl2":"Project Pythia Hub"},"content":"Just use the enable computing button within a notebook on this site to run each cell individually, rendering the output immediately to html.\nA second option, and the preferred one for this course is to fire up a jupyterlab instance on the Project Pythia Hub via the \n\nLaunch Environment-Button\non the top right navigation bar. You’ll find yourself in the well known jupyterlab environment, ready to do some science.","type":"content","url":"/getting-started#project-pythia-hub","position":3},{"hierarchy":{"lvl1":"Notebook Execution","lvl2":"Locally on your own premises"},"type":"lvl2","url":"/getting-started#locally-on-your-own-premises","position":4},{"hierarchy":{"lvl1":"Notebook Execution","lvl2":"Locally on your own premises"},"content":"The easiest is to make use of our pre-built docker image which includes all the needed bits and pieces and is actually also\nused as base image for the Project Pythia Hub instance.\n\nThe only thing you need is a running docker service on your local machine.\n\nThen it’s just a one-liner:$ docker run -ti --name ams2025 -p 8888:8888 -e LOCAL_USER_ID=$UID ghcr.io/openradar/ams2025:latest /srv/conda/envs/notebook/bin/jupyter lab --ip='*' --port=8888\n\nSome of the notebooks are utilizing quite some large cloud data files. So a decent network connection (LAN connection) is preferred to make use of those notebooks.\nDon’t try this at the course as bandwidth will be limited.\n\nIf you need a connection to the outside world, you can mount local folders and environment variables into the running container. Please check out the \n\ndocker documentation for more details$ docker run -ti --name ams2025 -p 8888:8888 -v /host/path/to/your/folder:/home/your/folder -e LOCAL_USER_ID=$UID -e YOUR_ENV_VAR=your_env_var ghcr.io/openradar/ams2025:latest /srv/conda/envs/notebook/bin/jupyter lab --ip='*' --port=8888\n","type":"content","url":"/getting-started#locally-on-your-own-premises","position":5},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets"},"type":"lvl1","url":"/arco-datasets","position":0},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets"},"content":"\n\n","type":"content","url":"/arco-datasets","position":1},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets"},"type":"lvl1","url":"/arco-datasets#analysis-ready-cloud-optimized-datasets","position":2},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets"},"content":"\n\n\n\n","type":"content","url":"/arco-datasets#analysis-ready-cloud-optimized-datasets","position":3},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Overview"},"type":"lvl2","url":"/arco-datasets#overview","position":4},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Overview"},"content":"In this notebook, we will work on understanding the main concepts of creating ARCO datasets for the Geosciences.\n\nAnalysis-Ready datasets\n\nCloud-Optimized datasets\n\nFair principles\n\nZarr format\n\n","type":"content","url":"/arco-datasets#overview","position":5},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Prerequisites"},"type":"lvl2","url":"/arco-datasets#prerequisites","position":6},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Xarray\n\nNecessary\n\nBasic features\n\nRadar Cookbook\n\nNecessary\n\nRadar basics\n\nIntro to Zarr\n\nNecessary\n\nZarr basics\n\nTime to learn: 30 minutes\n\n\n\n","type":"content","url":"/arco-datasets#prerequisites","position":7},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Imports"},"type":"lvl2","url":"/arco-datasets#imports","position":8},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Imports"},"content":"\n\nimport xarray as xr\nimport fsspec\nfrom glob import glob\nimport xradar as xd\nimport matplotlib.pyplot as plt\nimport cmweather\nimport numpy as np\nimport hvplot.xarray\nfrom xarray.core.datatree import DataTree\nfrom zarr.errors import ContainsGroupError  \n\n","type":"content","url":"/arco-datasets#imports","position":9},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Analys-Ready"},"type":"lvl2","url":"/arco-datasets#analys-ready","position":10},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Analys-Ready"},"content":"\n\nAnalysis-Ready data is a concept that emphasizes the preparation and structuring of datasets to be immediately usable for analysis. In the CrowdFlower Data Science Report 2016, the “How Data Scientists Spend Their Time” figure illustrates the distribution of time that data scientists allocate to various tasks. The figure highlights that the majority of a data scientist’s time is dedicated to preparing and cleaning data (~80%), which is often considered the most time-consuming and critical part of the data science workflow.\n\n\n\nHere’s how AR caters to various aspects:\n\nDatasets instead of data files\n\nPre-processed datasets, ensuring it is clean and well-organized\n\nDataset enriched with comprehensive metadata\n\nCurated and cataloged\n\nFacilitates a more efficient and accurate analysis\n\nMore time for fun (science)\n\n","type":"content","url":"/arco-datasets#analys-ready","position":11},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Cloud-Optimized"},"type":"lvl2","url":"/arco-datasets#cloud-optimized","position":12},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Cloud-Optimized"},"content":"NetCDF/Raw radar data formats are not cloud optimized. Other formats, like Zarr, aim to make accessing and reading data from the cloud fast and painless. Cloud-Optimized data is structured for efficient storage, access, and processing in cloud environments.\n\nCloud-Optimized leverages scalable formats and parallel processing capabilities\n\n","type":"content","url":"/arco-datasets#cloud-optimized","position":13},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"FAIR data"},"type":"lvl2","url":"/arco-datasets#fair-data","position":14},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"FAIR data"},"content":"FAIR data adheres to principles that ensure it is Findable, Accessible, Interoperable, and Reusable. These guidelines promote data sharing, collaboration, and long-term usability across various platforms and disciplines.\n\n ![fair](../images/fair-data-principles.jpg) \n\n\n\n“FAIR sharing of data is beneficial for both data producers and consumers. Consumers gain access to interesting datasets that would otherwise be out of reach. Producers get citations to their work, when consumers publish their derivative work. OME-Zarr is the technology basis for enabling effective FAIR sharing of large image datasets.” \n\nZarr illustrations\n\n\n\nCourtesy: \n\nZarr illustrations\n\n","type":"content","url":"/arco-datasets#fair-data","position":15},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Zarr format"},"type":"lvl2","url":"/arco-datasets#zarr-format","position":16},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Zarr format"},"content":"\n\nZarr is a flexible and efficient format for storing large, chunked, compressed, multi-dimensional arrays, enabling easy and scalable data access in both local and cloud environments. It supports parallel processing and is widely used in scientific computing for handling large datasets.\n\n\n\nCourtesy: \n\nZarr illustrations\n\n","type":"content","url":"/arco-datasets#zarr-format","position":17},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"ARCO Radar data"},"type":"lvl2","url":"/arco-datasets#arco-radar-data","position":18},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"ARCO Radar data"},"content":"\n\nLeveraging the Climate and Forecast (CF) format-based FM301 hierarchical tree structure, endorsed by the World Meteorological Organization (WMO), and Analysis-Ready Cloud-Optimized (ARCO) formats, we developed an open data model to arrange, manage, and store radar data in cloud-storage buckets efficiently\n\n","type":"content","url":"/arco-datasets#arco-radar-data","position":19},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl3":"CfRadial2.1/FM301 standard","lvl2":"ARCO Radar data"},"type":"lvl3","url":"/arco-datasets#cfradial2-1-fm301-standard","position":20},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl3":"CfRadial2.1/FM301 standard","lvl2":"ARCO Radar data"},"content":"\n\nXradar employs xarray.DataTree objects to organize radar sweeps within a single hierachical structure, where each sweep is an xarray.Dataset containing relevant metadata and variables.\n\n\n\nLet’s see how this hierarchical-datatree looks like\n\n# Connection to Pythi s3 Bucket\nURL = 'https://js2.jetstream-cloud.org:8001/'\npath = f'pythia/radar/erad2024'\n\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=URL))\n\n# C-band radar files\npath = \"pythia/radar/erad2024/20240522_MeteoSwiss_ARPA_Lombardia/Data/Cband/*.nc\"\nradar_files = fs.glob(path)\nradar_files[:3]\n\n# open files locally\nlocal_files = [\n    fsspec.open_local(\n        f\"simplecache::{URL}{i}\", s3={\"anon\": True}, filecache={\"cache_storage\": \".\"}\n    )\n    for i in radar_files[:5]\n]\n\nWe can open one of this nc files using xradar.io.open_cfradial1_datree method\n\ndt = xd.io.open_cfradial1_datatree(local_files[0])\ndisplay(dt)\n\nLet’s create our first ARCO dataset using .to_zarr method.\n\ndt.to_zarr(\"radar.zarr\", consolidated=True)\n\nWe can check that a new Zarr store is created (Object storage)\n\n!ls \n\nThis is stored locally, but could be stored in a Bucket on the cloud. Let’s open it back using Xarray.backends.api.open_datatree\n\ndt_back = xr.backends.api.open_datatree(\n    \"radar.zarr\", \n    consolidated=True\n)\n\ndisplay(dt_back)\n\n","type":"content","url":"/arco-datasets#cfradial2-1-fm301-standard","position":21},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Radar data time-series"},"type":"lvl2","url":"/arco-datasets#radar-data-time-series","position":22},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Radar data time-series"},"content":"\n\nConcatenating xradar.DataTree objects along a temporal dimension is a great approach to create a more organized and comprehensive dataset. By doing so, you can maintain a cohesive dataset that is both easier to manage and more meaningful for temporal analysis.\n\n#let's use our local files\nlen(local_files)\n\nTo create an ARCO dataset, we need to ensure that all radar volumes are properly aligned. To achieve this, we developed the following function:\n\ndef fix_angle(ds: xr.Dataset, tolerance: float=None, **kwargs) -> xr.Dataset:\n    \"\"\"\n    This function reindex the radar azimuth angle to make all sweeps starts and end at the same angle\n    @param ds: xarray dataset containing and xradar object\n    @param tolerance: Tolerance for interpolation between azimuth angles. \n                      Defaul, the radar azimuth angle resolution.\n    @return: azimuth reindex xarray dataset\n    \"\"\"\n    ds[\"time\"] = ds.time.load() \n    angle_dict = xd.util.extract_angle_parameters(ds)\n    start_ang = angle_dict[\"start_angle\"]\n    stop_ang = angle_dict[\"stop_angle\"]\n    direction = angle_dict[\"direction\"]\n    ds = xd.util.remove_duplicate_rays(ds)\n    az = len(np.arange(start_ang, stop_ang))\n    ar = np.round(az / len(ds.azimuth.data), 2)\n    tolerance = ar if not tolerance else tolerance\n    ds = xd.util.reindex_angle(\n        ds, \n        start_ang,  \n        stop_ang, \n        ar, \n        direction, \n        method=\"nearest\", \n        tolerance=tolerance, **kwargs\n    )\n    return ds\n\nNow, we can use the \n\nXarray.open_mfdataset method to open all nc files simultaneously. We can iterate over each sweep and concatenate them along the volume_time dimension.\n\n# listing all the sweeps within each nc file\nsweeps = [\n        i[1:] for i in list(dt.groups) if i.startswith(\"/sweep\") if i not in [\"/\"]\n    ]\nsweeps\n\nfor sweep in sweeps:\n    root = {}\n    ds = xr.open_mfdataset(\n        local_files,\n        preprocess=fix_angle,\n        engine=\"cfradial1\",\n        group=sweep,\n        concat_dim=\"volume_time\",\n        combine=\"nested\",\n    ).xradar.georeference()\n    ds\n    root[f\"{sweep}\"] = ds\n    dtree = DataTree.from_dict(root)\n    \n    try:\n        dtree.to_zarr(\n            \"radar_ts.zarr\", \n            consolidated=True,\n        )\n    except ContainsGroupError:\n        dtree.to_zarr(\n            \"radar_ts.zarr\", \n            consolidated=True, \n            mode=\"a\", \n        )\n    del dtree, ds\n\nLet’s see our new radar-time series dataset\n\ndtree = xr.backends.api.open_datatree(\n    \"radar_ts.zarr\",\n    consolidated=True,\n    chunks={}\n)\n\ndtree\n\nWe have successfully created a Analysis-Ready Cloud-Optimezed dataset.\n\n\n\n","type":"content","url":"/arco-datasets#radar-data-time-series","position":23},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Summary"},"type":"lvl2","url":"/arco-datasets#summary","position":24},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Summary"},"content":"We discussed the concept of Analysis-Ready Cloud-Optimezed (ARCO) datasets, emphasizing the importance of datasets that are pre-processed, clean, and well-organized. Leveraging the Climate and Forecast (CF) format-based FM301 hierarchical tree structure, endorsed by the World Meteorological Organization (WMO), we developed an open data model to arrange, manage, and store radar data in cloud-storage buckets efficiently. The ultimate goal of radar ARCO data is to streamline the data science process, making datasets immediately usable without the need for extensive preprocessing.","type":"content","url":"/arco-datasets#summary","position":25},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/arco-datasets#whats-next","position":26},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl3":"What’s next?","lvl2":"Summary"},"content":"Now, we can explore some quantitavite precipitation estimation (QPE) and quasy-vertical profiles (QVP) demos in the QPE-QVPs notebook.\n\n","type":"content","url":"/arco-datasets#whats-next","position":27},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Resources and references"},"type":"lvl2","url":"/arco-datasets#resources-and-references","position":28},{"hierarchy":{"lvl1":"Analysis-Ready Cloud-Optimized Datasets","lvl2":"Resources and references"},"content":"Xradar\n\nRadar cookbook\n\nPy-Art landing page\n\nWradlib landing page","type":"content","url":"/arco-datasets#resources-and-references","position":29},{"hierarchy":{"lvl1":"QPE & QVPs"},"type":"lvl1","url":"/qpe-qvps","position":0},{"hierarchy":{"lvl1":"QPE & QVPs"},"content":"\n\n","type":"content","url":"/qpe-qvps","position":1},{"hierarchy":{"lvl1":"QPE & QVPs"},"type":"lvl1","url":"/qpe-qvps#qpe-qvps","position":2},{"hierarchy":{"lvl1":"QPE & QVPs"},"content":"\n\n\n\n","type":"content","url":"/qpe-qvps#qpe-qvps","position":3},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Overview"},"type":"lvl2","url":"/qpe-qvps#overview","position":4},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Overview"},"content":"In this notebook, we demonstrate how utilizing radar data in the Analysis-Ready Cloud-Optimized (ARCO) format enables efficient computation of Quantitative Precipitation Estimates (QPE) and Quasi-Vertical Profiles (QVP). The ARCO format ensures that radar data is pre-processed, clean, and well-organized, significantly reducing the time spent on data preparation and cleaning. By leveraging ARCO radar data, we can focus more on scientific analysis.\n\nQPE Demo\n\nQVP Demo\n\n","type":"content","url":"/qpe-qvps#overview","position":5},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Prerequisites"},"type":"lvl2","url":"/qpe-qvps#prerequisites","position":6},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Xarray\n\nNecessary\n\nBasic features\n\nRadar Cookbook\n\nNecessary\n\nRadar basics\n\nIntro to Zarr\n\nNecessary\n\nZarr basics\n\nIntro to Hvplot\n\nNecessary\n\nInteractive visualization basics\n\nTime to learn: 45 minutes\n\n\n\n","type":"content","url":"/qpe-qvps#prerequisites","position":7},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Imports"},"type":"lvl2","url":"/qpe-qvps#imports","position":8},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Imports"},"content":"\n\nimport s3fs\nimport xarray as xr\nimport fsspec\nimport numpy as np\nimport hvplot.xarray\nimport matplotlib.pyplot as plt\nimport holoviews as hv\n\n","type":"content","url":"/qpe-qvps#imports","position":9},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"ARCO radar dataset"},"type":"lvl2","url":"/qpe-qvps#arco-radar-dataset","position":10},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"ARCO radar dataset"},"content":"\n\nWe build a dataset (object storage) containing both X and C-band radar data. This dataset is located at the Pythia S3 Bucket.\n\n## S3 bucket connection\nURL = 'https://js2.jetstream-cloud.org:8001/'\npath = f'pythia/radar/erad2024'\nfs = s3fs.S3FileSystem(anon=True, client_kwargs=dict(endpoint_url=URL))\nfile =  s3fs.S3Map(f\"{path}/zarr_radar/erad_2024.zarr\", s3=fs)\n\nLet’s read our ARCO dataset using xr.backends.api.open_datatree\n\n%%time\ndtree = xr.backends.api.open_datatree(\n    file, \n    engine='zarr', \n    consolidated=True, \n    chunks={}\n)\n\ndtree\n\nlist(dtree.children)\n\n","type":"content","url":"/qpe-qvps#arco-radar-dataset","position":11},{"hierarchy":{"lvl1":"QPE & QVPs","lvl3":"C-band radar data","lvl2":"ARCO radar dataset"},"type":"lvl3","url":"/qpe-qvps#c-band-radar-data","position":12},{"hierarchy":{"lvl1":"QPE & QVPs","lvl3":"C-band radar data","lvl2":"ARCO radar dataset"},"content":"\n\nWe can access a nested dataset by using the path as follows:\n\ndtree[\"cband\"]\n\n# all sweeps/nodes within the cband datatree\nlist(dtree[\"cband\"].children)\n\nAccessing one of the sweeps (“sweep_2”):\n\ndsc = dtree[\"cband/sweep_2\"].ds\n\ndisplay(dsc)\n\nLet’s use hvplot.quadmesh to create interactive plots\n\n# set constant colorbar limits\nref_C = dsc.reflectivity.compute().hvplot.quadmesh(\n    x=\"x\",\n    y=\"y\",\n    groupby=\"volume_time\",\n    clim=(-10, 60),\n    cmap=\"ChaseSpectral\",\n    width=600,\n    height=500,\n    widget_type=\"scrubber\",\n    widget_location=\"bottom\",\n    rasterize=True,\n)\n\nref_C\n\n","type":"content","url":"/qpe-qvps#c-band-radar-data","position":13},{"hierarchy":{"lvl1":"QPE & QVPs","lvl3":"X-band radar data","lvl2":"ARCO radar dataset"},"type":"lvl3","url":"/qpe-qvps#x-band-radar-data","position":14},{"hierarchy":{"lvl1":"QPE & QVPs","lvl3":"X-band radar data","lvl2":"ARCO radar dataset"},"content":"\n\nSimilarly, we can access X-band radar data as follows:\n\nlist(dtree[\"xband\"].children)\n\ndsx = dtree[\"xband/sweep_0\"].ds\n\ndisplay(dsx)\n\nInteractive plot using hvplot.quadmesh\n\n# set constant colorbar limits\nref_X = dsx.DBZ.compute().hvplot.quadmesh(\n    x=\"x\",\n    y=\"y\",\n    groupby=\"volume_time\",\n    clim=(-10, 60),\n    cmap=\"ChaseSpectral\",\n    width=600,\n    height=500,\n    widget_type=\"scrubber\",\n    widget_location=\"bottom\",\n    rasterize=True,\n)\nref_X\n\n","type":"content","url":"/qpe-qvps#x-band-radar-data","position":15},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Quantitave Precipitation Estimation (QPE)"},"type":"lvl2","url":"/qpe-qvps#quantitave-precipitation-estimation-qpe","position":16},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Quantitave Precipitation Estimation (QPE)"},"content":"\n\nQPE is a critical process in meteorology, providing measurements of rainfall intensity and accumulation from radar data. One of the foundational methods for QPE is based on the  Z-R relationship, which establishes a statistical relationship between radar reflectivity (Z) and rainfall rate (R). This empirical relationship, derived from observations, is commonly expressed as𝑍=\\alpha R^{\\beta}\n\nwhere \\alpha and \\beta are constants.\n\ndef rain_depth(z: xr.DataArray, a: float=200.0, b: float=1.6, t:int=5) -> xr.DataArray:\n    \"\"\"\n    Estimates rainfall depth using radar reflectivity and a Z-R relationship.\n    \n    This function computes Quantitative Precipitation Estimation (QPE) by converting\n    radar reflectivity (Z) into rainfall rate (R) using the Z-R relationship and\n    then integrating over time to estimate the total rainfall depth.\n    \n    Parameters:\n    -----------\n    z : xr.DataArray\n        Radar reflectivity in dBZ. This should be a multi-dimensional Xarray DataArray.\n    a : float, optional\n        The alpha (a) parameter in the Z-R relationship. Default is 200.0, corresponding\n        to the Marshall and Palmer (1948) relationship.\n    b : float, optional\n        The beta (b) parameter in the Z-R relationship. Default is 1.6, also from the\n        Marshall and Palmer (1948) relationship.\n    t : int, optional\n        Time integration period in minutes, used to convert rainfall rates into\n        accumulated depth. Default is 5 minutes.\n    \n    Returns:\n    --------\n    xr.DataArray\n        A DataArray representing the estimated rainfall depth in the same dimensions\n        as the input radar reflectivity. The units of the returned DataArray will be\n        consistent with the time integration provided (e.g., mm for 5-minute accumulation).\n    \n    Notes:\n    ------\n    - The Z-R relationship used is of the form Z = a * R^b, where Z is in linear units.\n    - The function first converts the radar reflectivity from dBZ to linear units (Z),\n      then computes the rainfall rate (R), and finally multiplies by the time integration\n      period to obtain the rainfall depth.\n    \n    Example:\n    --------\n    To compute the rainfall depth over a 5-minute period using reflectivity data:\n    \n    >>> rainfall_depth = rain_depth(z, a=200.0, b=1.6, t=5)\n    \n    This will return the estimated rainfall depth in millimeters, assuming the default\n    parameters for the Marshall and Palmer (1955) Z-R relationship.\n    \n    \"\"\"\n    # Convert reflectivity from dBZ to linear units\n    z_lin = 10 ** (z / 10) \n    # Compute rainfall depth using the Z-R relationship and time integration\n    \n    return ((1 / a) ** (1 / b) * z_lin ** (1 / b)) * (t / 60) # rainfall depth\n\nLet’s apply this fucntion to our radar dataset\n\nr_depth = rain_depth(dsc.reflectivity)\n\nr_depth\n\nAs the coordinates depend on the volume_time dimension, they will disappear when aggregating along this dimension. Therefore, we need to store these coordinates so that we can add them back to our xr.DataArray\n\nx = dsc.x.isel(volume_time=0)\ny = dsc.y.isel(volume_time=0)\nz = dsc.z.isel(volume_time=0)\n\nLet’s compute the total rainfall depth across the entire dataset.\n\nr_total = r_depth.sum(\"volume_time\")\n\nAdding coordinates back\n\nr_total = r_total.assign_coords({\"x\":x, \"y\":y, \"z\":z})\n\nPlotting the total rainfall depth\n\n%%time\nfig, ax = plt.subplots(figsize=(6, 5))\nc = r_total.plot.pcolormesh(\n    x='x', \n    y='y', \n    cmap='ChaseSpectral', \n    vmin=0,\n    vmax=50,\n    add_colorbar=False\n)\nplt.colorbar(c, ax=ax, label=\"Rainfall depth [mm]\")\nax.set_title(\"\")\n\nNow it’s your turn. Try computing the QPE for the X-band radar dataset\n\n# Computing rainfall depth\n\n\n# saving coordinates\n\n\n# Acummulating rainfall depths\n\n\n# adding back x,y, and z coordinates\n\n\n# Plotting rainfall accumulation\n\n\n","type":"content","url":"/qpe-qvps#quantitave-precipitation-estimation-qpe","position":17},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Quasi-Vertical Profile (QVP)"},"type":"lvl2","url":"/qpe-qvps#quasi-vertical-profile-qvp","position":18},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Quasi-Vertical Profile (QVP)"},"content":"\n\nQuasi-Vertical Profiles (QVP) are a radar analysis technique that provides vertical profiles of atmospheric phenomena by averaging radar data over a specific azimuthal range. This method simplifies the study of storm structures, revealing vertical distributions of reflectivity, velocity, and other key parameters. QVPs are valuable for understanding storm dynamics and the development of severe weather.\n\nThe following function will help us computing QVPs\n\ndef compute_qvp(ds: xr.Dataset, var=\"reflectivity\")-> xr.DataArray:\n    \"\"\"\n    Computes a Quasi-Vertical Profile (QVP) from a radar time-series dataset.\n    \n    This function averages the specified variable over the azimuthal dimension\n    to produce a QVP. If the variable is in dBZ (a logarithmic scale), it converts\n    the values to linear units before averaging and then converts the result \n    back to dBZ.\n    \n    Parameters:\n    -----------\n    ds : xr.Dataset\n        The Xarray Dataset containing the radar data. This dataset should include\n        multiple sweeps, azimuth angles, and range gates.\n    var : str, optional\n        The variable to be averaged to create the QVP. \n        Default is \"reflectivity\".\n    \n    Returns:\n    --------\n    xr.DataArray\n        A DataArray representing the QVP for the specified variable. The result\n        is averaged over azimuth and adjusted for height using the mean sweep \n        elevation angle.\n    \n    Notes:\n    ------\n    - If the variable is in dBZ units, the function converts it to linear units \n      before averaging to ensure accurate results, then converts it back to dBZ.\n    - The QVP is calculated by adjusting the range gates to height using the \n      sine of the mean sweep elevation angle.\n    \n    Example:\n    --------\n    To compute a QVP for reflectivity:\n    \n    >>> qvp_reflectivity = compute_qvp(ds, var=\"reflectivity\")\n    \n    The resulting QVP will be in dBZ and aligned along the height dimension.\n    \n    \"\"\"\n    \n    units: str = ds[var].attrs['units']\n    if units.startswith(\"dB\"):\n        qvp = 10 ** (ds[var] / 10)\n        qvp = qvp.mean(\"azimuth\")\n        qvp = 10 * np.log10(qvp)\n    else:\n        qvp = ds[var]\n        qvp = qvp.mean(\"azimuth\")\n        \n    qvp = qvp.assign_coords({\"range\":(qvp.range.values * \n                                 np.sin(ds.sweep_fixed_angle.values.mean() *  \n                                        np.pi / 180.))})\n    qvp = qvp.rename(f\"qvp_{var}\")\n    qvp = qvp.rename({\"range\": \"height\"})\n    return qvp\n\nLet’s compute the QVP for the X-band radar dataset at the highest elevation angle (“sweep_7”).\n\nds_x = dtree[\"xband/sweep_7\"].ds\n\ndisplay(ds_x)\n\nWe can use our compute_qvp function to create the reflectivity QVP.\n\nqvp_ref = compute_qvp(ds_x, var=\"DBZ\")\n\ndisplay(qvp_ref)\n\nWe can visualize the QVP results using the .plot functionality within xarray library.\n\nqvp_ref.sel(height=slice(0, 1.2e4)).plot(\n    x=\"volume_time\",\n    y=\"height\",\n    cmap=\"ChaseSpectral\",\n    vmin=-10,\n    vmax=50\n)\n\nLet’s try to create a figure similar to the one in \n\nRyzhkov et al. (2016) by estimating the QVP for differential reflectivity (ZDR), the cross-correlation coefficient (RHOHV), and the differential phase (PHIDP).\n\nqvp_zdr = compute_qvp(ds_x, var=\"ZDR\")\nqvp_rhohv = compute_qvp(ds_x, var=\"RHOHV\")\nqvp_phidp = compute_qvp(ds_x, var=\"PHIDP\")\n\nLet’s create the figure\n\n%%time\nfig, axs = plt.subplots(2, 2, figsize=(12, 5), sharey=True, sharex=True)\n\ncf = qvp_ref.sel(height=slice(0, 1.2e4)).plot.contourf(\n    x=\"volume_time\",\n    y=\"height\",\n    cmap=\"ChaseSpectral\",\n    vmin=-10,\n    vmax=50, \n    ax=axs[0][0],\n    levels=np.linspace(-10, 50, 61),\n    add_colorbar=False,\n)\naxs[0][0].set_title(r\"$Z$\")\naxs[0][0].set_xlabel(\"\")\naxs[0][0].set_ylabel(r\"$Height \\ [m]$\")\n\ncbar = plt.colorbar(cf, ax=axs[0][0], \n                    label=r\"$Reflectivity \\ [dBZ]$\", \n                   )\n\n\ncf1 = qvp_zdr.sel(height=slice(0, 1.2e4)).plot.contourf(\n    x=\"volume_time\",\n    y=\"height\",\n    cmap=\"ChaseSpectral\",\n    vmin=-1,\n    vmax=5, \n    ax=axs[0][1],\n    levels=np.linspace(-1, 5, 11),\n    add_colorbar=False,\n)\naxs[0][1].set_title(r\"$Z_{DR}$\")\naxs[0][1].set_xlabel(\"\")\naxs[0][1].set_ylabel(r\"\")\n\ncbar = plt.colorbar(cf1, ax=axs[0][1], \n                    label=r\"$Diff. \\ Reflectivity \\ [dB]$\", \n                   )\n\ncf2 = qvp_rhohv.sel(height=slice(0, 1.2e4)).plot.contourf(\n    x=\"volume_time\",\n    y=\"height\",\n    cmap=\"ChaseSpectral\",\n    vmin=0,\n    vmax=1, \n    ax=axs[1][0],\n    levels=np.linspace(0, 1, 101),\n    add_colorbar=False,\n)\naxs[1][0].set_title(r\"$\\rho _{HV}$\")\naxs[1][0].set_ylabel(r\"$Height \\ [m]$\")\naxs[1][0].set_xlabel(r\"$Time \\ [UTC]$\")\n\ncbar = plt.colorbar(cf2, ax=axs[1][0], \n                    label=r\"$Cross-Correlation \\ Coef.$\", \n                   )\ncf3 = qvp_phidp.sel(height=slice(0, 1.2e4)).plot.contourf(\n    x=\"volume_time\",\n    y=\"height\",\n    cmap=\"jet\",\n    vmin=0,\n    vmax=100, \n    ax=axs[1][1],\n    levels=np.linspace(0, 100, 101),\n    add_colorbar=False,\n\n)\naxs[1][1].set_title(r\"$\\theta _{DP}$\")\naxs[1][1].set_xlabel(r\"$Time \\ [UTC]$\")\naxs[1][1].set_ylabel(r\"\")\n\ncbar = plt.colorbar(cf3, ax=axs[1][1], \n                    label=r\"$Differential \\ Phase \\ [deg]$\", \n                   )\n\nfig.tight_layout()\nplt.savefig('../images/QVP.svg',  bbox_inches='tight')\n\nNow it’s your turn. Try computing the QPE for the C-band radar dataset using the 20 deg elevation angle (“sweep_15”)\n\n## Select the sweep_15 from the dtree\n\n\n## compute the QVP for \"reflectivity\", \"differential_reflectivity\", \n## \"uncorrected_cross_correlation_ratio\", and \"uncorrected_differential_phase\"\n\n\n# create the figure\n\n\n\n\n\n","type":"content","url":"/qpe-qvps#quasi-vertical-profile-qvp","position":19},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Summary"},"type":"lvl2","url":"/qpe-qvps#summary","position":20},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Summary"},"content":"In this notebook, we successfully computed Quantitative Precipitation Estimation (QPE) and Quasi-Vertical Profiles (QVP) for both X-band and C-band radar data using the Analysis-Ready Cloud-Optimized (ARCO) dataset. By leveraging the ARCO format, we were able to streamline the data processing, allowing us to efficiently apply our custom functions for QPE and QVP computation. This approach demonstrated the effectiveness of ARCO datasets in facilitating advanced radar data analysis with minimal preprocessing effort.\n\n","type":"content","url":"/qpe-qvps#summary","position":21},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Resources and references"},"type":"lvl2","url":"/qpe-qvps#resources-and-references","position":22},{"hierarchy":{"lvl1":"QPE & QVPs","lvl2":"Resources and references"},"content":"Ryzhkov, A., P. Zhang, H. Reeves, M. Kumjian, T. Tschallener, S. Trömel, and C. Simmer, 2016: Quasi-Vertical Profiles—A New Way to Look at Polarimetric Radar Data. J. Atmos.   Oceanic Technol., 33, 551–562, \n\nRyzhkov et al. (2016)\n\nMarshall, J. S.; Palmer, W. M. (1948). “The distribution of raindrops with size”. Journal of Meteorology. 5 (4): 165–166. \n\nMarshall & Palmer (1948)\n\nXradar\n\nRadar cookbook\n\nPy-Art landing page\n\nWradlib landing page","type":"content","url":"/qpe-qvps#resources-and-references","position":23},{"hierarchy":{"lvl1":"PyDDA tutorial"},"type":"lvl1","url":"/retrieving-winds-with-pydda","position":0},{"hierarchy":{"lvl1":"PyDDA tutorial"},"content":"\n\nPyDDA is an open source Python package for retrieving winds using Multiple Doppler analyses. It uses the 3D variational technique for retrieving winds from multiple Doppler radars. It uses Py-ART Grid Objects as inputs. Therefore, preprocessed and gridded data are needed for PyDDA to run.","type":"content","url":"/retrieving-winds-with-pydda","position":1},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"3D variational technique"},"type":"lvl2","url":"/retrieving-winds-with-pydda#id-3d-variational-technique","position":2},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"3D variational technique"},"content":"PyDDA uses a 3D variational technique to retrieve the 3D wind field. We will leave students that are interested in more information about these technqiues two references to read at the end of this notebook. A basic introduction to 3D variational analysis is given here.\n\nPyDDA minimizes a cost function J that corresponds to various penalties including:\n\nJ_{m} = \\nabla \\cdot V which corresponds to the mass continuity equation.\n\nJ_{o} =  RMSE between radar winds and analysis winds.\n\nJ_{b} =  RMSE between sounding winds and analysis winds.\n\nJ_{s} = \\nabla^2 V which corresponds to the smoothness of wind field to eliminate high-frequency noise that can result from numerical instability.\n\nThe cost function to be minimized is a weighted sum of the various cost functions in PyDDA and are represented in Equation (1):\n\n$J = c_{m}J_{m} + c_{o}J_{o} + c_{b}J_{b} + c_{s}J_{s} + ...$ (1)","type":"content","url":"/retrieving-winds-with-pydda#id-3d-variational-technique","position":3},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl3":"References","lvl2":"3D variational technique"},"type":"lvl3","url":"/retrieving-winds-with-pydda#references","position":4},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl3":"References","lvl2":"3D variational technique"},"content":"\n\n","type":"content","url":"/retrieving-winds-with-pydda#references","position":5},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Imports"},"type":"lvl2","url":"/retrieving-winds-with-pydda#imports","position":6},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Imports"},"content":"Let’s import the necessary libraries. For now, we’ll need PyART, glob, matplotlib, and PyDDA.\n\nimport glob\n\nimport pyart\nimport matplotlib.pyplot as plt\nimport pydda\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport fsspec\nimport cartopy.crs as ccrs\n\nwarnings.filterwarnings(\"ignore\")\n\n","type":"content","url":"/retrieving-winds-with-pydda#imports","position":7},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Case study"},"type":"lvl2","url":"/retrieving-winds-with-pydda#case-study","position":8},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Case study"},"content":"We will examine the same case study over Italy that has been used for this entire short course. For this case in May 2024, we had weak convective cells in the region of\n\nFor this case, we had coverage of the storm from two radars, a MeteoSwiss C-band radar near Monte Lema, CH and an X-band radar from ARPA Lombardia located about 50 km away in Milano, IT.\n\n","type":"content","url":"/retrieving-winds-with-pydda#case-study","position":9},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl3":"C-band Radar","lvl2":"Case study"},"type":"lvl3","url":"/retrieving-winds-with-pydda#c-band-radar","position":10},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl3":"C-band Radar","lvl2":"Case study"},"content":"We need to load and preprocess the C-band radar data first. In order to do so, we first need to load the MeteoSwiss C-band radar file.\n\n# Set the URL and path for the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = f\"pythia/radar/erad2024\"\n\n\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=URL))\n\nfs.glob(f\"{path}/*\")\n\nfiles = fs.glob(\"pythia/radar/erad2024/dda_data/*\")\nlocal_files = [\n    fsspec.open_local(\n        f\"simplecache::{URL}{i}\", s3={\"anon\": True}, filecache={\"cache_storage\": \".\"}\n    )\n    for i in files\n]\n\nradar = pyart.io.read(local_files[1])\n\nradar.info()\n\n","type":"content","url":"/retrieving-winds-with-pydda#c-band-radar","position":11},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl3":"Dealiasing","lvl2":"Case study"},"type":"lvl3","url":"/retrieving-winds-with-pydda#dealiasing","position":12},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl3":"Dealiasing","lvl2":"Case study"},"content":"The next step is to dealias the radar data. We will follow the steps that were shown eariler in this course to dealias the radar data. Dealiasing is covered in detail in the \n\nRadar Cookbook.\n\nnyquist = radar.instrument_parameters[\"nyquist_velocity\"][\"data\"][0]\nvel_dealias = pyart.correct.dealias_region_based(\n    radar,\n    vel_field=\"velocity\",\n    nyquist_vel=nyquist,\n    centered=True,\n)\nradar.add_field(\"corrected_velocity\", vel_dealias, replace_existing=True)\n\nPlot the data to make sure dealiasing succeeded.\n\ndisplay = pyart.graph.RadarDisplay(radar)\ndisplay.plot(\"reflectivity\", vmin=-20, vmax=70, cmap=\"pyart_ChaseSpectral\", sweep=0)\n\ndisplay = pyart.graph.RadarDisplay(radar)\ndisplay.plot(\"corrected_velocity\", vmin=-30, vmax=30, cmap=\"twilight_shifted\", sweep=0)\n\nSome regions did not dealias correctly, like in the region around (-100 km, -100 km) where gate-to-gate shear exceeds the Nyquist interval in the absence of . The region-based algorithm is very sensitive to speckles that are present in the above image. Let’s despeckle the above radar data to remove some artifacts.\n\ngatefilter = pyart.filters.GateFilter(radar)\ngatefilter.exclude_above(\"spectrum_width\", 7)\n# gatefilter.exclude_below('cross_correlation_ratio', 0.8)\ngatefilter = pyart.correct.despeckle_field(\n    radar, \"reflectivity\", gatefilter=gatefilter, size=36\n)\ndisplay = pyart.graph.RadarDisplay(radar)\ndisplay.plot(\n    \"reflectivity\",\n    vmin=-20,\n    vmax=70,\n    gatefilter=gatefilter,\n    cmap=\"pyart_ChaseSpectral\",\n    sweep=0,\n)\n\nLet’s also tweak the settings of the region based dealiasing. Currently, the dealiasing will attempt to dealias regions that are separated by 100 masked gates in the radial. We will disable this feature by setting skip_between_rays to 0 so that all dealiasing across filtered gates along the azimuth is disabled.\n\nnyquist = radar.instrument_parameters[\"nyquist_velocity\"][\"data\"][0]\nvel_dealias = pyart.correct.dealias_region_based(\n    radar,\n    vel_field=\"velocity\",\n    nyquist_vel=nyquist,\n    gatefilter=gatefilter,\n    centered=True,\n    skip_between_rays=0,\n)\nradar.add_field(\"corrected_velocity\", vel_dealias, replace_existing=True)\n\nLet’s plot all of the sweeps to make sure dealiasing worked correctly.\nA good indicator of checking this is to check if there are discontinuities in the radial velocities between sweeps on the order of the Nyquist velocity. If there are such discontinuties, further tweaking of the parameters or grounding the retrieval to a sounding may be needed. Using these parameters, the above example radar data is properly dealiased.\n\ndisplay = pyart.graph.RadarDisplay(radar)\nfig, ax = plt.subplots(4, 5, figsize=(15, 10))\nfor i in range(radar.nsweeps):\n    display.plot(\n        \"corrected_velocity\",\n        vmin=-30,\n        vmax=30,\n        cmap=\"twilight_shifted\",\n        sweep=i,\n        colorbar_label=\"m/s\",\n        ax=ax[int(i / 5), i % 5],\n    )\n    ax[int(i / 5), i % 5].set_title(\"%2.1f deg\" % radar.fixed_angle[\"data\"][i])\n    ax[int(i / 5), i % 5].set_xlabel(\"X [km]\")\n    ax[int(i / 5), i % 5].set_ylabel(\"Y [km]\")\nfig.tight_layout()\n\npyart.io.write_cfradial(\"MonteLema.20240522.151606_dealiased.nc\", radar)\n\n","type":"content","url":"/retrieving-winds-with-pydda#dealiasing","position":13},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Gridding"},"type":"lvl2","url":"/retrieving-winds-with-pydda#gridding","position":14},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Gridding"},"content":"PyDDA requires data to be gridded to Cartesian coordinates in order to retrieve the 3D wind fields. Therefore, we will use Py-ART’s grid_from_radars function in order to do the gridding. You usually want to have a grid resolution such that your features of interest are covered by four grid points. In this case, we’re at 1 km horizontal and 0.5 km vertical resolution. For more information on gridding with Py-ART, see the \n\nRadar Cookbook.\n\ngrid_limits = ((0.0, 15000.0), (-100_000.0, 100_000.0), (-100_000.0, 100_000.0))\ngrid_shape = (31, 201, 201)\nradar.fields[\"corrected_velocity\"][\"data\"] = np.ma.masked_where(\n    gatefilter.gate_excluded, radar.fields[\"corrected_velocity\"][\"data\"]\n)\nradar.fields[\"reflectivity\"][\"data\"] = np.ma.masked_where(\n    gatefilter.gate_excluded, radar.fields[\"reflectivity\"][\"data\"]\n)\n\ncband_grid = pyart.map.grid_from_radars(\n    [radar], grid_limits=grid_limits, grid_shape=grid_shape\n)\ncband_ds = cband_grid.to_xarray()\ncband_ds\n\nLet’s make sure the grid looks good!\n\ncband_ds.isel(z=1).reflectivity.plot(\n    x=\"lon\", y=\"lat\", vmin=-20, vmax=70, cmap=\"pyart_ChaseSpectral\"\n)\n\ncband_ds.isel(y=35).reflectivity.plot(\n    x=\"x\", y=\"z\", vmin=-20, vmax=70, cmap=\"pyart_ChaseSpectral\"\n)\n\n","type":"content","url":"/retrieving-winds-with-pydda#gridding","position":15},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl3":"X-band Data","lvl2":"Gridding"},"type":"lvl3","url":"/retrieving-winds-with-pydda#x-band-data","position":16},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl3":"X-band Data","lvl2":"Gridding"},"content":"Next, we need to load the X-band radar data from the archive.\n\nradar_xband = pyart.io.read(local_files[0])\n\nRead a single file, the one closes to the UAH volume scan used before\n\nradar.info()\n\nVisualize the data to make sure we have the correct scan.\n\ndisplay = pyart.graph.RadarDisplay(radar_xband)\ndisplay.plot(\"DBZ\", vmin=0, vmax=70, cmap=\"pyart_ChaseSpectral\", sweep=0)\nplt.ylim(-100, 100)\nplt.xlim(-100, 100)\n\nThe X-band radar data also need to be dealiased. We will still need to filter out the noise in the above radar data.\n\n# Use the C-band radar lat/lon as the center for the grid\n\ngatefilter = pyart.filters.GateFilter(radar_xband)\ngatefilter.exclude_above(\"WIDTH\", 7)\ngatefilter.exclude_below(\"RHOHV\", 0.8)\ngatefilter = pyart.correct.despeckle_field(\n    radar_xband, \"DBZ\", gatefilter=gatefilter, size=100\n)\nvel_dealias = pyart.correct.dealias_region_based(\n    radar_xband,\n    vel_field=\"VEL\",\n    nyquist_vel=nyquist,\n    centered=True,\n    skip_between_rays=0,\n    skip_along_ray=0,\n    interval_splits=3,\n)\nradar_xband.add_field(\"corrected_velocity\", vel_dealias, replace_existing=True)\n\nLet’s view the sweeps to make sure that dealiasing is working correctly.\n\ndisplay = pyart.graph.RadarDisplay(radar_xband)\nfig, ax = plt.subplots(2, 4, figsize=(15, 5))\nfor i in range(radar_xband.nsweeps):\n    display.plot(\n        \"corrected_velocity\",\n        vmin=-30,\n        vmax=30,\n        cmap=\"twilight_shifted\",\n        sweep=i,\n        colorbar_label=\"m/s\",\n        ax=ax[int(i / 4), i % 4],\n    )\n    ax[int(i / 4), i % 4].set_title(\"%2.1f deg\" % radar.fixed_angle[\"data\"][i])\n    ax[int(i / 4), i % 4].set_xlabel(\"X [km]\")\n    ax[int(i / 4), i % 4].set_ylabel(\"Y [km]\")\nfig.tight_layout()\n\npyart.io.write_cfradial(\"ARPA_Lombardia.20240522.151546_dealiased.nc\", radar_xband)\n\ngrid_lat = radar.latitude[\"data\"][0]\ngrid_lon = radar.longitude[\"data\"][0]\nxband_grid = pyart.map.grid_from_radars(\n    [radar_xband],\n    grid_limits=grid_limits,\n    grid_shape=grid_shape,\n    grid_origin=(grid_lat, grid_lon),\n)\n\n# Convert to xarray and remove the time dimension\nxband_ds = xband_grid.to_xarray().squeeze()\n\n","type":"content","url":"/retrieving-winds-with-pydda#x-band-data","position":17},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Visualize the grids"},"type":"lvl2","url":"/retrieving-winds-with-pydda#visualize-the-grids","position":18},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Visualize the grids"},"content":"Let’s see what our output data looks like!\n\nxband_ds.DBZ.isel(z=1).plot(x=\"lon\", y=\"lat\", cmap=\"Spectral_r\", vmin=-20, vmax=50)\n\nVelocities look good!\n\nxband_ds.corrected_velocity.isel(z=4).plot(\n    x=\"lon\", y=\"lat\", cmap=\"twilight_shifted\", vmin=-30, vmax=30\n)\n\nxband_ds.corrected_velocity.isel(y=55).plot(\n    x=\"x\", y=\"z\", cmap=\"twilight_shifted\", vmin=-20, vmax=20\n)\n\n","type":"content","url":"/retrieving-winds-with-pydda#visualize-the-grids","position":19},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"PyDDA initialization"},"type":"lvl2","url":"/retrieving-winds-with-pydda#pydda-initialization","position":20},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"PyDDA initialization"},"content":"The 3DVAR wind retrieval first requires an initial guess at the wind field in order to start the cost function minimization process. PyDDA has support for using WRF and sounding data as an initial guess of the wind field as well as constant wind fields.\n\nInitalization functions in pydda.initialization module:\n\nFunctionality\n\nmake_constant_wind_field(Grid[, wind, vel_field])\n\nThis function makes a constant wind field given a wind vector\n\nmake_wind_field_from_profile(Grid, profile)\n\nThis function makes a 3D wind field from a sounding.\n\nmake_background_from_wrf(Grid, file_path, ...)\n\nThis function makes an initalization field based off of the u and w from a WRF run.\n\nmake_initialization_from_era_interim(Grid[, ...])\n\nThis function will read ERA Interim in NetCDF format and add it to the Py-ART grid specified by Grid.\n\nFor this example, using a zero initialization field is sufficient to create an accurate representation of the wind field. Depending on your radar set up, you may need to adjust the input initial wind field to avoid artifacts at the edges of the multi-Doppler lobes.\n\ncband_ds = pydda.io.read_from_pyart_grid(cband_grid)\nxband_ds = pydda.io.read_from_pyart_grid(xband_grid)\ncband_ds = pydda.initialization.make_constant_wind_field(\n    cband_ds, (0.0, 0.0, 0.0), \"velocity\"\n)\nxband_ds[\"reflectivity\"] = xband_ds[\"DBZ\"]\n\n","type":"content","url":"/retrieving-winds-with-pydda#pydda-initialization","position":21},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"PyDDA wind retrieval"},"type":"lvl2","url":"/retrieving-winds-with-pydda#pydda-wind-retrieval","position":22},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"PyDDA wind retrieval"},"content":"The core wind retrieval function in PyDDA is done using retrieval.get_dd_wind_field. It has many potential keyword inputs that the user can enter. In this example, we are specifying:\n\nInput to pydda.initialization module:\n\nMeaning\n\nValue\n\nGrids\n\nThe input grids to analyze.\n\n[uah_grid, nexrad_grid]\n\nu_init\n\nInitial guess of u field.\n\nu_init\n\nv_init\n\nInitial guess of u field.\n\nv_init\n\nw_init\n\nInitial guess of u field.\n\nw_init\n\nCo\n\nWeight for cost function related to radar observations\n\n1.0\n\nCm\n\nWeight of cost function related to mass continuity equation\n\n256.0\n\nCx\n\nWeight of cost function for smoothess in the x-direction\n\n1e-3\n\nCy\n\nWeight of cost function for smoothess in the y-direction\n\n1e-3\n\nCz\n\nWeight of cost function for smoothess in the z-direction\n\n1e-3\n\nCb\n\nWeight of cost function for sounding (background) constraint\n\n0\n\nfrz\n\nThe freezing level in meters. This is to tell PyDDA where to use ice particle fall speeds in the wind retrieval verus liquid.\n\n5000.\n\nfilter_window\n\nThe window to apply the low pass filter on\n\n5\n\nmask_outside_opt\n\nMask all winds outside the Dual Doppler lobes\n\nTrue\n\nvel_name\n\nThe name of the velocity field in the radar data\n\n‘corrected_velocity’\n\nwind_tol\n\nStop optimization when the change in wind speeds between iterations is less than this value\n\n\n\nengine\n\nPyDDA supports three backends for optimization: SciPy, JAX, and TensorFlow.\n\n“scipy”\n\ngrids, params = pydda.retrieval.get_dd_wind_field(\n    [cband_ds, xband_ds],\n    Co=1,\n    Cm=1024.0,\n    Cx=1e-2,\n    Cy=1e-2,\n    Cz=1e-2,\n    frz=5000.0,\n    mask_outside_opt=True,\n    upper_bc=1,\n    vel_name=\"corrected_velocity\",\n    wind_tol=0.5,\n    engine=\"scipy\",\n)\n\n","type":"content","url":"/retrieving-winds-with-pydda#pydda-wind-retrieval","position":23},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Visualize the results"},"type":"lvl2","url":"/retrieving-winds-with-pydda#visualize-the-results","position":24},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Visualize the results"},"content":"Let’s visualize the results. There are two ways in which this data can be visualized. One way is by using PyDDA’s visualization routines. You can also use xarray to visualize the output grids.\n\nds = grids[0]\nds\n\nIf you are not able to get the above example to run on your laptop, pre-generated grid files are available \n\nhere.\n\nds.reflectivity.sel(z=2000, method=\"nearest\").plot(\n    cmap=\"pyart_ChaseSpectral\", vmin=-10, vmax=60\n)\nds.isel(time=0).sel(z=2000, method=\"nearest\").w.plot.contour(\n    x=\"x\", y=\"y\", levels=np.arange(1, 5, 1)\n)\nplt.xlim([-50000, 25000])\nplt.ylim([-100000, -25000])\n\n","type":"content","url":"/retrieving-winds-with-pydda#visualize-the-results","position":25},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Saving the grids"},"type":"lvl2","url":"/retrieving-winds-with-pydda#saving-the-grids","position":26},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"Saving the grids"},"content":"\n\nWe can save the grids using either xarray’s or Py-ART’s functionality. To save the output grids,  use pyart.io.write_grid (PyART) functions. For example:\n\n# Keep these lines if we can't update PyDDA in time for ERAD\ngrids[0].attrs[\"radar_name\"] = \"C-band\"\ndel grids[0][\"time\"].attrs[\"units\"]\ngrids[1].attrs[\"radar_name\"] = \"X-band\"\ndel grids[1][\"time\"].attrs[\"units\"]\n\ngrids[0].to_netcdf(\"output_grid_Cband.nc\")\ngrids[1].to_netcdf(\"output_grid_Xband.nc\")\n\nIn order to load the grids again, we can just use PyART’s pyart.io.read_grid procedure.\n\n# For live demos, load these since retrieval takes about 7 minutes\ngrids = [\n    pydda.io.read_grid(\"output_grid_Cband.nc\"),\n    pydda.io.read_grid(\"output_grid_Xband.nc\"),\n]\n\n","type":"content","url":"/retrieving-winds-with-pydda#saving-the-grids","position":27},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"PyDDA visualization routines"},"type":"lvl2","url":"/retrieving-winds-with-pydda#pydda-visualization-routines","position":28},{"hierarchy":{"lvl1":"PyDDA tutorial","lvl2":"PyDDA visualization routines"},"content":"PyDDA’s visualization routines support the native PyART grids that are output by PyDDA. These routines have an advantage over xarray’s plotting routines for adjusting your barb and quiver size by specifying their using parameters that are in scales of kilometers. This makes it easier to plot barb and quiver plots compared to using xarray’s functionality.\n\nFor example, the documentation for pydda.vis.plot_horiz_xsection_quiver is given below.\n\n?pydda.vis.plot_horiz_xsection_quiver\n\nPyDDA has the following visualization routines for your sets of grids:\n\nProcedure\n\nDescription\n\nplot_horiz_xsection_barbs(Grids[, ax, ...])\n\nHorizontal cross section of winds from wind fields generated by PyDDA using barbs.\n\nplot_xz_xsection_barbs(Grids[, ax, ...])\n\nCross section of winds from wind fields generated by PyDDA in the X-Z plane using barbs.\n\nplot_yz_xsection_barbs(Grids[, ax, ...])\n\nCross section of winds from wind fields generated by PyDDA in the Y-Z plane using barbs.\n\nplot_horiz_xsection_barbs_map(Grids[, ax, ...])\n\nHorizontal cross section of winds from wind fields generated by PyDDA onto a geographical map using barbs.\n\nplot_horiz_xsection_streamlines(Grids[, ax, ...])\n\nHorizontal cross section of winds from wind fields generated by PyDDA using streamlines.\n\nplot_xz_xsection_streamlines(Grids[, ax, ...])\n\nCross section of winds from wind fields generated by PyDDA in the X-Z plane using streamlines.\n\nplot_yz_xsection_streamlines(Grids[, ax, ...])\n\nCross section of winds from wind fields generated by PyDDA in the Y-Z plane using streamlines.\n\nplot_horiz_xsection_streamlines_map(Grids[, ...])\n\nHorizontal cross section of winds from wind fields generated by PyDDA using streamlines.\n\nplot_horiz_xsection_quiver(Grids[, ax, ...])\n\nHorizontal cross section of winds from wind fields generated by PyDDA using quivers.\n\nplot_xz_xsection_quiver(Grids[, ax, ...])\n\nCross section of winds from wind fields generated by PyDDA in the X-Z plane using quivers.\n\nplot_yz_xsection_quiver(Grids[, ax, ...])\n\nCross section of winds from wind fields generated by PyDDA in the Y-Z plane using quivers.\n\nplot_horiz_xsection_quiver_map(Grids[, ax, ...])\n\nHorizontal cross section of winds from wind fields generated by PyDDA using quivers onto a geographical map.\n\nLet’s show a quiver plot of this storm!\n\nWe have specified the quivers to be 4 km apart and moved the key to the bottom right with the specific length indicating 20 m/s winds. Let’s look at the 3 km level.\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\npydda.vis.plot_horiz_xsection_quiver(\n    grids,\n    quiver_spacing_x_km=2.5,\n    quiver_spacing_y_km=2.5,\n    quiver_width=0.005,\n    vmax=60,\n    quiverkey_len=10.0,\n    w_vel_contours=np.arange(1, 5, 1),\n    level=4,\n    cmap=\"pyart_ChaseSpectral\",\n    ax=ax,\n    quiverkey_loc=\"bottom_right\",\n)\nplt.xlim([-75, 25])\nplt.ylim([-100, -25])\n\nWe can zoom in and modify the plot using standard matplotlib functions on the axis handle.\n\nIt is much easier to see updrafts being placed just to the outside of the strongest precipitation, with potential new growth in the north of the domain with updraft velocities > 7 m/s. The precipitation is downwind of the updraft as we would expect.\n\nUpdrafts are right tilted due to the horizontal wind shear. The horizontal wind shear also causes the most intense precipitation to be downshear of the updraft. This therefore shows us that we have a good quality wind retrieval below about 5 km in altitude.\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 4))\npydda.vis.plot_xz_xsection_quiver(\n    grids,\n    quiver_spacing_x_km=2.0,\n    quiver_spacing_z_km=1.0,\n    quiver_width=0.005,\n    quiverkey_len=10.0,\n    w_vel_contours=np.arange(1, 5, 1),\n    level=37,\n    cmap=\"pyart_ChaseSpectral\",\n    ax=ax,\n    quiverkey_loc=\"top_right\",\n)\nax.set_xlim([-75, -25])\nax.set_ylim([0, 13])\n\nLet’s view a horizontal cross section with barbs!\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\npydda.vis.plot_horiz_xsection_barbs(\n    grids,\n    barb_spacing_x_km=6.0,\n    barb_spacing_y_km=6.0,\n    w_vel_contours=np.arange(1, 10, 1),\n    level=6,\n    cmap=\"pyart_ChaseSpectral\",\n    ax=ax,\n)\n# ax.set_xlim([-60, 0])\n# ax.set_ylim([0, 70])\n\ncband_ds[\"time\"][0].dt.year.values","type":"content","url":"/retrieving-winds-with-pydda#pydda-visualization-routines","position":29},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib"},"type":"lvl1","url":"/baltrad2wradlib","position":0},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib"},"content":"Comparison between BALTRAD and wradlib attenuation correction\n\n","type":"content","url":"/baltrad2wradlib","position":1},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Retrieve data from s3 bucket"},"type":"lvl2","url":"/baltrad2wradlib#retrieve-data-from-s3-bucket","position":2},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Retrieve data from s3 bucket"},"content":"\n\nimport os\nimport urllib.request\nfrom pathlib import Path\n\n# Set the URL for the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = \"pythia/radar/erad2024/baltrad/baltrad2wradlib/\"\n!mkdir -p data\n!mkdir -p shp\nfiles = [\n    \"data/201405190715_SUR.h5\",\n    \"shp/europe_countries.dbf\",\n    \"shp/europe_countries.prj\",\n    \"shp/europe_countries.sbn\",\n    \"shp/europe_countries.sbx\",\n    \"shp/europe_countries.shp\",\n    \"shp/europe_countries.shx\",\n]\nfor file in files:\n    file0 = os.path.join(path, Path(file).name)\n    if not os.path.exists(file):\n        print(f\"downloading, {file}\")\n        x = urllib.request.urlretrieve(f\"{URL}{file0}\", file)\n\n","type":"content","url":"/baltrad2wradlib#retrieve-data-from-s3-bucket","position":3},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Prepare your environment"},"type":"lvl2","url":"/baltrad2wradlib#prepare-your-environment","position":4},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Prepare your environment"},"content":"\n\n%matplotlib inline\n\nimport gc\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport numpy as np\nimport shapefile\nimport wradlib\nimport xradar as xd\nfrom matplotlib.collections import PatchCollection\nfrom matplotlib.patches import Polygon\n\n","type":"content","url":"/baltrad2wradlib#prepare-your-environment","position":5},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Run BALTRAD’s odc_toolbox"},"type":"lvl2","url":"/baltrad2wradlib#run-baltrads-odc-toolbox","position":6},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Run BALTRAD’s odc_toolbox"},"content":"\n\nFirst, you will process a scan from Suergavere (Estland) by using BALTRAD’s odc_toolbox.\n\nFrom your VM’s vagrant directory, navigate to the folder /baltrad2wradlib.\n\nExecute the following command:\n\n$ odc_toolbox -i data -o out -q ropo,radvol-att\n\nCheck whether a file was created in the folder /out.\n\nBALTRAD will not create output files if these already exist. You can check that via !ls out.\n\n!odc_toolbox --help\n\n!odc_toolbox -i data -o out -q ropo,radvol-att\n\n!ls out\n\n","type":"content","url":"/baltrad2wradlib#run-baltrads-odc-toolbox","position":7},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Read and inspect data from Suergavere (Estonia) before and after QC with odc_toolbox"},"type":"lvl2","url":"/baltrad2wradlib#read-and-inspect-data-from-suergavere-estonia-before-and-after-qc-with-odc-toolbox","position":8},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Read and inspect data from Suergavere (Estonia) before and after QC with odc_toolbox"},"content":"\n\n# Before QC\ninp = xd.io.open_odim_datatree(\"data/201405190715_SUR.h5\")\n# After QC\nout = xd.io.open_odim_datatree(\"out/201405190715_SUR.h5\")\n\n","type":"content","url":"/baltrad2wradlib#read-and-inspect-data-from-suergavere-estonia-before-and-after-qc-with-odc-toolbox","position":9},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Georeference"},"type":"lvl2","url":"/baltrad2wradlib#georeference","position":10},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Georeference"},"content":"\n\ninp = inp.xradar.georeference()\nout = out.xradar.georeference()\n\nswp_inp = inp[\"sweep_0\"].ds.set_coords(\"sweep_mode\")\nswp_out = out[\"sweep_0\"].ds.set_coords(\"sweep_mode\")\ndisplay(swp_inp)\ndisplay(swp_out)\n\n","type":"content","url":"/baltrad2wradlib#georeference","position":11},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Design a plot we will use for all PPIs in this exercise"},"type":"lvl2","url":"/baltrad2wradlib#design-a-plot-we-will-use-for-all-ppis-in-this-exercise","position":12},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Design a plot we will use for all PPIs in this exercise"},"content":"\n\nimport cartopy.crs as ccrs\nimport wradlib as wrl\nfrom cartopy.io.shapereader import Reader\n\nmap_proj = ccrs.AzimuthalEquidistant(\n    central_latitude=swp_inp.latitude.values, central_longitude=swp_inp.longitude.values\n)\nosr_proj = wrl.georef.create_osr(\n    \"aeqd\", lat_0=swp_inp.latitude.values, lon_0=swp_inp.longitude.values\n)\n\ngeometries = list(Reader(\"shp/europe_countries.shp\").geometries())\n\n\ndef plot_ppi_to_ax(ppi, ax, title=\"\", geometries=None, **kwargs):\n    pm = ppi.wrl.vis.plot(crs=map_proj, ax=ax, **kwargs)\n    ax.set_title(title)\n    if geometries is not None:\n        ax.add_geometries(\n            geometries,\n            ccrs.PlateCarree(),\n            facecolor=\"lightgrey\",\n            edgecolor=\"k\",\n            linewidths=1,\n            zorder=-1,\n        )\n    wrl.vis.plot_ppi_crosshair(\n        site=(ppi.longitude.values, ppi.latitude.values, ppi.altitude.values),\n        ranges=[50000, 100000, 150000, 200000, ppi.range.max().values],\n        angles=[0, 90, 180, 270],\n        line=dict(color=\"white\"),\n        circle={\"edgecolor\": \"white\"},\n        ax=ax,\n        crs=osr_proj,\n    )\n    return pm\n\n","type":"content","url":"/baltrad2wradlib#design-a-plot-we-will-use-for-all-ppis-in-this-exercise","position":13},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Plot the selected fields into one figure"},"type":"lvl2","url":"/baltrad2wradlib#plot-the-selected-fields-into-one-figure","position":14},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Plot the selected fields into one figure"},"content":"\n\nfig = plt.figure(figsize=(12, 10))\n\nax = plt.subplot(221, projection=map_proj)\npm = plot_ppi_to_ax(\n    swp_inp.DBZH.where(swp_inp.DBZH >= -10),\n    ax=ax,\n    geometries=geometries,\n    title=\"Before QC\",\n    add_colorbar=False,\n    vmin=-10,\n    vmax=65,\n)\n\nax = plt.subplot(222, projection=map_proj)\npm = plot_ppi_to_ax(\n    swp_out.DBZH.where(swp_out.DBZH >= -10),\n    ax=ax,\n    geometries=geometries,\n    title=\"After QC\",\n    add_colorbar=False,\n    vmin=-10,\n    vmax=65,\n)\n\nax = plt.subplot(223, projection=map_proj)\nqm = plot_ppi_to_ax(\n    swp_out.quality1,\n    ax=ax,\n    geometries=geometries,\n    add_colorbar=False,\n    title=\"Quality 1\",\n)\n\nax = plt.subplot(224, projection=map_proj)\nqm = plot_ppi_to_ax(\n    swp_out.QIND, ax=ax, geometries=geometries, add_colorbar=False, title=\"Quality 2\"\n)\n\nplt.tight_layout()\n\n# Add colorbars\nfig.subplots_adjust(right=0.9)\ncax = fig.add_axes((0.9, 0.6, 0.03, 0.3))\ncbar = plt.colorbar(pm, cax=cax)\ncbar.set_label(\"Horizontal reflectivity (dBZ)\", fontsize=\"large\")\n\ncax = fig.add_axes((0.9, 0.1, 0.03, 0.3))\ncbar = plt.colorbar(qm, cax=cax)\ncbar.set_label(\"Quality index\", fontsize=\"large\")\n\n","type":"content","url":"/baltrad2wradlib#plot-the-selected-fields-into-one-figure","position":15},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Collect and plot the polarimetric moments from the original ODIM_H5 dataset"},"type":"lvl2","url":"/baltrad2wradlib#collect-and-plot-the-polarimetric-moments-from-the-original-odim-h5-dataset","position":16},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Collect and plot the polarimetric moments from the original ODIM_H5 dataset"},"content":"\n\nfig = plt.figure(figsize=(12, 12))\n\nax = plt.subplot(221, projection=map_proj)\npm = plot_ppi_to_ax(swp_inp.RHOHV, ax=ax, title=\"RhoHV\", geometries=geometries)\n\nax = plt.subplot(222, projection=map_proj)\npm = plot_ppi_to_ax(swp_inp.PHIDP, ax=ax, title=\"PhiDP\", geometries=geometries)\n\nax = plt.subplot(223, projection=map_proj)\npm = plot_ppi_to_ax(\n    swp_inp.ZDR, ax=ax, title=\"Differential reflectivity\", geometries=geometries\n)\n\nax = plt.subplot(224, projection=map_proj)\npm = plot_ppi_to_ax(\n    swp_inp.VRAD, ax=ax, title=\"Doppler velocity\", geometries=geometries\n)\n\nplt.tight_layout()\n\n","type":"content","url":"/baltrad2wradlib#collect-and-plot-the-polarimetric-moments-from-the-original-odim-h5-dataset","position":17},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Try some filtering and attenuation correction"},"type":"lvl2","url":"/baltrad2wradlib#try-some-filtering-and-attenuation-correction","position":18},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Try some filtering and attenuation correction"},"content":"\n\n# Set ZH to a very low value where we do not expect valid data\nzh = swp_inp.DBZH.fillna(-32.0)\n# Retrieve PIA by using some constraints (see https://docs.wradlib.org/en/latest/notebooks/attenuation/attenuation.html for help)\npia = zh.wrl.atten.correct_attenuation_constrained(\n    constraints=[wradlib.atten.constraint_dbz, wradlib.atten.constraint_pia],\n    constraint_args=[[64.0], [20.0]],\n)\n\n# Correct reflectivity by PIA\nzh_corrected = swp_inp.DBZH + pia\n\n","type":"content","url":"/baltrad2wradlib#try-some-filtering-and-attenuation-correction","position":19},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Compare results against QC from odc_toolbox"},"type":"lvl2","url":"/baltrad2wradlib#compare-results-against-qc-from-odc-toolbox","position":20},{"hierarchy":{"lvl1":"Attenuation correction comparison with wradlib","lvl2":"Compare results against QC from odc_toolbox"},"content":"\n\nfig = plt.figure(figsize=(18, 10))\n\nax = plt.subplot(131, projection=map_proj)\npm = plot_ppi_to_ax(\n    swp_inp.DBZH.where(swp_out.DBZH >= -10),\n    ax=ax,\n    geometries=geometries,\n    title=\"Before QC\",\n)\n\nax = plt.subplot(132, projection=map_proj)\npm = plot_ppi_to_ax(\n    swp_out.DBZH.where(swp_out.DBZH >= -10),\n    ax=ax,\n    geometries=geometries,\n    title=\"After QC using BALTRAD Toolbox\",\n)\n\nax = plt.subplot(133, projection=map_proj)\npm = plot_ppi_to_ax(\n    zh_corrected.where(zh_corrected >= -10),\n    ax=ax,\n    geometries=geometries,\n    title=\"After QC using wradlib\",\n)","type":"content","url":"/baltrad2wradlib#compare-results-against-qc-from-odc-toolbox","position":21},{"hierarchy":{"lvl1":"I/O model"},"type":"lvl1","url":"/baltrad-io","position":0},{"hierarchy":{"lvl1":"I/O model"},"content":"making sense out of data and metadata\n\n","type":"content","url":"/baltrad-io","position":1},{"hierarchy":{"lvl1":"I/O model","lvl2":"retrieve data from s3 bucket"},"type":"lvl2","url":"/baltrad-io#retrieve-data-from-s3-bucket","position":2},{"hierarchy":{"lvl1":"I/O model","lvl2":"retrieve data from s3 bucket"},"content":"\n\nimport os\nimport urllib.request\nfrom pathlib import Path\n\n# Set the URL for the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\n!mkdir -p data\nfiles = [\n    \"pythia/radar/erad2024/baltrad/baltrad_short_course/201405190715_SUR.h5\",\n]\nfor file in files:\n    name = os.path.join(\"data\", Path(file).name)\n    if not os.path.exists(name):\n        print(f\"downloading, {name}\")\n        urllib.request.urlretrieve(f\"{URL}{file}\", name)\n\n","type":"content","url":"/baltrad-io#retrieve-data-from-s3-bucket","position":3},{"hierarchy":{"lvl1":"I/O model","lvl2":"Import the file I/O module along with the main RAVE module containing useful constants"},"type":"lvl2","url":"/baltrad-io#import-the-file-i-o-module-along-with-the-main-rave-module-containing-useful-constants","position":4},{"hierarchy":{"lvl1":"I/O model","lvl2":"Import the file I/O module along with the main RAVE module containing useful constants"},"content":"\n\n%matplotlib inline\nimport _raveio, _rave\n\n","type":"content","url":"/baltrad-io#import-the-file-i-o-module-along-with-the-main-rave-module-containing-useful-constants","position":5},{"hierarchy":{"lvl1":"I/O model","lvl2":"Read an input ODIM_H5 file"},"type":"lvl2","url":"/baltrad-io#read-an-input-odim-h5-file","position":6},{"hierarchy":{"lvl1":"I/O model","lvl2":"Read an input ODIM_H5 file"},"content":"\n\nrio = _raveio.open(\"data/201405190715_SUR.h5\")\n\n","type":"content","url":"/baltrad-io#read-an-input-odim-h5-file","position":7},{"hierarchy":{"lvl1":"I/O model","lvl2":"What is the payload in the I/O container?"},"type":"lvl2","url":"/baltrad-io#what-is-the-payload-in-the-i-o-container","position":8},{"hierarchy":{"lvl1":"I/O model","lvl2":"What is the payload in the I/O container?"},"content":"\n\nrio.objectType is _rave.Rave_ObjectType_PVOL\n\n","type":"content","url":"/baltrad-io#what-is-the-payload-in-the-i-o-container","position":9},{"hierarchy":{"lvl1":"I/O model","lvl2":"How many scans does this volume contain?"},"type":"lvl2","url":"/baltrad-io#how-many-scans-does-this-volume-contain","position":10},{"hierarchy":{"lvl1":"I/O model","lvl2":"How many scans does this volume contain?"},"content":"\n\npvol = rio.object\nprint(\"%i scans in polar volume\" % pvol.getNumberOfScans())\n\n","type":"content","url":"/baltrad-io#how-many-scans-does-this-volume-contain","position":11},{"hierarchy":{"lvl1":"I/O model","lvl2":"Ascending or descending scan strategy?"},"type":"lvl2","url":"/baltrad-io#ascending-or-descending-scan-strategy","position":12},{"hierarchy":{"lvl1":"I/O model","lvl2":"Ascending or descending scan strategy?"},"content":"\n\npvol.isAscendingScans()\n\n","type":"content","url":"/baltrad-io#ascending-or-descending-scan-strategy","position":13},{"hierarchy":{"lvl1":"I/O model","lvl2":"Where is this site?"},"type":"lvl2","url":"/baltrad-io#where-is-this-site","position":14},{"hierarchy":{"lvl1":"I/O model","lvl2":"Where is this site?"},"content":"\n\n","type":"content","url":"/baltrad-io#where-is-this-site","position":15},{"hierarchy":{"lvl1":"I/O model","lvl3":"Note that all angles are represented internally in radians","lvl2":"Where is this site?"},"type":"lvl3","url":"/baltrad-io#note-that-all-angles-are-represented-internally-in-radians","position":16},{"hierarchy":{"lvl1":"I/O model","lvl3":"Note that all angles are represented internally in radians","lvl2":"Where is this site?"},"content":"\n\nfrom Proj import rd\n\nprint(\n    \"Site is located at %2.3f° lon, %2.3f° lat and %3.1f masl\"\n    % (pvol.longitude * rd, pvol.latitude * rd, pvol.height)\n)\nprint(\"Site's ODIM source identifiers are: %s\" % pvol.source)\n\n","type":"content","url":"/baltrad-io#note-that-all-angles-are-represented-internally-in-radians","position":17},{"hierarchy":{"lvl1":"I/O model","lvl2":"Access lowest scan and query some characteristics"},"type":"lvl2","url":"/baltrad-io#access-lowest-scan-and-query-some-characteristics","position":18},{"hierarchy":{"lvl1":"I/O model","lvl2":"Access lowest scan and query some characteristics"},"content":"\n\nscan = pvol.getScan(0)\nnrays, nbins = scan.nrays, scan.nbins\nprint(\"Elevation angle %2.1f°\" % (scan.elangle * rd))\nprint(\"%i rays per sweep\" % nrays)\nprint(\"%i bins per ray\" % nbins)\nprint(\"%3.1f meter range bins\" % scan.rscale)\nprint(\"First ray scanned is ray %i (indexing starts at 0)\" % scan.a1gate)\nprint(\"Data acquisition started on %s:%sZ\" % (scan.startdate, scan.starttime))\nprint(\"Data acquisition ended on %s:%sZ\" % (scan.enddate, scan.endtime))\nprint(\n    \"Scan contains %i quantities: %s\"\n    % (len(scan.getParameterNames()), scan.getParameterNames())\n)\n\n","type":"content","url":"/baltrad-io#access-lowest-scan-and-query-some-characteristics","position":19},{"hierarchy":{"lvl1":"I/O model","lvl2":"Access horizontal reflectivity and query some characteristics"},"type":"lvl2","url":"/baltrad-io#access-horizontal-reflectivity-and-query-some-characteristics","position":20},{"hierarchy":{"lvl1":"I/O model","lvl2":"Access horizontal reflectivity and query some characteristics"},"content":"\n\ndbzh = scan.getParameter(\"DBZH\")\nprint(\"Quantity is %s\" % dbzh.quantity)\nprint(\"8-bit unsigned byte data? %s\" % str(dbzh.datatype is _rave.RaveDataType_UCHAR))\nprint(\n    \"Linear scaling coefficients from 0-255 to dBZ: gain=%2.1f, offset=%2.1f\"\n    % (dbzh.gain, dbzh.offset)\n)\nprint(\n    \"Unradiated areas = %2.1f, radiated areas with no echo = %2.1f\"\n    % (dbzh.nodata, dbzh.undetect)\n)\n\ndbzh_data = dbzh.getData()  # Accesses the NumPy array containing the reflectivities\nprint(\n    \"NumPy array's dimensions = %s and type = %s\"\n    % (str(dbzh_data.shape), dbzh_data.dtype)\n)\n\n","type":"content","url":"/baltrad-io#access-horizontal-reflectivity-and-query-some-characteristics","position":21},{"hierarchy":{"lvl1":"I/O model","lvl2":"A primitive visualizer for plotting B-scans"},"type":"lvl2","url":"/baltrad-io#a-primitive-visualizer-for-plotting-b-scans","position":22},{"hierarchy":{"lvl1":"I/O model","lvl2":"A primitive visualizer for plotting B-scans"},"content":"\n\n# Convenience functionality. First convert a palette from GoogleMapsPlugin for use with matplotlib\nimport matplotlib\nfrom GmapColorMap import dbzh as pal\n\ncolorlist = []\nfor i in range(0, len(pal), 3):\n    colorlist.append([pal[i] / 255.0, pal[i + 1] / 255.0, pal[i + 2] / 255.0])\n\n# Then create a simple plotter\nimport matplotlib.pyplot as plt\n\n\ndef plot(data):\n    fig = plt.figure(figsize=(16, 12))\n    plt.title(\"B-scan\")\n    plt.imshow(data, cmap=matplotlib.colors.ListedColormap(colorlist), clim=(0, 255))\n    plt.colorbar(shrink=float(nrays) / nbins)\n\nplot(dbzh_data)\n\n","type":"content","url":"/baltrad-io#a-primitive-visualizer-for-plotting-b-scans","position":23},{"hierarchy":{"lvl1":"I/O model","lvl2":"Management of optional metadata"},"type":"lvl2","url":"/baltrad-io#management-of-optional-metadata","position":24},{"hierarchy":{"lvl1":"I/O model","lvl2":"Management of optional metadata"},"content":"\n\n","type":"content","url":"/baltrad-io#management-of-optional-metadata","position":25},{"hierarchy":{"lvl1":"I/O model","lvl3":"While manadatory metadata are represented as object attributes in Python, optional metadata are not!","lvl2":"Management of optional metadata"},"type":"lvl3","url":"/baltrad-io#while-manadatory-metadata-are-represented-as-object-attributes-in-python-optional-metadata-are-not","position":26},{"hierarchy":{"lvl1":"I/O model","lvl3":"While manadatory metadata are represented as object attributes in Python, optional metadata are not!","lvl2":"Management of optional metadata"},"content":"\n\nprint(\"Polar volume has %i optional attributes\" % len(pvol.getAttributeNames()))\nprint(\"Polar scan has %i optional attributes\" % len(scan.getAttributeNames()))\nprint(\n    \"Quantity %s has %i optional attributes\"\n    % (dbzh.quantity, len(dbzh.getAttributeNames()))\n)\n\nprint(\"Mandatory attribute: beamwidth is %2.1f°\" % (pvol.beamwidth * rd))\nprint(\n    \"Optional attributes: Radar is a %s running %s\"\n    % (pvol.getAttribute(\"how/system\"), pvol.getAttribute(\"how/software\"))\n)\n\n","type":"content","url":"/baltrad-io#while-manadatory-metadata-are-represented-as-object-attributes-in-python-optional-metadata-are-not","position":27},{"hierarchy":{"lvl1":"I/O model","lvl3":"Add a bogus attribute","lvl2":"Management of optional metadata"},"type":"lvl3","url":"/baltrad-io#add-a-bogus-attribute","position":28},{"hierarchy":{"lvl1":"I/O model","lvl3":"Add a bogus attribute","lvl2":"Management of optional metadata"},"content":"\n\ndbzh.addAttribute(\"how/foo\", \"bar\")\nprint(\n    \"Quantity %s now has %i optional attributes\"\n    % (dbzh.quantity, len(dbzh.getAttributeNames()))\n)\n\n","type":"content","url":"/baltrad-io#add-a-bogus-attribute","position":29},{"hierarchy":{"lvl1":"I/O model","lvl2":"Create an empty parameter and populate it"},"type":"lvl2","url":"/baltrad-io#create-an-empty-parameter-and-populate-it","position":30},{"hierarchy":{"lvl1":"I/O model","lvl2":"Create an empty parameter and populate it"},"content":"\n\nimport _polarscanparam\n\nparam = _polarscanparam.new()\nparam.quantity = \"DBZH\"\nparam.nodata, param.undetect = 255.0, 0.0\nparam.gain, param.offset = 0.4, -30.0\n\nimport numpy\n\ndata = numpy.zeros((420, 500), numpy.uint8)\nparam.setData(data)\n\n","type":"content","url":"/baltrad-io#create-an-empty-parameter-and-populate-it","position":31},{"hierarchy":{"lvl1":"I/O model","lvl2":"Create an empty scan and add the parameter to it"},"type":"lvl2","url":"/baltrad-io#create-an-empty-scan-and-add-the-parameter-to-it","position":32},{"hierarchy":{"lvl1":"I/O model","lvl2":"Create an empty scan and add the parameter to it"},"content":"\n\nimport _polarscan\nfrom Proj import dr\n\nnewscan = _polarscan.new()\nnewscan.elangle = 25.0 * dr\nnewscan.addAttribute(\"how/simulated\", \"True\")\n\nnewscan.addParameter(param)\nprint(\"%i rays per sweep\" % newscan.nrays)\nprint(\"%i bins per ray\" % newscan.nbins)\n\n","type":"content","url":"/baltrad-io#create-an-empty-scan-and-add-the-parameter-to-it","position":33},{"hierarchy":{"lvl1":"I/O model","lvl3":"See how the parameter’s dimensions were passed along to the scan, so they don’t have to be set explicitly. Nevertheless, plenty of metadata must be handled explicitly or ODIM_H5 files risk being incomplete.","lvl2":"Create an empty scan and add the parameter to it"},"type":"lvl3","url":"/baltrad-io#see-how-the-parameters-dimensions-were-passed-along-to-the-scan-so-they-dont-have-to-be-set-explicitly-nevertheless-plenty-of-metadata-must-be-handled-explicitly-or-odim-h5-files-risk-being-incomplete","position":34},{"hierarchy":{"lvl1":"I/O model","lvl3":"See how the parameter’s dimensions were passed along to the scan, so they don’t have to be set explicitly. Nevertheless, plenty of metadata must be handled explicitly or ODIM_H5 files risk being incomplete.","lvl2":"Create an empty scan and add the parameter to it"},"content":"\n\nnewscan.a1gate = 0\nnewscan.beamwidth = 1.0 * dr\nnewscan.rscale = 500.0\nnewscan.rstart = (\n    0.0  # Distance in meters to the start of the first range bin, unknown=0.0\n)\nnewscan.startdate = \"20140831\"\nnewscan.starttime = \"145005\"\nnewscan.enddate = \"20140831\"\nnewscan.endtime = \"145020\"\n\n# Top-level attributes\nnewscan.date = \"20140831\"\nnewscan.time = \"145000\"\nnewscan.source = \"WMO:26232,RAD:EE41,PLC:Sürgavere,NOD:eesur\"\nnewscan.longitude = 25.519 * dr\nnewscan.latitude = 58.482 * dr\nnewscan.height = 157.0\n\n","type":"content","url":"/baltrad-io#see-how-the-parameters-dimensions-were-passed-along-to-the-scan-so-they-dont-have-to-be-set-explicitly-nevertheless-plenty-of-metadata-must-be-handled-explicitly-or-odim-h5-files-risk-being-incomplete","position":35},{"hierarchy":{"lvl1":"I/O model","lvl2":"Now create a new I/O container and write the scan to ODIM_H5 file."},"type":"lvl2","url":"/baltrad-io#now-create-a-new-i-o-container-and-write-the-scan-to-odim-h5-file","position":36},{"hierarchy":{"lvl1":"I/O model","lvl2":"Now create a new I/O container and write the scan to ODIM_H5 file."},"content":"\n\ncontainer = _raveio.new()\ncontainer.object = newscan\ncontainer.save(\"data/myscan.h5\")\n\nimport os\n\nprint(\"ODIM_H5 file is %i bytes large\" % os.path.getsize(\"data/myscan.h5\"))\n\n","type":"content","url":"/baltrad-io#now-create-a-new-i-o-container-and-write-the-scan-to-odim-h5-file","position":37},{"hierarchy":{"lvl1":"I/O model","lvl3":"Remove compression. It makes file I/O faster. You can also tune HDF5 file-creation properties through the I/O container object.","lvl2":"Now create a new I/O container and write the scan to ODIM_H5 file."},"type":"lvl3","url":"/baltrad-io#remove-compression-it-makes-file-i-o-faster-you-can-also-tune-hdf5-file-creation-properties-through-the-i-o-container-object","position":38},{"hierarchy":{"lvl1":"I/O model","lvl3":"Remove compression. It makes file I/O faster. You can also tune HDF5 file-creation properties through the I/O container object.","lvl2":"Now create a new I/O container and write the scan to ODIM_H5 file."},"content":"\n\ncontainer.compression_level = 0  # ZLIB compression levels 0-9\ncontainer.save(\"data/myscan.h5\")\nprint(\"ODIM_H5 file is now %i bytes large\" % os.path.getsize(\"data/myscan.h5\"))","type":"content","url":"/baltrad-io#remove-compression-it-makes-file-i-o-faster-you-can-also-tune-hdf5-file-creation-properties-through-the-i-o-container-object","position":39},{"hierarchy":{"lvl1":"Quality Control"},"type":"lvl1","url":"/baltrad-qc","position":0},{"hierarchy":{"lvl1":"Quality Control"},"content":"","type":"content","url":"/baltrad-qc","position":1},{"hierarchy":{"lvl1":"Quality Control","lvl2":"retriev data from s3 bucket"},"type":"lvl2","url":"/baltrad-qc#retriev-data-from-s3-bucket","position":2},{"hierarchy":{"lvl1":"Quality Control","lvl2":"retriev data from s3 bucket"},"content":"\n\nimport os\nimport urllib.request\nfrom pathlib import Path\n\n# Set the URL for the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = \"pythia/radar/erad2024/baltrad/baltrad_short_course/\"\n!mkdir -p data\nfiles = [\"201405190715_SUR.h5\", \"plrze_pvol_20120205T0430Z.h5\", \"sekir.h5\"]\nfor file in files:\n    file0 = os.path.join(path, file)\n    name = os.path.join(\"data\", Path(file).name)\n    if not os.path.exists(name):\n        print(f\"downloading, {name}\")\n        urllib.request.urlretrieve(\n            f\"{URL}{file0}\", os.path.join(\"data\", Path(file).name)\n        )\n\n","type":"content","url":"/baltrad-qc#retriev-data-from-s3-bucket","position":3},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Import the file I/O module along with the main RAVE module containing useful constants"},"type":"lvl2","url":"/baltrad-qc#import-the-file-i-o-module-along-with-the-main-rave-module-containing-useful-constants","position":4},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Import the file I/O module along with the main RAVE module containing useful constants"},"content":"\n\n%matplotlib inline\nimport matplotlib\nimport _raveio, _rave\n\n","type":"content","url":"/baltrad-qc#import-the-file-i-o-module-along-with-the-main-rave-module-containing-useful-constants","position":5},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Read an input ODIM_H5 file"},"type":"lvl2","url":"/baltrad-qc#read-an-input-odim-h5-file","position":6},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Read an input ODIM_H5 file"},"content":"\n\nrio = _raveio.open(\"data/201405190715_SUR.h5\")\n\n","type":"content","url":"/baltrad-qc#read-an-input-odim-h5-file","position":7},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Create a simple plotter for B-scans, elaborating the example from the I/O exercise"},"type":"lvl2","url":"/baltrad-qc#create-a-simple-plotter-for-b-scans-elaborating-the-example-from-the-i-o-exercise","position":8},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Create a simple plotter for B-scans, elaborating the example from the I/O exercise"},"content":"\n\n# Two color palettes, one used in GoogleMapsPlugin, and the other from RAVE\nfrom GmapColorMap import dbzh as dbzp\nfrom rave_win_colors import continuous_MS as vradp\n\n\n# Convert a 768-list palette to a matplotlib colorlist\ndef make_colorlist(pal):\n    colorlist = []\n    for i in range(0, len(pal), 3):\n        colorlist.append([pal[i] / 255.0, pal[i + 1] / 255.0, pal[i + 2] / 255.0])\n    return colorlist\n\n\n# Convert lists to colormaps\ndbzcl = make_colorlist(dbzp)\nvradcl = make_colorlist(vradp)\n\n# Then create a simple plotter\nimport matplotlib.pyplot as plt\n\n# from types import StringType\nStringType = type(\"\")\n\n\ndef plot(data, colorlist=dbzcl, title=\"B-scan\"):\n    mini, maxi = data.shape.index(min(data.shape)), data.shape.index(max(data.shape))\n    figsize = (16, 12) if mini == 0 else (12, 8)\n    fig = plt.figure(figsize=figsize)\n    plt.title(title)\n    clist = (\n        colorlist\n        if type(colorlist) == StringType\n        else matplotlib.colors.ListedColormap(colorlist)\n    )\n    plt.imshow(data, cmap=clist, clim=(0, 255))\n    plt.colorbar(shrink=float(data.shape[mini]) / data.shape[maxi])\n\n","type":"content","url":"/baltrad-qc#create-a-simple-plotter-for-b-scans-elaborating-the-example-from-the-i-o-exercise","position":9},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Access the polar volume and plot VRAD data from the lowest scan"},"type":"lvl2","url":"/baltrad-qc#access-the-polar-volume-and-plot-vrad-data-from-the-lowest-scan","position":10},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Access the polar volume and plot VRAD data from the lowest scan"},"content":"\n\npvol = rio.object\nplot(pvol.getScan(0).getParameter(\"VRADH\").getData(), vradcl, \"Original VRAD\")\n\n","type":"content","url":"/baltrad-qc#access-the-polar-volume-and-plot-vrad-data-from-the-lowest-scan","position":11},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Dealias the volume"},"type":"lvl2","url":"/baltrad-qc#dealias-the-volume","position":12},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Dealias the volume"},"content":"\n\nimport _dealias\n\nret = _dealias.dealias(pvol)\n\n","type":"content","url":"/baltrad-qc#dealias-the-volume","position":13},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Check whether the first scan’s been dealiased","lvl2":"Dealias the volume"},"type":"lvl3","url":"/baltrad-qc#check-whether-the-first-scans-been-dealiased","position":14},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Check whether the first scan’s been dealiased","lvl2":"Dealias the volume"},"content":"\n\nprint(\"This first scan is dealiased: %s\" % str(_dealias.dealiased(pvol.getScan(0))))\n\n","type":"content","url":"/baltrad-qc#check-whether-the-first-scans-been-dealiased","position":15},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Replot for comparison","lvl2":"Dealias the volume"},"type":"lvl3","url":"/baltrad-qc#replot-for-comparison","position":16},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Replot for comparison","lvl2":"Dealias the volume"},"content":"\n\nplot(pvol.getScan(0).getParameter(\"VRADH\").getData(), vradcl, \"Dealiased VRAD\")\n\n","type":"content","url":"/baltrad-qc#replot-for-comparison","position":17},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Shift gears - back to reflectivity"},"type":"lvl2","url":"/baltrad-qc#shift-gears-back-to-reflectivity","position":18},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Shift gears - back to reflectivity"},"content":"\n\nrio = _raveio.open(\"data/plrze_pvol_20120205T0430Z.h5\")\npvol = rio.object\nplot(pvol.getScan(0).getParameter(\"DBZH\").getData(), title=\"Original DBZH\")\n\n","type":"content","url":"/baltrad-qc#shift-gears-back-to-reflectivity","position":19},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Use the bRopo package’s quality plugin to identify and remove non-precipitation echoes"},"type":"lvl2","url":"/baltrad-qc#use-the-bropo-packages-quality-plugin-to-identify-and-remove-non-precipitation-echoes","position":20},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Use the bRopo package’s quality plugin to identify and remove non-precipitation echoes"},"content":"\n\nimport odc_polarQC\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")  # Suppress SyntaxWarning from Python2 code\n\nodc_polarQC.algorithm_ids = [\"ropo\"]\npvol = odc_polarQC.QC(pvol)\n\n","type":"content","url":"/baltrad-qc#use-the-bropo-packages-quality-plugin-to-identify-and-remove-non-precipitation-echoes","position":21},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Plot the resulting DBZH","lvl2":"Use the bRopo package’s quality plugin to identify and remove non-precipitation echoes"},"type":"lvl3","url":"/baltrad-qc#plot-the-resulting-dbzh","position":22},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Plot the resulting DBZH","lvl2":"Use the bRopo package’s quality plugin to identify and remove non-precipitation echoes"},"content":"\n\nplot(pvol.getScan(0).getParameter(\"DBZH\").getData(), title=\"DBZH after bRopo\")\n\n","type":"content","url":"/baltrad-qc#plot-the-resulting-dbzh","position":23},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Topographical beam-blockage QC using the beamb package’s quality plugin"},"type":"lvl2","url":"/baltrad-qc#topographical-beam-blockage-qc-using-the-beamb-packages-quality-plugin","position":24},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Topographical beam-blockage QC using the beamb package’s quality plugin"},"content":"\n\nimport time\n\nodc_polarQC.algorithm_ids = [\"beamb\"]\nbefore = time.time()\npvol = odc_polarQC.QC(pvol)\nafter = time.time()\nprint(\"beamb runtime = %2.2f seconds\" % (after - before))\n\n","type":"content","url":"/baltrad-qc#topographical-beam-blockage-qc-using-the-beamb-packages-quality-plugin","position":25},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Probability of overshooting"},"type":"lvl2","url":"/baltrad-qc#probability-of-overshooting","position":26},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Probability of overshooting"},"content":"\n\nodc_polarQC.algorithm_ids = [\"rave-overshooting\"]\npvol = odc_polarQC.QC(pvol)\n\n","type":"content","url":"/baltrad-qc#probability-of-overshooting","position":27},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Accessing and manging data quality fields"},"type":"lvl2","url":"/baltrad-qc#accessing-and-manging-data-quality-fields","position":28},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Accessing and manging data quality fields"},"content":"\n\nscan = pvol.getScan(0)\nprint(\"Scan contains %i quality fields\" % scan.getNumberOfQualityFields())\n\nfor i in range(scan.getNumberOfQualityFields()):\n    qf = scan.getQualityField(i)\n    print(\"Quality field %i has identifier %s\" % (i, qf.getAttribute(\"how/task\")))\n\n","type":"content","url":"/baltrad-qc#accessing-and-manging-data-quality-fields","position":29},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Plot quality fields"},"type":"lvl2","url":"/baltrad-qc#plot-quality-fields","position":30},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Plot quality fields"},"content":"\n\n","type":"content","url":"/baltrad-qc#plot-quality-fields","position":31},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Beam blockage","lvl2":"Plot quality fields"},"type":"lvl3","url":"/baltrad-qc#beam-blockage","position":32},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Beam blockage","lvl2":"Plot quality fields"},"content":"\n\nbb = scan.getQualityFieldByHowTask(\"se.smhi.detector.beamblockage\")\nplot(bb.getData(), \"binary\", \"Quality indicator for beam blockage\")\n\n","type":"content","url":"/baltrad-qc#beam-blockage","position":33},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Probability of non-precipitation","lvl2":"Plot quality fields"},"type":"lvl3","url":"/baltrad-qc#probability-of-non-precipitation","position":34},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Probability of non-precipitation","lvl2":"Plot quality fields"},"content":"\n\nbb = scan.getQualityFieldByHowTask(\"fi.fmi.ropo.detector.classification\")\nplot(bb.getData(), \"binary\", \"Quality indicator for ropo\")\n\n","type":"content","url":"/baltrad-qc#probability-of-non-precipitation","position":35},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Probability of overshooting","lvl2":"Plot quality fields"},"type":"lvl3","url":"/baltrad-qc#probability-of-overshooting-1","position":36},{"hierarchy":{"lvl1":"Quality Control","lvl3":"Probability of overshooting","lvl2":"Plot quality fields"},"content":"\n\nbb = scan.getQualityFieldByHowTask(\"se.smhi.detector.poo\")\nplot(bb.getData(), \"binary\", \"Quality indicator for PoO\")\n\n","type":"content","url":"/baltrad-qc#probability-of-overshooting-1","position":37},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Chaining algorithms - new data"},"type":"lvl2","url":"/baltrad-qc#chaining-algorithms-new-data","position":38},{"hierarchy":{"lvl1":"Quality Control","lvl2":"Chaining algorithms - new data"},"content":"\n\nrio = _raveio.open(\"data/sekir.h5\")\npvol = rio.object\n\nodc_polarQC.algorithm_ids = [\n    \"ropo\",\n    \"beamb\",\n    \"radvol-att\",\n    \"radvol-broad\",\n    \"rave-overshooting\",\n]\npvol = odc_polarQC.QC(pvol)\n\nscan = pvol.getScan(0)\natt = scan.getQualityField(2)\nplot(att.getData(), \"binary\", \"Attenuation\")\n\n","type":"content","url":"/baltrad-qc#chaining-algorithms-new-data","position":39},{"hierarchy":{"lvl1":"Quality Control","lvl2":"“Total Quality”"},"type":"lvl2","url":"/baltrad-qc#total-quality","position":40},{"hierarchy":{"lvl1":"Quality Control","lvl2":"“Total Quality”"},"content":"\n\nodc_polarQC.algorithm_ids = [\"qi-total\"]\npvol = odc_polarQC.QC(pvol)\n\nqitot = scan.getQualityField(5)\nplot(qitot.getData(), \"binary\", \"Total quality index\")","type":"content","url":"/baltrad-qc#total-quality","position":41},{"hierarchy":{"lvl1":"Quality Control using DR"},"type":"lvl1","url":"/baltrad-drqc","position":0},{"hierarchy":{"lvl1":"Quality Control using DR"},"content":"In this notebook, we will use the depolarization ratio to quality control a volume of data from the new radar at Radisson, Saskatchewan\n\nWe will also visualize the data using some openly-available colour tables.\n\nThis notebook was originally prepared using material subsequently published in \n\nMichelson et al. (2020)\n\n","type":"content","url":"/baltrad-drqc","position":1},{"hierarchy":{"lvl1":"Quality Control using DR","lvl2":"retrieve data from s3 bucket"},"type":"lvl2","url":"/baltrad-drqc#retrieve-data-from-s3-bucket","position":2},{"hierarchy":{"lvl1":"Quality Control using DR","lvl2":"retrieve data from s3 bucket"},"content":"\n\nimport os\nimport urllib.request\nfrom pathlib import Path\n\n# Set the URL for the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = \"pythia/radar/erad2024/baltrad/baltrad_short_course/\"\n!mkdir -p data\nfiles = [\n    \"2019051509_00_ODIMH5_PVOL6S_VOL_casra.16.h5\",\n    \"hawaii.txt\",\n    \"moleron.txt\",\n    \"oleron.txt\",\n    \"mroma.txt\",\n    \"vik.txt\",\n]\nfor file in files:\n    file0 = os.path.join(path, file)\n    name = os.path.join(\"data\", Path(file).name)\n    if not os.path.exists(name):\n        print(f\"downloading, {name}\")\n        urllib.request.urlretrieve(f\"{URL}{file0}\", name)\n\nimport _raveio\nimport ropo_realtime, ec_drqc\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport GmapColorMap\n\n","type":"content","url":"/baltrad-drqc#retrieve-data-from-s3-bucket","position":3},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Block of look-ups for display","lvl2":"retrieve data from s3 bucket"},"type":"lvl3","url":"/baltrad-drqc#block-of-look-ups-for-display","position":4},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Block of look-ups for display","lvl2":"retrieve data from s3 bucket"},"content":"\n\nPALETTE = {}  # To be populated\n\nUNDETECT = {\n    \"TH\": GmapColorMap.PUREWHITE,\n    \"DBZH\": GmapColorMap.PUREWHITE,\n    \"DR\": GmapColorMap.PUREWHITE,\n    \"VRADH\": GmapColorMap.GREY5,\n    \"RHOHV\": GmapColorMap.PUREWHITE,\n    \"ZDR\": GmapColorMap.PUREWHITE,\n}\n\nNODATA = {\n    \"TH\": GmapColorMap.WEBSAFEGREY,\n    \"DBZH\": GmapColorMap.WEBSAFEGREY,\n    \"DR\": GmapColorMap.WEBSAFEGREY,\n    \"VRADH\": GmapColorMap.GREY8,\n    \"RHOHV\": GmapColorMap.WEBSAFEGREY,\n    \"ZDR\": GmapColorMap.WEBSAFEGREY,\n}\n\nLEGEND = {\n    \"TH\": \"Radar reflectivity factor (dBZ)\",\n    \"DBZH\": \"Radar reflectivity factor (dBZ)\",\n    \"DR\": \"Depolarization ratio (dB)\",\n    \"VRADH\": \"Radial wind velocity away from radar (m/s)\",\n    \"RHOHV\": \"Cross-polar correlation coefficient\",\n    \"ZDR\": \"Differential reflectivity (dB)\",\n}\n\nTICKS = {\n    \"TH\": range(-30, 80, 10),\n    \"DBZH\": range(-30, 80, 10),\n    \"ZDR\": range(-8, 9, 2),\n    \"RHOHV\": np.arange(0, 11, 1) / 10.0,\n    \"VRADH\": range(-48, 56, 8),\n    \"DR\": range(-36, 3, 3),\n}\n\n","type":"content","url":"/baltrad-drqc#block-of-look-ups-for-display","position":5},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Colormap loader and loads","lvl2":"retrieve data from s3 bucket"},"type":"lvl3","url":"/baltrad-drqc#colormap-loader-and-loads","position":6},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Colormap loader and loads","lvl2":"retrieve data from s3 bucket"},"content":"\n\ndef loadPal(fstr, reverse=True):\n    fd = open(fstr)\n    LINES = fd.readlines()\n    fd.close()\n    pal = []\n    for line in LINES:\n        s = line.split()\n        if reverse:\n            s.reverse()\n        for val in s:\n            pal.append(int(float(val) * 255))\n    if reverse:\n        pal.reverse()\n    return pal\n\n\n# Colour maps by Fabio Crameri, http://www.fabiocrameri.ch/colourmaps.php, a couple of them modified\n# Todo: maybe use new cmweather colormaps\nPALETTE[\"DBZH\"] = loadPal(\"data/hawaii.txt\")\nPALETTE[\"DR\"] = loadPal(\"data/moleron.txt\", False)  # Modified oleron\nPALETTE[\"ZDR\"] = loadPal(\"data/oleron.txt\", False)\nPALETTE[\"RHOHV\"] = loadPal(\"data/mroma.txt\")  # Modified roma\nPALETTE[\"VRADH\"] = loadPal(\"data/vik.txt\", False)\n\n","type":"content","url":"/baltrad-drqc#colormap-loader-and-loads","position":7},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Set up the display","lvl2":"retrieve data from s3 bucket"},"type":"lvl3","url":"/baltrad-drqc#set-up-the-display","position":8},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Set up the display","lvl2":"retrieve data from s3 bucket"},"content":"\n\ndef plot(obj):\n    fig = plt.figure()\n    default_size = fig.get_size_inches()\n    fig.set_size_inches((default_size[0] * 2, default_size[1] * 2))\n\n    paramname = obj.getParameterNames()[0]\n    pal = PALETTE[paramname]\n    pal[0], pal[1], pal[2] = UNDETECT[\n        paramname\n    ]  # Special value - areas radiated but void of echo\n    pal[767], pal[766], pal[765] = NODATA[paramname]  # Special value - areas unradiated\n    if paramname == \"VRADH\":\n        pal[379], pal[380], pal[381] = GmapColorMap.PUREWHITE  # VRADH isodop\n        pal[382], pal[383], pal[384] = GmapColorMap.PUREWHITE  # VRADH isodop\n        pal[385], pal[386], pal[387] = GmapColorMap.PUREWHITE  # VRADH isodop\n    colorlist = []\n    for i in range(0, len(pal), 3):\n        colorlist.append([pal[i] / 255.0, pal[i + 1] / 255.0, pal[i + 2] / 255.0])\n\n    param = obj.getParameter(paramname)\n    data = param.getData()\n    data = data * param.gain + param.offset\n\n    im = plt.imshow(data, cmap=matplotlib.colors.ListedColormap(colorlist))\n    cax = plt.gca()\n    cax.axes.get_xaxis().set_visible(False)\n    cax.axes.get_yaxis().set_visible(False)\n\n    cb = plt.colorbar(ticks=TICKS[paramname])\n    cb.set_label(LEGEND[paramname])\n\n    plt.show()\n\n","type":"content","url":"/baltrad-drqc#set-up-the-display","position":9},{"hierarchy":{"lvl1":"Quality Control using DR","lvl2":"Do the science"},"type":"lvl2","url":"/baltrad-drqc#do-the-science","position":10},{"hierarchy":{"lvl1":"Quality Control using DR","lvl2":"Do the science"},"content":"","type":"content","url":"/baltrad-drqc#do-the-science","position":11},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Read the polar volume, QC the reflectivity using legacy ROPO, and then save the QC:ed result","lvl2":"Do the science"},"type":"lvl3","url":"/baltrad-drqc#read-the-polar-volume-qc-the-reflectivity-using-legacy-ropo-and-then-save-the-qc-ed-result","position":12},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Read the polar volume, QC the reflectivity using legacy ROPO, and then save the QC:ed result","lvl2":"Do the science"},"content":"\n\nrio = _raveio.open(\"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.16.h5\")\nrio.object = ropo_realtime.generate(rio.object)\nrio.save(\"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.ropo.h5\")\n\n","type":"content","url":"/baltrad-drqc#read-the-polar-volume-qc-the-reflectivity-using-legacy-ropo-and-then-save-the-qc-ed-result","position":13},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Re-read the polar volume, QC it using depolarization ratio, and then save the QC:ed result","lvl2":"Do the science"},"type":"lvl3","url":"/baltrad-drqc#re-read-the-polar-volume-qc-it-using-depolarization-ratio-and-then-save-the-qc-ed-result","position":14},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Re-read the polar volume, QC it using depolarization ratio, and then save the QC:ed result","lvl2":"Do the science"},"content":"\n\nrio = _raveio.open(\"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.16.h5\")\npvol = rio.object\nec_drqc.drQC(pvol)\nrio.object = pvol\nrio.save(\"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.drqc.h5\")\n\n","type":"content","url":"/baltrad-drqc#re-read-the-polar-volume-qc-it-using-depolarization-ratio-and-then-save-the-qc-ed-result","position":15},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Create, read and display CAPPIs, starting with Doppler-corrected reflectivity","lvl2":"Do the science"},"type":"lvl3","url":"/baltrad-drqc#create-read-and-display-cappis-starting-with-doppler-corrected-reflectivity","position":16},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Create, read and display CAPPIs, starting with Doppler-corrected reflectivity","lvl2":"Do the science"},"content":"\n\n!radarcomp -i \"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.16.h5\" -o data/cappi_DBZH.h5 -s 1000 -T -M\n\ncappi = _raveio.open(\"data/cappi_DBZH.h5\").object\nplot(cappi)\n\n","type":"content","url":"/baltrad-drqc#create-read-and-display-cappis-starting-with-doppler-corrected-reflectivity","position":17},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Differential reflectivity","lvl2":"Do the science"},"type":"lvl3","url":"/baltrad-drqc#differential-reflectivity","position":18},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Differential reflectivity","lvl2":"Do the science"},"content":"\n\n!radarcomp -i \"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.16.h5\" -o data/cappi_ZDR.h5 -s 1000.0 -T -M -q ZDR -g 0.0629921 -O -8.0\n\ncappi = _raveio.open(\"data/cappi_ZDR.h5\").object\nplot(cappi)\n\n","type":"content","url":"/baltrad-drqc#differential-reflectivity","position":19},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Cross-polar correlation coefficient","lvl2":"Do the science"},"type":"lvl3","url":"/baltrad-drqc#cross-polar-correlation-coefficient","position":20},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Cross-polar correlation coefficient","lvl2":"Do the science"},"content":"\n\n!radarcomp -i \"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.16.h5\" -o data/cappi_RHOHV.h5 -s 1000.0 -T -M -q RHOHV -g 0.00393701 -O 0.0\n\ncappi = _raveio.open(\"data/cappi_RHOHV.h5\").object\nplot(cappi)\n\n","type":"content","url":"/baltrad-drqc#cross-polar-correlation-coefficient","position":21},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Radial wind velocity, lowest PPI","lvl2":"Do the science"},"type":"lvl3","url":"/baltrad-drqc#radial-wind-velocity-lowest-ppi","position":22},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Radial wind velocity, lowest PPI","lvl2":"Do the science"},"content":"\n\n!radarcomp -i \"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.16.h5\" -o data/ppi_VRADH.h5 -s 1000.0 -T -M -q VRADH -g 0.37716537714004517 -O -48. -p PPI -P 0.4\n\nppi = _raveio.open(\"data/ppi_VRADH.h5\").object\nplot(ppi)\n\n","type":"content","url":"/baltrad-drqc#radial-wind-velocity-lowest-ppi","position":23},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Depolarization ratio","lvl2":"Do the science"},"type":"lvl3","url":"/baltrad-drqc#depolarization-ratio","position":24},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"Depolarization ratio","lvl2":"Do the science"},"content":"\n\n!radarcomp -i \"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.drqc.h5\" -o data/cappi_DR.h5 -s 1000 -T -M -q DR -g 0.129951 -O -33.1376\n\ncappi = _raveio.open(\"data/cappi_DR.h5\").object\nplot(cappi)\n\n","type":"content","url":"/baltrad-drqc#depolarization-ratio","position":25},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"ROPO:ed reflectivity","lvl2":"Do the science"},"type":"lvl3","url":"/baltrad-drqc#ropo-ed-reflectivity","position":26},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"ROPO:ed reflectivity","lvl2":"Do the science"},"content":"\n\n!radarcomp -i \"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.ropo.h5\" -o data/cappi_DBZH_ropo.h5 -s 1000 -T -M\n\ncappi = _raveio.open(\"data/cappi_DBZH_ropo.h5\").object\nplot(cappi)\n\n","type":"content","url":"/baltrad-drqc#ropo-ed-reflectivity","position":27},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"DRQC:ed reflectivity","lvl2":"Do the science"},"type":"lvl3","url":"/baltrad-drqc#drqc-ed-reflectivity","position":28},{"hierarchy":{"lvl1":"Quality Control using DR","lvl3":"DRQC:ed reflectivity","lvl2":"Do the science"},"content":"\n\n!radarcomp -i \"data/2019051509_00_ODIMH5_PVOL6S_VOL_casra.drqc.h5\" -o data/cappi_DBZH_drqc.h5 -s 1000 -T -M\n\ncappi = _raveio.open(\"data/cappi_DBZH_drqc.h5\").object\nplot(cappi)","type":"content","url":"/baltrad-drqc#drqc-ed-reflectivity","position":29},{"hierarchy":{"lvl1":"Parallel processing"},"type":"lvl1","url":"/baltrad-parallel-processing","position":0},{"hierarchy":{"lvl1":"Parallel processing"},"content":"The default VM setup is to use a single CPU core. In order to demonstrate the power of parallel processing, you must first determine whether your physical hardware has more than a single core.\n\nOn Linux this is done in the terminal with the ‘nproc’ command.\n\nOn Mac this is done in the terminal with the ‘sysctl -n hw.ncpu’ command.\n\nOn Windows this is done graphically using the Task Manager’s Performance tab.\n\nWe want tune our VM to harness the power of several CPUs. Follow the following steps:\n\nShut down the IPython notebook Server (Ctrl-C, answer yes)\n\nShutdown the VM (click the X button in the VM window, choose power down the machine)\n\nSelect the VM in the VirtualBox Manager Window, from the menu choose Machine->Setting\n\nChoose the System Tab, then Processor, use the slider to set the number of Processor to 2, 4, or 8 depending on your system resources.\n\nClick Ok, and then start the machine\n\nLogin, use the start_notebook.sh script to start the IPython server, start the notebook and you should have multiple processors!\n\nRELOAD THIS PAGE!\n\n","type":"content","url":"/baltrad-parallel-processing","position":1},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"retrieve data from s3 bucket"},"type":"lvl2","url":"/baltrad-parallel-processing#retrieve-data-from-s3-bucket","position":2},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"retrieve data from s3 bucket"},"content":"\n\nimport os\nimport urllib.request\nfrom pathlib import Path\n\n# Set the URL for the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = \"pythia/radar/erad2024/baltrad/baltrad_short_course/\"\n!mkdir -p data\nfiles = [\n    \"seang.h5\",\n    \"searl.h5\",\n    \"sease.h5\",\n    \"sehud.h5\",\n    \"sekir.h5\",\n    \"sekkr.h5\",\n    \"selek.h5\",\n    \"selul.h5\",\n    \"seosu.h5\",\n    \"sevar.h5\",\n    \"sevil.h5\",\n]\nfor file in files:\n    file0 = os.path.join(path, file)\n    name = os.path.join(\"data\", Path(file).name)\n    if not os.path.exists(name):\n        print(f\"downloading, {name}\")\n        urllib.request.urlretrieve(\n            f\"{URL}{file0}\", os.path.join(\"data\", Path(file).name)\n        )\n\n","type":"content","url":"/baltrad-parallel-processing#retrieve-data-from-s3-bucket","position":3},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"Verify from Python the number of CPU cores at our disposal"},"type":"lvl2","url":"/baltrad-parallel-processing#verify-from-python-the-number-of-cpu-cores-at-our-disposal","position":4},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"Verify from Python the number of CPU cores at our disposal"},"content":"\n\nimport multiprocessing\n\nprint(\"We have %i cores to play with!\" % multiprocessing.cpu_count())\n\nYay! Now we’re going to set up some rudimentary functionality that will allow us to distribute a processing load among our cores.\n\n","type":"content","url":"/baltrad-parallel-processing#verify-from-python-the-number-of-cpu-cores-at-our-disposal","position":5},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"Define a generator"},"type":"lvl2","url":"/baltrad-parallel-processing#define-a-generator","position":6},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"Define a generator"},"content":"\n\nimport os\nimport _raveio, odc_polarQC\n\n# Specify the processing chain\nodc_polarQC.algorithm_ids = [\n    \"ropo\",\n    \"beamb\",\n    \"radvol-att\",\n    \"radvol-broad\",\n    \"rave-overshooting\",\n    \"qi-total\",\n]\n\n\n# Run processing chain on a single file. Return an output file string.\ndef generate(file_string):\n    rio = _raveio.open(file_string)\n\n    pvol = rio.object\n    pvol = odc_polarQC.QC(pvol)\n    rio.object = pvol\n\n    # Derive an output file name\n    path, fstr = os.path.split(file_string)\n    ofstr = os.path.join(path, \"qc_\" + fstr)\n\n    rio.save(ofstr)\n    return ofstr\n\n","type":"content","url":"/baltrad-parallel-processing#define-a-generator","position":7},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"Feed the generator, sequentially"},"type":"lvl2","url":"/baltrad-parallel-processing#feed-the-generator-sequentially","position":8},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"Feed the generator, sequentially"},"content":"\n\nimport glob, time\n\nifstrs = glob.glob(\"data/se*.h5\")\nbefore = time.time()\nfor fstr in ifstrs:\n    print(fstr, generate(fstr))\nafter = time.time()\n\nprint(\"Processing time: %3.2f seconds\" % (after - before))\n\nMental note: repeat once!\n\n","type":"content","url":"/baltrad-parallel-processing#feed-the-generator-sequentially","position":9},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"Multiprocess the generator"},"type":"lvl2","url":"/baltrad-parallel-processing#multiprocess-the-generator","position":10},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"Multiprocess the generator"},"content":"\n\n# Both input and output are a list of file strings\ndef multi_generate(fstrs, procs=None):\n    pool = multiprocessing.Pool(\n        procs\n    )  # Pool of processors. Defaults to all available logical cores\n\n    results = []\n    # chunksize=1 means feed a process a new job as soon as the process is idle.\n    # In our case, this restricts the queue to one \"dispatcher\" which is faster.\n    r = pool.map_async(generate, fstrs, chunksize=1, callback=results.append)\n    r.wait()\n\n    return results[0]\n\n","type":"content","url":"/baltrad-parallel-processing#multiprocess-the-generator","position":11},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"Feed the monster, asynchronously!"},"type":"lvl2","url":"/baltrad-parallel-processing#feed-the-monster-asynchronously","position":12},{"hierarchy":{"lvl1":"Parallel processing","lvl2":"Feed the monster, asynchronously!"},"content":"\n\nbefore = time.time()\nofstrs = multi_generate(ifstrs)\nafter = time.time()\n\nprint(\"Processing time: %3.2f seconds\" % (after - before))","type":"content","url":"/baltrad-parallel-processing#feed-the-monster-asynchronously","position":13},{"hierarchy":{"lvl1":"Compositing"},"type":"lvl1","url":"/baltrad-compositing","position":0},{"hierarchy":{"lvl1":"Compositing"},"content":"This exercise builds on output from the parallel processing exercise. It does not address how projections and navigation is dealt with in BALTRAD. This should be addressed in a separate exercise.\n\nThe Cartesian product area used in this exercise is pre-configured and looked up from a registry.\n\n","type":"content","url":"/baltrad-compositing","position":1},{"hierarchy":{"lvl1":"Compositing","lvl2":"Rudimentary composite"},"type":"lvl2","url":"/baltrad-compositing#rudimentary-composite","position":2},{"hierarchy":{"lvl1":"Compositing","lvl2":"Rudimentary composite"},"content":"\n\n%matplotlib inline\nimport glob, time\nimport matplotlib\nimport _raveio, _rave\nimport _pycomposite, compositing\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")  # Suppress SyntaxWarning from Python2 code\n\ngenerator = compositing.compositing()\ngenerator.filenames = glob.glob(\"data/se*.h5\")\n\n# Run with all defaults to a pre-configured area that uses the Google Maps projection.\n# First two arguments are product date and time. These are taken from the last input file if not specified.\nbefore = time.time()\ncomp = generator.generate(None, None, area=\"swegmaps_2000\")\nafter = time.time()\n\nrio = _raveio.new()\nrio.object = comp\nrio.save(\"data/comp_pcappi1000m.h5\")\n\nprint(\"Compositing took %3.2f seconds\" % (after - before))\n\n","type":"content","url":"/baltrad-compositing#rudimentary-composite","position":3},{"hierarchy":{"lvl1":"Compositing","lvl2":"Tweak the plotter from earlier exercises"},"type":"lvl2","url":"/baltrad-compositing#tweak-the-plotter-from-earlier-exercises","position":4},{"hierarchy":{"lvl1":"Compositing","lvl2":"Tweak the plotter from earlier exercises"},"content":"\n\n# Two color palettes, one used in GoogleMapsPlugin, and the other from RAVE\nfrom GmapColorMap import dbzh as dbzp\n\n\n# Convert a 768-list palette to a matplotlib colorlist\ndef make_colorlist(pal):\n    colorlist = []\n    for i in range(0, len(pal), 3):\n        colorlist.append([pal[i] / 255.0, pal[i + 1] / 255.0, pal[i + 2] / 255.0])\n    return colorlist\n\n\n# Convert lists to colormaps\ndbzcl = make_colorlist(dbzp)\n\n# Then create a simple plotter\nimport matplotlib.pyplot as plt\n\nStringType = type(\"\")\n\n\ndef plot(data, colorlist=dbzcl, title=\"Composite\"):\n    mini, maxi = data.shape.index(min(data.shape)), data.shape.index(max(data.shape))\n    figsize = (20, 16)  # if mini == 0 else (12,8)\n    fig = plt.figure(figsize=figsize)\n    plt.title(title)\n    clist = (\n        colorlist\n        if type(colorlist) == StringType\n        else matplotlib.colors.ListedColormap(colorlist)\n    )\n    plt.imshow(data, cmap=clist, clim=(0, 255))\n    plt.colorbar(shrink=float(data.shape[mini]) / data.shape[maxi])\n\nplot(\n    comp.getParameter(\"DBZH\").getData(),\n    title=\"Default composite: DBZH 1000 m Pseudo-CAPPI, nearest radar\",\n)\n\n","type":"content","url":"/baltrad-compositing#tweak-the-plotter-from-earlier-exercises","position":5},{"hierarchy":{"lvl1":"Compositing","lvl2":"Maximum reflectivity, lowest pixel, add QC chain"},"type":"lvl2","url":"/baltrad-compositing#maximum-reflectivity-lowest-pixel-add-qc-chain","position":6},{"hierarchy":{"lvl1":"Compositing","lvl2":"Maximum reflectivity, lowest pixel, add QC chain"},"content":"\n\ngenerator.product = _rave.Rave_ProductType_MAX\ngenerator.selection_method = _pycomposite.SelectionMethod_HEIGHT\ngenerator.detectors = [\n    \"ropo\",\n    \"beamb\",\n    \"radvol-att\",\n    \"radvol-broad\",\n    \"rave-overshooting\",\n    \"qi-total\",\n]\nbefore = time.time()\ncomp = generator.generate(None, None, area=\"swegmaps_2000\")\nafter = time.time()\nrio.object = comp\nrio.save(\"data/comp_max.h5\")\nprint(\"Compositing took %3.2f seconds\" % (after - before))\n\nplot(comp.getParameter(\"DBZH\").getData(), title=\"Maximum reflectivity, lowest pixel\")\n\n","type":"content","url":"/baltrad-compositing#maximum-reflectivity-lowest-pixel-add-qc-chain","position":7},{"hierarchy":{"lvl1":"Compositing","lvl2":"Plot correspondong total quality index"},"type":"lvl2","url":"/baltrad-compositing#plot-correspondong-total-quality-index","position":8},{"hierarchy":{"lvl1":"Compositing","lvl2":"Plot correspondong total quality index"},"content":"\n\ndbzh = comp.getParameter(\"DBZH\")\nqitot = dbzh.getQualityFieldByHowTask(\"pl.imgw.quality.qi_total\")\nplot(qitot.getData(), \"binary\", \"Total quality index\")\n\n","type":"content","url":"/baltrad-compositing#plot-correspondong-total-quality-index","position":9},{"hierarchy":{"lvl1":"Compositing","lvl2":"Now use “total quality” as the compositing criterion"},"type":"lvl2","url":"/baltrad-compositing#now-use-total-quality-as-the-compositing-criterion","position":10},{"hierarchy":{"lvl1":"Compositing","lvl2":"Now use “total quality” as the compositing criterion"},"content":"\n\ngenerator.qitotal_field = \"pl.imgw.quality.qi_total\"\nbefore = time.time()\ncomp = generator.generate(None, None, area=\"swegmaps_2000\")\nafter = time.time()\nrio.object = comp\nrio.save(\"data/comp_qitotal.h5\")\nprint(\"Compositing took %3.2f seconds\" % (after - before))\n\nplot(comp.getParameter(\"DBZH\").getData(), title=\"Maximum reflectivity, quality-based\")\n\nplot(\n    comp.getParameter(\"DBZH\")\n    .getQualityFieldByHowTask(\"pl.imgw.quality.qi_total\")\n    .getData(),\n    \"binary\",\n    \"Total quality index\",\n)","type":"content","url":"/baltrad-compositing#now-use-total-quality-as-the-compositing-criterion","position":11},{"hierarchy":{"lvl1":"Rain Rate retrieval with Py-ART"},"type":"lvl1","url":"/baltrad-pyart-rain-rate-example","position":0},{"hierarchy":{"lvl1":"Rain Rate retrieval with Py-ART"},"content":"In this notebook, an ODIM_H5 file is read using BALTRAD. Then the rain rate is determined from the calculated specific attenuation using Py-ART.\nThis is a severe flooding case from July 8, 2013 in Toronto, Canada, with radar data from the King City, Ontario, radar.\n\n","type":"content","url":"/baltrad-pyart-rain-rate-example","position":1},{"hierarchy":{"lvl1":"Rain Rate retrieval with Py-ART","lvl3":"retrieve data from s3 bucket"},"type":"lvl3","url":"/baltrad-pyart-rain-rate-example#retrieve-data-from-s3-bucket","position":2},{"hierarchy":{"lvl1":"Rain Rate retrieval with Py-ART","lvl3":"retrieve data from s3 bucket"},"content":"\n\nimport os\nimport urllib.request\nfrom pathlib import Path\n\n# Set the URL for the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = \"pythia/radar/erad2024/baltrad/pyart2baltrad\"\n!mkdir -p data\nfiles = [\"WKR_201307082030.h5\"]\nfor file in files:\n    file0 = os.path.join(path, file)\n    name = os.path.join(\"data\", Path(file).name)\n    if not os.path.exists(name):\n        print(f\"downloading, {name}\")\n        urllib.request.urlretrieve(f\"{URL}{file0}\", name)\n\n%matplotlib inline\n\nImport the necessary modules.\n\nimport numpy as np\nimport pyart\nimport baltrad_pyart_bridge as bridge  # routines to pass data from Py-ART and BALTRAD\nimport _raveio  # BALTRAD's input/output module\nimport cmweather\n\nRead in the data using RAVE (a component of BALTRAD)\n\n","type":"content","url":"/baltrad-pyart-rain-rate-example#retrieve-data-from-s3-bucket","position":3},{"hierarchy":{"lvl1":"Rain Rate retrieval with Py-ART","lvl2":"Rain rate retrieval using specific attenuation using BALTRAD and Py-ART"},"type":"lvl2","url":"/baltrad-pyart-rain-rate-example#rain-rate-retrieval-using-specific-attenuation-using-baltrad-and-py-art","position":4},{"hierarchy":{"lvl1":"Rain Rate retrieval with Py-ART","lvl2":"Rain rate retrieval using specific attenuation using BALTRAD and Py-ART"},"content":"\n\nrio = _raveio.open(\"data/WKR_201307082030.h5\")\n\nConvert the data to a Py-ART Radar object.\n\nradar = bridge.raveio2radar(rio)\n\nExamine some of the radar moments.\n\ndisplay = pyart.graph.RadarDisplay(radar)\n\ndisplay.plot_ppi(\"DBZH\", 0, vmin=-15, vmax=60)\ndisplay.plot_range_rings([50, 100, 150])\n\ndisplay.plot_ppi(\"PHIDP\", 0, vmin=0, vmax=180, cmap=\"ChaseSpectral\")\ndisplay.plot_range_rings([50, 100, 150])\n\ndisplay.plot_ppi(\"RHOHV\", 0, vmin=0, vmax=1.0, mask_outside=False, cmap=\"CM_rhohv\")\ndisplay.plot_range_rings([50, 100, 150])\n\ndisplay.plot_ppi(\"SQIH\", 0, vmin=0, vmax=1, mask_outside=False, cmap=\"ChaseSpectral\")\ndisplay.plot_range_rings([50, 100, 150])\n\nCalculate the specific attenuation and attenuation corrected reflectivity using Py-ART, add these field to the radar object.\n\nradar.info()\n\nspec_at, cor_z = pyart.correct.calculate_attenuation(\n    radar,\n    0,\n    doc=0,\n    refl_field=\"DBZH\",\n    ncp_field=\"SQIH\",\n    rhv_field=\"RHOHV\",\n    phidp_field=\"PHIDP\",\n    fzl=8000,\n)\n# use the parameter below for a more 'cleanup up' attenuation field\n# ncp_min=-1, rhv_min=-1)\n\nradar.info()\n\nradar.add_field(\"specific_attenuation\", spec_at)\nradar.add_field(\"corrected_reflectivity\", cor_z)\n\nExamine these two new fields.\n\ndisplay.plot_ppi(\"specific_attenuation\", 0, vmin=0, vmax=0.1)\ndisplay.plot_range_rings([50, 100, 150])\n\ndisplay.plot_ppi(\"corrected_reflectivity\", 0, vmin=-15, vmax=60)\ndisplay.plot_range_rings([50, 100, 150])\n\nCalculate the rain rate from the specific attenuation using a power law determined from the ARM Southern Great Plains site.  Mask values where the attenuation is not valid (when the cross correlation ratio or signal quality is low). Add this field to the radar object.\n\nR = 300.0 * (radar.fields[\"specific_attenuation\"][\"data\"]) ** 0.89\nrain_rate_dic = pyart.config.get_metadata(\"rain_rate\")\nrain_rate_dic[\"units\"] = \"mm/hr\"\nrate_not_valid = np.logical_or(\n    (radar.fields[\"SQIH\"][\"data\"] < 0.4), (radar.fields[\"RHOHV\"][\"data\"] < 0.8)\n)\nrain_rate_dic[\"data\"] = np.ma.masked_where(rate_not_valid, R)\n# fill the missing values with 0 for a nicer plot\nrain_rate_dic[\"data\"] = np.ma.filled(rain_rate_dic[\"data\"], 0)\n\nradar.add_field(\"RATE\", rain_rate_dic)\n\nExamine the rain rate\n\ndisplay.plot_ppi(\"RATE\", 0, vmin=0, vmax=50.0)\n\nCreate a new RaveIO object from the Py-ART radar object and write this out using Rave\n\nrio_out = bridge.radar2raveio(radar)\n\ncontainer = _raveio.new()\ncontainer.object = rio_out.object\ncontainer.save(\"data/WKR_201307082030_with_rain_rate.h5\")\n\nimport os\n\nprint(\n    \"ODIM_H5 file is %i bytes large\"\n    % os.path.getsize(\"data/WKR_201307082030_with_rain_rate.h5\")\n)","type":"content","url":"/baltrad-pyart-rain-rate-example#rain-rate-retrieval-using-specific-attenuation-using-baltrad-and-py-art","position":5},{"hierarchy":{"lvl1":"Doppler Velocity Dealiasing with Py-ART"},"type":"lvl1","url":"/pyart-baltrad-dealias-example","position":0},{"hierarchy":{"lvl1":"Doppler Velocity Dealiasing with Py-ART"},"content":"In this notebook Doppler Velocity data from the ARM C-band SAPR radar is read using Py-ART and dealiased using BALTRAD.\n\n","type":"content","url":"/pyart-baltrad-dealias-example","position":1},{"hierarchy":{"lvl1":"Doppler Velocity Dealiasing with Py-ART","lvl2":"retrieve data from s3 bucket"},"type":"lvl2","url":"/pyart-baltrad-dealias-example#retrieve-data-from-s3-bucket","position":2},{"hierarchy":{"lvl1":"Doppler Velocity Dealiasing with Py-ART","lvl2":"retrieve data from s3 bucket"},"content":"\n\nimport os\nimport urllib.request\nfrom pathlib import Path\n\n# Set the URL for the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = \"pythia/radar/erad2024/baltrad/pyart2baltrad\"\n!mkdir -p data\nfiles = [\"sgpcsaprppi_20110520095101.nc\"]\nfor file in files:\n    file0 = os.path.join(path, file)\n    name = os.path.join(\"data\", Path(file).name)\n    if not os.path.exists(name):\n        print(f\"downloading, {name}\")\n        urllib.request.urlretrieve(f\"{URL}{file0}\", name)\n\n%matplotlib inline\n\nImport the necessary modules\n\nimport pyart\nimport baltrad_pyart_bridge as bridge  # routines to pass data from Py-ART to BALTRAD\nimport _dealias  # BALTRAD's dealiasing module\n\nRead in the data using Py-ART\n\nradar = pyart.io.read(\"data/sgpcsaprppi_20110520095101.nc\")\n\nExamine the velocity data using Py-ART Display object.\n\ndisplay = pyart.graph.RadarDisplay(radar)\nnyquist_velocity = radar.instrument_parameters[\"nyquist_velocity\"][\"data\"][0]\ndisplay.plot_ppi(\n    \"velocity\", 1, colorbar_label=\"m/s\", vmin=-nyquist_velocity, vmax=nyquist_velocity\n)\n\nConvert the radar data into a RaveIO object with the velocity data having the correct name.\n\nvel_data = radar.fields[\"velocity\"][\"data\"]\nradar.add_field_like(\"velocity\", \"VRAD\", vel_data)\nrio = bridge.radar2raveio(radar)\n\nPerform Doppler velocity dealiasing using BALTRAD.\n\nret = _dealias.dealias(rio.object)\nprint(\"This first scan is dealiased:\"), _dealias.dealiased(rio.object.getScan(0))\n\nAdd the dealiased velocity field to the origin Py-ART radar object.\n\ntemp = bridge.raveio2radar(rio)\nif \"dealiased_velocity\" in radar.fields:\n    radar.fields.pop(\"dealiased_velocity\")\nradar.add_field_like(\"velocity\", \"dealiased_velocity\", temp.fields[\"VRAD\"][\"data\"])\n\nPlot the dealiased velocities.\n\ndisplay.plot_ppi(\n    \"dealiased_velocity\",\n    1,\n    colorbar_label=\"m/s\",\n    vmin=-2 * nyquist_velocity,\n    vmax=2 * nyquist_velocity,\n)","type":"content","url":"/pyart-baltrad-dealias-example#retrieve-data-from-s3-bucket","position":3},{"hierarchy":{"lvl1":"Data Access Instructions"},"type":"lvl1","url":"/intro-data-access","position":0},{"hierarchy":{"lvl1":"Data Access Instructions"},"content":"Data are accessible via \n\nan object store system, which enables easy, scalable web access!\n\n","type":"content","url":"/intro-data-access","position":1},{"hierarchy":{"lvl1":"Data Access Instructions","lvl2":"Imports"},"type":"lvl2","url":"/intro-data-access#imports","position":2},{"hierarchy":{"lvl1":"Data Access Instructions","lvl2":"Imports"},"content":"\n\nimport fsspec\nimport urllib.request\nfrom pathlib import Path\nimport xradar as xd\nimport pyart\n\n","type":"content","url":"/intro-data-access#imports","position":3},{"hierarchy":{"lvl1":"Data Access Instructions","lvl2":"Find Data in the Bucket"},"type":"lvl2","url":"/intro-data-access#find-data-in-the-bucket","position":4},{"hierarchy":{"lvl1":"Data Access Instructions","lvl2":"Find Data in the Bucket"},"content":"It is stored on the jetstream cloud bucket, under the /pythia/radar/erad2024 space.\n\n# Set the URL and path for the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = f\"pythia/radar/erad2024\"\n\n\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=URL))\n\nfs.glob(f\"{path}/*\")\n\n","type":"content","url":"/intro-data-access#find-data-in-the-bucket","position":5},{"hierarchy":{"lvl1":"Data Access Instructions","lvl3":"Find Data to Stream","lvl2":"Find Data in the Bucket"},"type":"lvl3","url":"/intro-data-access#find-data-to-stream","position":6},{"hierarchy":{"lvl1":"Data Access Instructions","lvl3":"Find Data to Stream","lvl2":"Find Data in the Bucket"},"content":"We can easily stream the data with xradar\n\nfiles = fs.glob(\"pythia/radar/erad2024/dda_data/*\")[:1]\nfiles\n\nlocal_files = [\n    fsspec.open_local(\n        f\"simplecache::{URL}{i}\", s3={\"anon\": True}, filecache={\"cache_storage\": \".\"}\n    )\n    for i in files\n]\n\ndt = xd.io.open_cfradial1_datatree(local_files[0])\nradar = pyart.io.read_cfradial(local_files[0])\n\ndt\n\n","type":"content","url":"/intro-data-access#find-data-to-stream","position":7},{"hierarchy":{"lvl1":"Data Access Instructions","lvl3":"Download the Data Locally","lvl2":"Find Data in the Bucket"},"type":"lvl3","url":"/intro-data-access#download-the-data-locally","position":8},{"hierarchy":{"lvl1":"Data Access Instructions","lvl3":"Download the Data Locally","lvl2":"Find Data in the Bucket"},"content":"We can also use the url of the data to download the data locally if neccessary!\n\nfor file in files:\n    urllib.request.urlretrieve(f\"{URL}{file}\", Path(file).name)","type":"content","url":"/intro-data-access#download-the-data-locally","position":9},{"hierarchy":{"lvl1":"Environment overview"},"type":"lvl1","url":"/environment","position":0},{"hierarchy":{"lvl1":"Environment overview"},"content":"This notebook gives a short over view over the installed packages and the environment.\n\n","type":"content","url":"/environment","position":1},{"hierarchy":{"lvl1":"Environment overview","lvl2":"Linux Environment"},"type":"lvl2","url":"/environment#linux-environment","position":2},{"hierarchy":{"lvl1":"Environment overview","lvl2":"Linux Environment"},"content":"\n\n!env\n\n","type":"content","url":"/environment#linux-environment","position":3},{"hierarchy":{"lvl1":"Environment overview","lvl2":"Conda Environment"},"type":"lvl2","url":"/environment#conda-environment","position":4},{"hierarchy":{"lvl1":"Environment overview","lvl2":"Conda Environment"},"content":"\n\n!conda list","type":"content","url":"/environment#conda-environment","position":5},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)"},"type":"lvl1","url":"/sr-gr-calibration-applied","position":0},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)"},"content":"In this tutorial, we demonstrate how to exploit GPM-API along with other radar software such\n\n\nxradar and\n\n\nwradlib to match reflectivities measurements of spaceborne (SR) and ground (GR) radars and assess the GR calibration bias.\n\nAs example, we analyze a coincident GPM DPR and NEXRAD overpass over San Diego, USA, during the landfall of Tropical Storm Hilary in 2023. The NEXRAD KNKX radar data appears to be significantly miscalibrated and we will assess the calibration bias.\n\nTo facilitate your hands-on experience, we’ve preprocessed the native NEXRAD radar data using the xradar package and the coincident GPM DPR overpass using GPM-API. The resulting data has been uploaded in Zarr format to the Pythia Cloud Bucket, allowing you to start the tutorial directly in the Binder environment.\n\nIf you wish to adapt this tutorial to your own case study, you can use the xradar package to read your GR radar data into the expected xarray format. Similarly, you can retrieve the relevant GPM data using GPM-API.\n\nAdditionally, note that the GPM-API’s volume_matching routine can automatically download and open the coincident GPM overpass data if the SR dataset is not provided to the function.\n\nPlease read the \n\nSpaceborne-Ground Radar Matching Tutorial for a step-by-step guide through the process of obtaining spatially and temporally coincident radar samples.\n\nNow let’s start the tutorial by importing the required packages:\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nfrom functools import reduce\n\nimport cartopy.crs as ccrs\nimport fsspec\nimport numpy as np\nimport xradar as xd\nimport xarray as xr\nfrom IPython.display import display\nfrom xarray.backends.api import open_datatree\nfrom gpm.gv import (\n    calibration_summary,\n    compare_maps,\n    reflectivity_scatterplots,\n    volume_matching,\n)\n\nnp.set_printoptions(suppress=True)\n\n","type":"content","url":"/sr-gr-calibration-applied","position":1},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Load SR and GR data"},"type":"lvl2","url":"/sr-gr-calibration-applied#load-sr-and-gr-data","position":2},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Load SR and GR data"},"content":"\n\nNow let’s open the NEXRAD GR data and the GPM granule with the coincident overpass.\n\n# Open fsspec connection to the bucket\nbucket_url = \"https://js2.jetstream-cloud.org:8001\"\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=bucket_url))\n\n# Open the GR datatree\nfile = fs.get_mapper(f\"pythia/radar/erad2024/gpm_api/KNKX20230820_221341_V06.zarr\")\ndt_gr = open_datatree(file, engine=\"zarr\", consolidated=True, chunks={})\ndisplay(dt_gr)\n\n# Open the SR dataset\nfile = fs.get_mapper(\n    f\"pythia/radar/erad2024/gpm_api/2A.GPM.DPR.V9-20211125.20230820-S213941-E231213.053847.V07B.zarr\"\n)\nds_sr = xr.open_zarr(file, consolidated=True, chunks={})\n\nNow, let’s select a GR sweep to match with GPM DPR:\n\nprint(\"Available sweeps:\", list(dt_gr.groups))\n\nsweep_idx = 0\nsweep_group = f\"sweep_{sweep_idx}\"  # GR sweep (elevation to be used)\nds_gr = dt_gr[sweep_group].to_dataset().compute()\n\nand display the horizontally and vertically polarized reflectivity fields:\n\nds_gr[\"DBZH\"].where(ds_gr[\"DBZH\"] > -10).xradar_dev.plot_map()\nds_gr[\"DBZV\"] = (ds_gr[\"DBZH\"].gpm.idecibel / ds_gr[\"ZDR\"].gpm.idecibel).gpm.decibel\nds_gr[\"DBZV\"].where(ds_gr[\"DBZV\"] > -10).xradar_dev.plot_map()\n# ds_gr[\"ZDR\"].xradar_dev.plot_map()\n\n","type":"content","url":"/sr-gr-calibration-applied#load-sr-and-gr-data","position":3},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Run SR/GR volume matching"},"type":"lvl2","url":"/sr-gr-calibration-applied#run-sr-gr-volume-matching","position":4},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Run SR/GR volume matching"},"content":"\n\nHere we start defining the required settings for the SR/GR volume matching procedure:\n\nThe GR radar_band controls to which frequency SR Ku-band reflectivities will be converted. Valid values are X, C, S, Ku.\n\nThe beamwidth_gr refers to the angular beam width of the GR.\n\nThe minimum reflectivity thresholds z_min_threshold_sr and z_min_threshold_gr are used to mask out SR and GR\ngates belows such thresholds.\n\nradar_band = \"S\"\nbeamwidth_gr = 1\nz_min_threshold_gr = 0\nz_min_threshold_sr = 10\n\nThe SR/GR volume matching routine typically takes around 40-50 seconds to complete. It returns a geopandas.DataFrame with the matched aggregated reflectivities and the associated statistics.\n\ngdf_match = volume_matching(\n    ds_gr=ds_gr,\n    ds_sr=ds_sr,\n    z_variable_gr=\"DBZH\",\n    radar_band=radar_band,\n    beamwidth_gr=beamwidth_gr,\n    z_min_threshold_gr=z_min_threshold_gr,\n    z_min_threshold_sr=z_min_threshold_sr,\n    min_gr_range=0,\n    max_gr_range=150_000,\n    # gr_sensitivity_thresholds=None,\n    # sr_sensitivity_thresholds=None,\n    download_sr=False,  # require internet connection !\n    display_quicklook=True,\n)\n# Note: The circle radius in the quicklook represents the min_gr_range, max_gr_range and 250_000 m range distances.\n\ndisplay(gdf_match)\n\n","type":"content","url":"/sr-gr-calibration-applied#run-sr-gr-volume-matching","position":5},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Analyse SR/GR database"},"type":"lvl2","url":"/sr-gr-calibration-applied#analyse-sr-gr-database","position":6},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Analyse SR/GR database"},"content":"\n\nNow let’s first define the variables names of the SR and GR reflectivities:\n\nsr_z_column = f\"SR_zFactorFinal_{radar_band}_mean\"\ngr_z_column = \"GR_Z_mean\"\n\n","type":"content","url":"/sr-gr-calibration-applied#analyse-sr-gr-database","position":7},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl3":"Compare spatial reflectivity fields","lvl2":"Analyse SR/GR database"},"type":"lvl3","url":"/sr-gr-calibration-applied#compare-spatial-reflectivity-fields","position":8},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl3":"Compare spatial reflectivity fields","lvl2":"Analyse SR/GR database"},"content":"\n\nHere we start comparing the spatial reflectivity fields without applying restrictive filtering criteria:\n\nfig = compare_maps(\n    gdf_match,\n    sr_column=sr_z_column,\n    gr_column=gr_z_column,\n    sr_label=\"SR Reflectivity (dBz)\",\n    gr_label=\"GR Reflectivity (dBz)\",\n    cmap=\"Spectral_r\",\n    unified_color_scale=True,\n    vmin=15,\n    # vmax=40\n)\nfig.tight_layout()\n\nIf you wish to create a cartopy map, specify the 'projection' in the subplot_kwargs argument:\n\nccrs_gr_aeqd = ccrs.AzimuthalEquidistant(\n    central_longitude=ds_gr[\"longitude\"].item(),\n    central_latitude=ds_gr[\"latitude\"].item(),\n)\nsubplot_kwargs = {}\nsubplot_kwargs[\"projection\"] = ccrs_gr_aeqd\nfig = compare_maps(\n    gdf_match,\n    sr_column=sr_z_column,\n    gr_column=gr_z_column,\n    sr_label=\"SR Reflectivity (dBz)\",\n    gr_label=\"GR Reflectivity (dBz)\",\n    cmap=\"Spectral_r\",\n    unified_color_scale=True,\n    vmin=15,\n    # vmax=40\n    subplot_kwargs=subplot_kwargs,\n)\nfig.tight_layout()\n\nHere we show how to explore interactively the reflectivity fields using \n\nFolium:\n\ngdf_match.explore(column=\"GR_Z_mean\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=40)\n\n","type":"content","url":"/sr-gr-calibration-applied#compare-spatial-reflectivity-fields","position":9},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl3":"Generate calibration summary","lvl2":"Analyse SR/GR database"},"type":"lvl3","url":"/sr-gr-calibration-applied#generate-calibration-summary","position":10},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl3":"Generate calibration summary","lvl2":"Analyse SR/GR database"},"content":"\n\nWe now create a figure comparing SR/GR aggregated reflectivities volume-by-volume and displaying the overall distributions.\n\ngr_z_column = \"GR_Z_mean\"\nsr_z_column = f\"SR_zFactorFinal_{radar_band}_mean\"\n\nfig = calibration_summary(\n    df=gdf_match,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    # Histogram options\n    bin_width=2,\n    # Scatterplot options\n    hue_column=\"SR_fraction_clutter\",\n    # gr_range=[15, 50]\n    # sr_range=[15, 50]\n    marker=\"+\",\n    cmap=\"Spectral\",\n)\nfig.tight_layout()\n\n","type":"content","url":"/sr-gr-calibration-applied#generate-calibration-summary","position":11},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl3":"Investigate filtering criteria","lvl2":"Analyse SR/GR database"},"type":"lvl3","url":"/sr-gr-calibration-applied#investigate-filtering-criteria","position":12},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl3":"Investigate filtering criteria","lvl2":"Analyse SR/GR database"},"content":"\n\nWhen comparing SR and GR data or trying to determine an accurate GR calibration bias, it’s necessary to define a set of filtering criteria. In the figures below, we perform exploratory data analysis to investigate the relationships between the SR/GR reflectivity deviations and sets of variables characterizing radar measurements and SR/GR volume properties. The patterns and deviations observed in the scatterplots will be used to define a set of filtering critera in the next section of the tutorial.\n\n# Matching characteristics\nhue_columns = [\n    \"VolumeRatio\",\n    \"VolumeDiff\",\n    \"GR_vres_max\",\n    \"GR_range_max\",\n    \"GR_gate_volume_sum\",\n    \"SR_gate_volume_sum\",\n    \"SR_vres_sum\",\n    \"GR_fraction_covered_area\",\n]\nfig = reflectivity_scatterplots(\n    df=gdf_match,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    hue_columns=hue_columns,\n    ncols=2,\n)\nfig.tight_layout()\n\n# Value validity & sensitivity\nhue_columns = [\n    \"GR_counts\",\n    \"GR_counts_valid\",\n    \"SR_counts\",\n    \"SR_counts_valid\",\n]\nfig = reflectivity_scatterplots(\n    df=gdf_match,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    hue_columns=hue_columns,\n    ncols=2,\n)\nfig.tight_layout()\n\nhue_columns = [\n    \"SR_zFactorFinal_Ku_fraction_above_12dBZ\",\n    \"SR_zFactorFinal_Ku_fraction_above_14dBZ\",\n    \"GR_Z_fraction_above_10dBZ\",\n    \"GR_Z_fraction_above_12dBZ\",\n]\nfig = reflectivity_scatterplots(\n    df=gdf_match,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    hue_columns=hue_columns,\n    ncols=2,\n)\nfig.tight_layout()\n\n# NUBF & Variability\nhue_columns = [\n    \"SR_zFactorFinal_Ku_range\",\n    \"GR_Z_range\",\n    \"SR_zFactorFinal_Ku_std\",\n    \"GR_Z_std\",\n    \"SR_zFactorFinal_Ku_cov\",\n    \"GR_Z_cov\",\n]\nfig = reflectivity_scatterplots(\n    df=gdf_match,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    hue_columns=hue_columns,\n    ncols=2,\n)\nfig.tight_layout()\n\n# Attenuation\nhue_columns = [\n    \"SR_pathAtten\",\n    \"SR_piaFinal\",\n    \"SR_zFactorCorrection_Ku_max\",\n    \"SR_zFactorCorrection_Ku_mean\",\n    \"SR_reliabFlag\",\n    \"GR_Z_cumsum_max\",\n]\nfig = reflectivity_scatterplots(\n    df=gdf_match,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    hue_columns=hue_columns,\n    ncols=2,\n)\nfig.tight_layout()\n\n# Hydrometeors\nhue_columns = [\n    \"SR_fraction_no_precip\",\n    \"SR_fraction_clutter\",\n    \"SR_fraction_rain\",\n    \"SR_fraction_snow\",\n    \"SR_fraction_hail\",\n    \"SR_fraction_below_isotherm\",\n    \"SR_fraction_above_isotherm\",\n    \"SR_fraction_melting_layer\",\n    # 'SR_airTemperature_min',\n]\nfig = reflectivity_scatterplots(\n    df=gdf_match,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    hue_columns=hue_columns,\n    ncols=2,\n)\nfig.tight_layout()\n\n# SR Quality Flags\nhue_columns = [\n    \"SR_flagPrecipitationType\",\n    \"SR_qualityTypePrecip\",\n    \"SR_qualityBB\",\n    \"SR_flagPrecip\",\n    \"SR_qualityFlag\",\n    \"SR_dataQuality\",\n]\nfig = reflectivity_scatterplots(\n    df=gdf_match,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    hue_columns=hue_columns,\n    ncols=2,\n)\nfig.tight_layout()\n\n","type":"content","url":"/sr-gr-calibration-applied#investigate-filtering-criteria","position":13},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Define SR/GR filtering criteria"},"type":"lvl2","url":"/sr-gr-calibration-applied#define-sr-gr-filtering-criteria","position":14},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Define SR/GR filtering criteria"},"content":"When calibrating or comparing SR and GR data, there is a necessary tradeoff between the strictness of filtering criteria filtering and the number of available samples. Here below we provide some general recommendations for effective filtering:\n\nSensitivity Thresholds: Retain only those radar beams where the aggregated gate reflectivities exceed the instrument sensitivities.\nThe GR_Z_fraction_above_<thr>dBZ and SR_zFactorFinal_Ku_fraction_above_<thr>dBZ variables can be used filter the samples.\n\nStratiform Precipitation:  If the purpose of your analysis is to assess the calibration bias of GR data, it is suggested to focus on stratiform precipitation that ocurrs outside the melting layer (i.e. avoiding the bright band). Only stratiform samples above the melting layer are used in ground validation of the GPM DPR (W. Petersen 2017, personal communication).\nConvective SR footprints are typically excluded to avoid dealing with:\n\nthe high spatial variability in the precipitation field and issues with non-uniform beam filling (NUBF),\n\nthe potential biases introduced by the SR attenuation correction,\n\nthe potential biases in GR reflectivities, especially at C and X band, due to beam attenuation,\n\nthe multiple scattering signature caused by hail particles.\n\nReflectivity Range: According to Warren et al. (2018), volume-averaged SR and GR reflectivity values should be selected within the range of 24 to 36 dBZ. This range minimizes the impact of low SR sensitivity,  SR beam attenuation and non-rayleigh scattering effects.\n\nClutter Removal: Exclude SR/GR samples that are contaminated by ground clutter, anomalous propagation, or beam blockage.\n\nVolume matching: Exclude SR/GR samples where there are excessive differences in the total gate volume.\n\n# Define masks\nmasks = [\n    # Select SR scan with \"normal\" dataQuality (for entire cross-track scan)\n    gdf_match[\"SR_dataQuality\"] == 0,\n    # Select SR beams with detected precipitation\n    gdf_match[\"SR_flagPrecip\"] > 0,\n    # Select only 'high quality' SR data\n    # - qualityFlag == 1 indicates low quality retrievals\n    # - qualityFlag == 2 indicates bad/missing retrievals\n    gdf_match[\"SR_qualityFlag\"] == 0,\n    # Select SR beams with SR above minimum reflectivity\n    gdf_match[\"SR_zFactorFinal_Ku_fraction_above_12dBZ\"] > 0.95,\n    # Select SR beams with GR above minimum reflectivity\n    gdf_match[\"GR_Z_fraction_above_10dBZ\"] > 0.95,\n    # Select only SR beams with detected bright band\n    gdf_match[\"SR_qualityBB\"] == 1,\n    # Select only beams with confident precipitation type\n    gdf_match[\"SR_qualityTypePrecip\"] == 1,\n    # Select only stratiform precipitation\n    # - SR_flagPrecipitationType == 2 indicates convective\n    gdf_match[\"SR_flagPrecipitationType\"] == 1,\n    # Select only SR beams with reliable attenuation correction\n    gdf_match[\"SR_reliabFlag\"].isin((1, 2)),  # or == 1\n    # Select only beams with reduced path attenuation\n    # gdf_match[\"SR_zFactorCorrection_Ku_max\"]\n    # gdf_match[\"SR_piaFinal\"]\n    # gdf_match[\"SR_pathAtten\"]\n    # Select only SR beams with matching SR gates with no clutter\n    gdf_match[\"SR_fraction_clutter\"] == 0,\n    # Select only SR beams with matching SR gates not in the melting layer\n    gdf_match[\"SR_fraction_melting_layer\"] == 0,\n    # Select only SR beams with matching SR gates with precipitation\n    gdf_match[\"SR_fraction_no_precip\"] == 0,\n    # Select only SR beams with matching SR gates with no hail\n    gdf_match[\"SR_fraction_hail\"] == 0,\n    # Select only SR beams with matching SR gates with rain\n    # gdf_match[\"SR_fraction_rain\"] == 1,\n    # Select only SR beams with matching SR gates with snow\n    # gdf_match[\"SR_fraction_snow\"] == 1,\n    # Discard SR beams with high NUBF\n    # gdf_match[\"SR_zFactorFinal_Ku_range\"] > 5,\n    # gdf_match[\"SR_zFactorFinal_Ku_cov\"] < 0.5,\n    # gdf_match[\"GR_Z_cov\"] < 0.5,\n    gdf_match[\"GR_Z_range\"] < 15,\n    # Select only interval of reflectivities\n    # - Warren et al., 2018:  between 24 and 36 dBZ\n    # (gdf_match[\"SR_zFactorFinal_Ku_mean\"] > 24) & (gdf_match[\"SR_zFactorFinal_Ku_mean\"] < 36),\n    # (gdf_match[\"GR_Z_mean\"] > 24) & (gdf_match[\"GR_Z_mean\"] < 36),\n    # Select SR beams only within given GR radius interval\n    # (gdf_match[\"GR_range_min\"] > min_gr_range) & (gdf_match[\"GR_range_max\"] < max_gr_range),\n    # Discard SR beams where scanning time difference > 5 minutes\n    # - time_difference is in seconds !\n    gdf_match[\"time_difference\"] < 60 * 5,\n    # Discard SR beams where GR gates does not cover 80% of the horizontal area\n    gdf_match[\"GR_fraction_covered_area\"] > 0.8,\n    # # Filter footprints where volume ratio exceeds 60\n    # gdf_match[\"VolumeRatio\"] > 60,\n    # Filter footprints where GR affected by beam blockage\n    # TODO: Filtering by beam blockage\n]\n\n# Define final mask\nmask_final = reduce(np.logical_and, masks)\n\n# Dsplay final filtering mask\ngdf_match[\"filtering_mask\"] = mask_final\nreflectivity_scatterplots(\n    df=gdf_match,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    hue_columns=\"filtering_mask\",\n    marker=\"o\",\n    s=1,\n    cmap=\"viridis_r\",\n)\n\n","type":"content","url":"/sr-gr-calibration-applied#define-sr-gr-filtering-criteria","position":15},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Analyze filtered SR/GR database"},"type":"lvl2","url":"/sr-gr-calibration-applied#analyze-filtered-sr-gr-database","position":16},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Analyze filtered SR/GR database"},"content":"\n\nWe now filter the SR/GR Database, compare the reflectivity fields and display the new calibration summary:\n\ngdf_final = gdf_match[mask_final]\n\nfig = compare_maps(\n    gdf_final,\n    sr_column=sr_z_column,\n    gr_column=gr_z_column,\n    sr_label=\"SR Reflectivity (dBz)\",\n    gr_label=\"GR Reflectivity (dBz)\",\n    cmap=\"Spectral_r\",\n    unified_color_scale=True,\n    vmin=15,\n    # vmax=40\n)\nfig.tight_layout()\n\nfig = calibration_summary(\n    df=gdf_final,\n    sr_z_column=sr_z_column,\n    gr_z_column=gr_z_column,\n    # Histogram options\n    bin_width=2,\n    # Scatterplot options\n    # hue_column=\"GR_gate_volume_sum\",\n    hue_column=\"GR_range_mean\",\n    # gr_range=[15, 50]\n    # sr_range=[15, 50]\n    marker=\"+\",\n    cmap=\"Spectral\",\n)\nfig.tight_layout()\n\nExploratory data analysis can again be performed to check if the filtering criteria were effective to discard the undesired SR/GR matched volumes and if the filtering criteria should be further expanded.\n\n# Attenuation\nhue_columns = [\n    \"SR_pathAtten\",\n    \"SR_piaFinal\",\n    \"SR_reliabFlag\",\n    \"SR_zFactorCorrection_Ku_max\",\n    \"SR_zFactorCorrection_Ku_mean\",\n    \"GR_Z_cumsum_max\",\n]\nfig = reflectivity_scatterplots(\n    df=gdf_final,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    hue_columns=hue_columns,\n    ncols=2,\n)\nfig.tight_layout()\n\n","type":"content","url":"/sr-gr-calibration-applied#analyze-filtered-sr-gr-database","position":17},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Determine GR calibration bias"},"type":"lvl2","url":"/sr-gr-calibration-applied#determine-gr-calibration-bias","position":18},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Determine GR calibration bias"},"content":"\n\nThe GR calibration bias can be obtained by averaging the difference between the matched SR/GR reflectivity measurements:\n\n# Compute average offset\nz_offset = np.nanmean(gdf_final[sr_z_column] - gdf_final[gr_z_column]).round(2)\nz_offset_robust = np.nanmedian(gdf_final[sr_z_column] - gdf_final[gr_z_column]).round(2)\n\nprint(f\"Th ZH Calibration offset is (mean): {z_offset} dBZ\")\nprint(f\"Th ZH Calibration offset is (median): {z_offset_robust} dBZ\")\n\n","type":"content","url":"/sr-gr-calibration-applied#determine-gr-calibration-bias","position":19},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Volume matching with calibrated GR"},"type":"lvl2","url":"/sr-gr-calibration-applied#volume-matching-with-calibrated-gr","position":20},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Volume matching with calibrated GR"},"content":"\n\nNow, we remove the estimated GR calibration bias, we rerun the SR/GR volume matching procedure, we compare the matched reflectivities and we assess if we have effectively removed the bias by generating the calibration summary. Please note that here below we don’t filter out  undesired SR/GR volumes, but this is operation is recommended once you defined appropriate robust filtering criteria !\n\n# Apply offset\nds_gr[\"DBZH_c\"] = ds_gr[\"DBZH\"] + z_offset\n\n# Apply matching\ngdf_match_corrected = volume_matching(\n    ds_gr=ds_gr,\n    ds_sr=ds_sr,\n    z_variable_gr=\"DBZH_c\",\n    radar_band=radar_band,\n    beamwidth_gr=beamwidth_gr,\n    z_min_threshold_gr=z_min_threshold_gr,\n    z_min_threshold_sr=z_min_threshold_sr,\n    min_gr_range=0,\n    max_gr_range=150_000,\n    # gr_sensitivity_thresholds=None,\n    # sr_sensitivity_thresholds=None,\n    download_sr=False,  # require internet connection !\n)\n\n# Compare reflectivities\nfig = compare_maps(\n    gdf_match_corrected,\n    sr_column=sr_z_column,\n    gr_column=gr_z_column,\n    sr_label=\"SR Reflectivity (dBz)\",\n    gr_label=\"GR Reflectivity (dBz)\",\n    cmap=\"Spectral_r\",\n    unified_color_scale=True,\n    vmin=15,\n    # vmax=40\n)\nfig.tight_layout()\n\n# Display difference in reflectivity betweeen SR and GR\ngdf_match_corrected[\"z_offset\"] = gdf_match_corrected[sr_z_column] - gdf_match_corrected[gr_z_column]\ngdf_match_corrected.plot(column=\"z_offset\", legend=True, cmap=\"RdBu\", vmin=-1.5, vmax=1.5)\n\n# Display calibration summary\nfig = calibration_summary(\n    df=gdf_match_corrected,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    # Histogram options\n    bin_width=2,\n    # Scatterplot options\n    hue_column=\"SR_fraction_clutter\",\n    marker=\"+\",\n    cmap=\"Spectral\",\n)\nfig.tight_layout()\n\n","type":"content","url":"/sr-gr-calibration-applied#volume-matching-with-calibrated-gr","position":21},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Next steps"},"type":"lvl2","url":"/sr-gr-calibration-applied#next-steps","position":22},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Next steps"},"content":"\n\nWe encourage you to explore and adapt the code provided in this tutorial to infer calibration bias also\nfor the vertically polarized channel, iterate over GR sweeps, analyze multiple GPM overpasses, and assess the\nlong-term calibration bias of your GR network.\n\nPlease share any insights or suggestions for improving the matching procedure or filtering criteria with\nthe GPM-API community so we can collaboratively enhance the routines.\n\nWe hope you enjoyed the tutorial! 😊\n\n","type":"content","url":"/sr-gr-calibration-applied#next-steps","position":23},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"References"},"type":"lvl2","url":"/sr-gr-calibration-applied#references","position":24},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"References"},"content":"\n\nCao, Q., Y. Hong, Y. Qi, Y. Wen, J. Zhang, J. J. Gourley, and L. Liao, 2013: Empirical conversion of the vertical profile of reflectivity from Ku-band to S-band frequency. J. Geophys. Res. Atmos., 118, 1814–1825, https://doi.org/10.1002/jgrd.50138\n\nSchwaller, MR, and Morris, KR. 2011. A ground validation network for the Global Precipitation Measurement mission. J. Atmos. Oceanic Technol., 28, 301-319.28, https://doi.org/10.1175/2010JTECHA1403.1\n\nWarren, R.A., A. Protat, S.T. Siems, H.A. Ramsay, V. Louf, M.J. Manton, and T.A. Kane, 2018. Calibrating ground-based radars against TRMM and GPM. J. Atmos. Oceanic Technol., 35, 323–346, https://doi.org/10.1175/JTECH-D-17-0128.1\n\n","type":"content","url":"/sr-gr-calibration-applied#references","position":25},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Citation"},"type":"lvl2","url":"/sr-gr-calibration-applied#citation","position":26},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Calibration (Application)","lvl2":"Citation"},"content":"\n\nThis notebook is part of the \n\nGPM-API  documentation.\n\nLarge portions of this tutorials were adapted and derived from an old \\omega radlib  tutorial.\n\nCopyright: \\omega radlib  and GPM-API developers.\nDistributed under the MIT License. See \n\nGPM-API license for more info.","type":"content","url":"/sr-gr-calibration-applied#citation","position":27},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)"},"type":"lvl1","url":"/sr-gr-matching-procedure","position":0},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)"},"content":"In this tutorial, we demonstrate how to exploit GPM-API along with other radar software such\n\n\nxradar and\n\n\nwradlib to match reflectivities measurements of spaceborne (SR) and ground (GR) radars.\n\nWe guide you step-by-step through the process of obtaining spatially and temporally coincident radar samples.\n\nThe procedure, based on \n\nSchwaller and Morris (2011) and adapted by \n\nWarren, et. al. (2018), involves:\n\naveraging SR reflectivities vertically along the SR beam between the half-power points of the GR sweep.\n\naveraging GR reflectivities horizontally within the SR beam’s footprint.\n\nThe basic principle is illustrated in Fig. 2 of the original paper of Schwaller and Morris (2011).\n\nWarren et al. (2018) describe the method as follows:\n“[...] intersections between individual SR beams and GR elevation sweeps are identified and the reflectivity values from both  instruments are averaged within a spatial neighborhood around the intersection.\nSpecifically, SR data are averaged in range over the width of the GR beam at the GR range of the intersection, while GR data are averaged in the range–azimuth plane within the footprint of the SR beam.\nThe result is a pair of reflectivity measurements corresponding to approximately the same volume of atmosphere. [...]”.\n\nThe procedure should become clearer in Fig. 3:\n\n","type":"content","url":"/sr-gr-matching-procedure","position":1},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Relevant software"},"type":"lvl2","url":"/sr-gr-matching-procedure#relevant-software","position":2},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Relevant software"},"content":"\n\nTo run this tutorial, it is necessary to install additional libraries which are not automatically required by GPM-API.\nThe libraries are\n\n\nxradar,\n\n\nwradlib,\n\n\ngeopandas,\n\n\nfsspec,\n\n\ns3fs and\n\n\nfolium.\nYou can install them with terminal command conda install -c conda-forge xradar wradlib geopandas fsspec s3fs folium\n\nIf you have such libraries installed, you can start importing the required packages:\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport datetime\nfrom functools import reduce\n\nimport cartopy.crs as ccrs\nimport fsspec\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport wradlib as wrl\nimport xarray as xr\nimport xradar as xd\nfrom IPython.display import display\nfrom shapely import Point\nfrom xarray.backends.api import open_datatree\nimport gpm\nfrom gpm.gv.routines import (\n    convert_s_to_ku_band,\n    retrieve_gates_projection_coordinates,\n    xyz_to_antenna_coordinates,\n)\nfrom gpm.utils.remapping import reproject_coords\nfrom gpm.utils.zonal_stats import PolyAggregator\n\nnp.set_printoptions(suppress=True)\n\n","type":"content","url":"/sr-gr-matching-procedure#relevant-software","position":3},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Load SR and GR data"},"type":"lvl2","url":"/sr-gr-matching-procedure#load-sr-and-gr-data","position":4},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Load SR and GR data"},"content":"\n\nIn this tutorial, we exploit a coincident GPM DPR and NEXRAD overpass over San Diego, USA, during the landfall of Tropical Storm Hilary in 2023, to illustrate step-by-step the SR/GR volume matching procedure.\n\nTo facilitate your hands-on experience, we’ve preprocessed the native NEXRAD radar data using the xradar package and the coincident GPM DPR overpass using GPM-API. The resulting data has been uploaded in Zarr format to the Pythia Cloud Bucket, allowing you to start the tutorial directly in the Binder environment.\n\nIf you wish to adapt this tutorial to your own case study, you can use the xradar package to read your GR radar data into the expected xarray format. Similarly, you can retrieve the relevant GPM data using GPM-API. The GPM-API \n\nSpaceborne-Ground Radar Matching Tutorial shows how to read NEXRAD GR data directly from the AWS S3 bucket and how to download the GPM data of interest using GPM-API.\n\nTo start this tutorial let’s open the NEXRAD ground radar data and the GPM granule with the coincident overpass.\n\n# Open fsspec connection to the bucket\nbucket_url = \"https://js2.jetstream-cloud.org:8001\"\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=bucket_url))\n\n# Open the GR datatree\nfile = fs.get_mapper(f\"pythia/radar/erad2024/gpm_api/KNKX20230820_221341_V06.zarr\")\ndt_gr = open_datatree(file, engine=\"zarr\", consolidated=True, chunks={})\ndisplay(dt_gr)\n\n# Open the SR dataset\nfile = fs.get_mapper(\n    f\"pythia/radar/erad2024/gpm_api/2A.GPM.DPR.V9-20211125.20230820-S213941-E231213.053847.V07B.zarr\"\n)\nds_sr = xr.open_zarr(file, consolidated=True, chunks={})\n\nDuring this tutorial we will use only the GPM DPR Ku band reflectivities, therefore we subset the dataset here to facilitate the analysis.\n\nPlease note that the GPM DPR reflectivites measurements are provided by the ZFactorFinaland ZFactorMeasured variables:\n\nThe ZFactorMeasured variable contains the reflectivity measurements with sidelobe clutter removed. However, it still includes ground clutter, background noise, and is not corrected for atmospheric and hydrometeors attenuation.\n\nThe ZFactorFinal represents the reflectivity measurements with background noise, ground clutter, and sidelobe clutter removed. The reflectivites have been corrected atmospheric and hydrometeors attenuation.\n\nds_sr = ds_sr.sel({\"radar_frequency\": \"Ku\"})\n\ndisplay(ds_sr)\n\n","type":"content","url":"/sr-gr-matching-procedure#load-sr-and-gr-data","position":5},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Define settings for SR/GR matching"},"type":"lvl2","url":"/sr-gr-matching-procedure#define-settings-for-sr-gr-matching","position":6},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Define settings for SR/GR matching"},"content":"\n\nHere, we define key parameters and settings necessary for the SR/GR comparison. Minimum reflectivity thresholds are applied to exclude certain radar gates from the analysis, primarily to distinguish precipitating regions.\n\nWe strongly recommend specifying an “optimistic” minimum reflectivity sensitivity threshold, as reflectivities may be biased, and this approach allows for the assessment of non-uniform beam filling (NUBF) during the SR/GR matching process.\n\nMore restrictive filtering can be applied after the SR/GR gate matching is completed.\n\n# Define half power beam width angle (in degrees)\nazimuth_beamwidth_gr = 1.0\nelevation_beamwidth_gr = 1.0\n\n# Define Z min threshold\nz_min_threshold_gr = 0  # to remove dry case\nz_min_threshold_sr = 10\n\n# GR matching ROI\nmin_gr_range_lb = 0\nmax_gr_range_ub = 150_000\n\n# Define SR CRS\ncrs_sr = ds_sr.gpm.pyproj_crs\n\n","type":"content","url":"/sr-gr-matching-procedure#define-settings-for-sr-gr-matching","position":7},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Preprocess GR data with xradar"},"type":"lvl2","url":"/sr-gr-matching-procedure#preprocess-gr-data-with-xradar","position":8},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Preprocess GR data with xradar"},"content":"\n\nNow we select the GR sweep, we georeference the dataset, we set the GR CRS and we extract GR radar gates coordinates.\n\nsweep_idx = 0\nsweep_group = f\"sweep_{sweep_idx}\"  # GR sweep (elevation to be used)\n\n# Select sweep dataset\nds_gr = dt_gr[sweep_group].to_dataset().compute()\n\nprint(\"Sweep Mode:\", ds_gr[\"sweep_mode\"].to_numpy())\nprint(\"Sweep Elevation Angle:\", ds_gr[\"sweep_fixed_angle\"].to_numpy())\n\n# Set auxiliary info as coordinates\n# - To avoid broadcasting i.e. when masking\npossible_coords = [\"sweep_mode\", \"sweep_number\", \"prt_mode\", \"follow_mode\", \"sweep_fixed_angle\"]\nextra_coords = [coord for coord in possible_coords if coord in ds_gr]\nds_gr = ds_gr.set_coords(extra_coords)\n\n# Georeference the data on a azimuthal_equidistant projection centered on the radar\nds_gr = ds_gr.xradar.georeference()\nds_gr[\"crs_wkt\"].attrs\n\n# Get the GR CRS\ncrs_gr = ds_gr.xradar_dev.pyproj_crs\n\n# Add lon/lat coordinates to GR\n# - Useful for plotting ;)\nlon_gr, lat_gr, height_gr = reproject_coords(x=ds_gr[\"x\"], y=ds_gr[\"y\"], z=ds_gr[\"z\"], src_crs=crs_gr, dst_crs=crs_sr)\nds_gr[\"lon\"] = lon_gr\nds_gr[\"lat\"] = lat_gr\nds_gr = ds_gr.set_coords([\"lon\", \"lat\"])\n\n# Set GR gates with Z < 0 to NaN\n# - Following Morris and Schwaller 2011 recommendation\nds_gr = ds_gr.where(ds_gr[\"DBZH\"] >= 0)\n\n# Show some GR fields\nds_gr[\"DBZH\"].xradar_dev.plot_map()\nds_gr[\"RHOHV\"].xradar_dev.plot_map()\n\n# Retrieve GR extent\nextent_gr = ds_gr.xradar_dev.extent(max_distance=None, crs=None)\nextent_gr\n\n","type":"content","url":"/sr-gr-matching-procedure#preprocess-gr-data-with-xradar","position":9},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Preprocess SR data"},"type":"lvl2","url":"/sr-gr-matching-procedure#preprocess-sr-data","position":10},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Preprocess SR data"},"content":"\n\nLet’s start by cropping the SR granule on the GR extent and put data into memory:\n\nds_sr = ds_sr.gpm.crop(extent_gr).compute()\n\nWe can further subset the GPM overpass selecting the scans occured between the following timesteps:\n\nstart_time = datetime.datetime.strptime(\"2023-08-20 22:12:00\", \"%Y-%m-%d %H:%M:%S\")\nend_time = datetime.datetime.strptime(\"2023-08-20 22:13:45\", \"%Y-%m-%d %H:%M:%S\")\nds_sr = ds_sr.gpm.sel(time=slice(start_time, end_time))\n\nNow let’s display some variables illustrating the GPM overpass\n\nds_sr[\"precipRateNearSurface\"].gpm.plot_map()\nds_sr[\"zFactorMeasured\"].gpm.slice_range_at_bin(ds_sr[\"binClutterFreeBottom\"]).gpm.plot_map(\n    vmax=40,\n)  # zFactorMeasuredNearSurface\nds_sr[\"zFactorFinalNearSurface\"].gpm.plot_map(vmax=40)\nds_sr[\"flagPrecip\"].gpm.plot_map()\n\nIn the following map and cross-sections, we can see that the zFactorMeasured variable is contaminated by ground clutter:\n\n# Display the maximum observed reflectivity\nds_sr[\"zFactorMeasured\"].max(dim=\"range\").gpm.plot_map()\nds_sr[\"zFactorFinal\"].max(dim=\"range\").gpm.plot_map(vmax=40)\n\n# Compute SR attenuation correction\nds_sr[\"zFactorCorrection\"] = ds_sr[\"zFactorFinal\"] - ds_sr[\"zFactorMeasured\"]\n\n# Display cross-section\nds_sr[\"zFactorMeasured\"].isel(cross_track=24).gpm.plot_cross_section(zoom=False)\nds_sr[\"zFactorFinal\"].isel(cross_track=24).gpm.plot_cross_section(zoom=False)\nds_sr[\"zFactorCorrection\"].isel(cross_track=24).gpm.plot_cross_section(vmin=0, vmax=3, cmap=\"Spectral_r\", zoom=False)\n\nSo now we mask out gates impacted by ground clutter, adn we verify with maps and cross-sections that the ground clutter is effectively removed:\n\n# Mask SR gates with ground clutter\nds_sr[\"zFactorMeasured\"] = ds_sr[\"zFactorMeasured\"].gpm.mask_below_bin(\n    bins=ds_sr[\"binClutterFreeBottom\"],\n    strict=False,\n)  # do not mask the specified bin\nds_sr[\"zFactorCorrection\"] = ds_sr[\"zFactorCorrection\"].gpm.mask_below_bin(\n    bins=ds_sr[\"binClutterFreeBottom\"],\n    strict=False,\n)  # do not mask the specified bin\n\n# Display the maximum observed reflectivity\nds_sr[\"zFactorMeasured\"].max(dim=\"range\").gpm.plot_map()\nds_sr[\"zFactorFinal\"].max(dim=\"range\").gpm.plot_map(vmax=40)\n\n# Display cross-section with ground clutter masked out\nds_sr[\"zFactorMeasured\"].isel(cross_track=24).gpm.plot_cross_section(zoom=False)\nds_sr[\"zFactorFinal\"].isel(cross_track=24).gpm.plot_cross_section(zoom=False)\nds_sr[\"zFactorCorrection\"].isel(cross_track=24).gpm.plot_cross_section(vmin=0, vmax=3, cmap=\"Spectral_r\", zoom=False)\n\n","type":"content","url":"/sr-gr-matching-procedure#preprocess-sr-data","position":11},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve GR gate resolution"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-gr-gate-resolution","position":12},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve GR gate resolution"},"content":"In this subsection we derive the horizontal and vertical resolution of GR gates.\n\nThe GR horizontal and vertical resolution change as a function of the range distance.\n\n# Compute horizontal and vertical GR gate resolution\nh_res_gr, v_res_gr = ds_gr.xradar_dev.resolution_at_range(\n    azimuth_beamwidth=azimuth_beamwidth_gr,\n    elevation_beamwidth=elevation_beamwidth_gr,\n)\nh_res_gr.xradar_dev.plot_map()\nv_res_gr.xradar_dev.plot_map()\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-gr-gate-resolution","position":13},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Define GR range distance interval"},"type":"lvl2","url":"/sr-gr-matching-procedure#define-gr-range-distance-interval","position":14},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Define GR range distance interval"},"content":"\n\nNow let’s define the minimum range distance at which the GR gate vertical resolution is larger than 150/250 m (the range resolution of GPM) and at which GR distance the GR gate vertical resolution exceed 1500 m (which correspond to 12/6 SR gates included in a GR gate)\n\nmask_gr_gate_depth_above_250 = v_res_gr > 250\nmask_gr_gate_depth_above_250.xradar_dev.plot_map()\nmin_gr_range = np.max(\n    mask_gr_gate_depth_above_250[\"range\"].data[mask_gr_gate_depth_above_250.sum(dim=\"azimuth\") == 0],\n)  # min_range_distance\n\nmask_gr_gate_depth_below_2000 = v_res_gr > 1500\nmask_gr_gate_depth_below_2000.xradar_dev.plot_map()\nmax_gr_range = np.max(\n    mask_gr_gate_depth_below_2000[\"range\"].data[mask_gr_gate_depth_below_2000.sum(dim=\"azimuth\") == 0],\n)  # min_range_distance\n\nprint(\"Minimum GR distance:\", min_gr_range, \"m\")\nprint(\"Maximum GR distance:\", max_gr_range, \"m\")\n\nNow let’s specify the minimum and maximum GR range distance to consider when matching SR/GR gates.\n\nIt’s good practice to avoid restricting too much at this stage. Matched SR/GR gates can be filtered afterwards.\n\n# Specify GR range distance interval over which to perform SR matching\nmin_gr_range = 7_000  # about 15_000 km\nmax_gr_range = 150_000\n\n","type":"content","url":"/sr-gr-matching-procedure#define-gr-range-distance-interval","position":15},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Display SR slice and GR sweep"},"type":"lvl2","url":"/sr-gr-matching-procedure#display-sr-slice-and-gr-sweep","position":16},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Display SR slice and GR sweep"},"content":"\n\n# Slice SR volume\nda_sr = ds_sr[\"zFactorFinal\"].isel(range=-5)\nda_sr = ds_sr[\"zFactorFinal\"].gpm.slice_range_at_bin(ds_sr[\"binClutterFreeBottom\"])\nda_sr = ds_sr[\"zFactorFinal\"].gpm.slice_range_at_height(value=2000)\n\n# Define SR and GR mask\nmask_gr = ds_gr[\"DBZH\"] >= z_min_threshold_gr\n# mask_gr = np.logical_and(ds_gr[\"DBZH\"] >= z_min_threshold_gr, ds_gr[\"RHOHV\"] >= 0.80)\n\nmask_sr = True  # aka do not mask\n\n# Retrieve SR extent\nsr_extent = ds_sr.gpm.extent()\n\n# Define cmap\ncmap = \"Spectral_r\"\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), dpi=120, subplot_kw={\"projection\": ccrs.PlateCarree()})\n# - Plot SR\np_sr = da_sr.where(mask_sr).gpm.plot_map(\n    ax=ax1,\n    cmap=cmap,\n    vmin=0,\n    vmax=40,\n    cbar_kwargs={\"label\": \"SR Reflectivity (dBz)\"},\n    add_colorbar=True,\n)\n# - Plot GR\nds_gr[\"DBZH\"].where(mask_gr).xradar_dev.plot_map(\n    ax=ax2,\n    cmap=cmap,\n    vmin=0,\n    vmax=40,\n    cbar_kwargs={\"label\": \"GR Reflectivity (dBz)\", \"extend\": \"both\"},\n    add_colorbar=True,\n)\n# - Add the SR swath boundary\nda_sr.gpm.plot_swath_lines(ax=ax2)\n# - Restrict the extent to the SR overpass\nax2.set_extent(sr_extent)\n# - Display GR range distances\nfor ax in [ax1, ax2]:\n    ds_gr.xradar_dev.plot_range_distance(\n        distance=min_gr_range,\n        ax=ax,\n        add_background=True,\n        linestyle=\"dashed\",\n        edgecolor=\"black\",\n    )\n    ds_gr.xradar_dev.plot_range_distance(\n        distance=max_gr_range,\n        ax=ax,\n        add_background=True,\n        linestyle=\"dashed\",\n        edgecolor=\"black\",\n    )\n    ds_gr.xradar_dev.plot_range_distance(\n        distance=250_000,\n        ax=ax,\n        add_background=True,\n        linestyle=\"dashed\",\n        edgecolor=\"black\",\n    )\n# - Add GR location\nax1.scatter(ds_gr[\"longitude\"], ds_gr[\"latitude\"], c=\"black\", marker=\"X\", s=4)\nax2.scatter(ds_gr[\"longitude\"], ds_gr[\"latitude\"], c=\"black\", marker=\"X\", s=4)\n# - Set title\nax1.set_title(\"GPM\", fontsize=12, loc=\"left\")\nax2.set_title(\"Ground Radar\", fontsize=12, loc=\"left\")\n# - Improve layout and display\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/sr-gr-matching-procedure#display-sr-slice-and-gr-sweep","position":17},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve GR (lon, lat) coordinates"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-gr-lon-lat-coordinates","position":18},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve GR (lon, lat) coordinates"},"content":"Here we retrieve the 2D non-dimensional longitude and latitude coordinates in the CRS of the SR.\nThese 2D coordinates will have dimensions (azimuth, range)\n\nlon_gr, lat_gr, height_gr = reproject_coords(x=ds_gr[\"x\"], y=ds_gr[\"y\"], z=ds_gr[\"z\"], src_crs=crs_gr, dst_crs=crs_sr)\n\n# If crs_gr and crs_sr share same datum/ellispoid, z does not vary\nprint(crs_gr.datum)\nprint(crs_sr.datum)\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-gr-lon-lat-coordinates","position":19},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve SR (x,y,z) coordinates"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-sr-x-y-z-coordinates","position":20},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve SR (x,y,z) coordinates"},"content":"Here we retrieve the 3D (x,y,z) coordinates of SR gates in the GR CRS projection.\n\nThe GR CRS is a azimuthal equidistant (AZEQ) projection centered on the ground radar.\nIn the GR CRS, the (x,y) coordinates (0,0) corresponds to the location of the ground radar.\nTherefore, the retrieved SR (x,y) coordinates are relative to the ground radar site, while the z coordinates is relative to the ellipsoid.\n\nx_sr, y_sr, z_sr = retrieve_gates_projection_coordinates(ds_sr, dst_crs=crs_gr)\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-sr-x-y-z-coordinates","position":21},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve SR (range, azimuth, elevation) coordinates"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-sr-range-azimuth-elevation-coordinates","position":22},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve SR (range, azimuth, elevation) coordinates"},"content":"\n\nNow we inverse the SR (x,y,z) 3D GR CRS coordinates to derive the SR (range, azimuth, elevation) coordinates with respect to GR sweep.\nThese coordinates allow to identify the SR gates intersecting the GR sweep.\n\nrange_sr, azimuth_sr, elevation_sr = xyz_to_antenna_coordinates(\n    x=x_sr,\n    y=y_sr,\n    z=z_sr,\n    site_altitude=ds_gr[\"altitude\"],\n    crs=crs_gr,\n    effective_radius_fraction=None,\n)\nprint(range_sr.isel(cross_track=0).min().item(), \"m\")  # far from the radar\nprint(range_sr.isel(cross_track=-1).min().item(), \"m\")  # closer to radar\n\n# Show elevation angle at different SR scan angle\nelevation_sr.isel(cross_track=0).gpm.plot_cross_section(vmin=0)  # far from the radar\nelevation_sr.isel(cross_track=-1).gpm.plot_cross_section(vmin=0)  # closer to radar\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-sr-range-azimuth-elevation-coordinates","position":23},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve SR range distance"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-sr-range-distance","position":24},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve SR range distance"},"content":"The range distance from the satellite for each SR radar gate has been precomputed using information in the GPM L1B product and already included in the preprocessed GPM Zarr Store.\n\nThe range_distance_from_satellite can also be derived from the GPM L2 product if we assume a cross-track scan angle.\nHowever, uncertainties in cross-tracks scan angle can erroneously impacts the estimates.\nAs we show here below, an uncertainty of 0.1° translates to a range distance difference of up to 400 m which corresponds to 3/4 radar gates !\n\n# Show impact of scan angle on range distance\n# - Variation of 0.01 impacts range distance up to 30 m\n# - Variation of 0.05 impacts range distance up to 100 m\n# - Variation of 0.1 impacts range distance up to 400 m\nscan_angle_template = np.abs(np.linspace(-17.04, 17.04, 49))  # assuming Ku swath of size 49\nscan_angle = xr.DataArray(scan_angle_template[ds_sr[\"gpm_cross_track_id\"].data], dims=\"cross_track\")\nscan_angle = scan_angle + 0.1\nl2_distance = ds_sr.gpm.retrieve(\"range_distance_from_satellite\", scan_angle=scan_angle)\n\ndiff = l2_distance - ds_sr[\"range_distance_from_satellite\"]\ndiff.isel(along_track=0).gpm.plot_cross_section()  # difference > 500 m\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-sr-range-distance","position":25},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve radar gates volumes"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-radar-gates-volumes","position":26},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve radar gates volumes"},"content":"Here we compute SR and GR gate volumes.\n\nAn accurate beam width is necessary to derive accurate gate volume estimates. This is demonstrated here below !\n\n# Compute GR gates volumes\nvol_gr = wrl.qual.pulse_volume(\n    ds_gr[\"range\"],  # range distance\n    h=ds_gr[\"range\"].diff(\"range\").median(),  # range resolution\n    theta=elevation_beamwidth_gr,\n)  # beam width\nvol_gr = vol_gr.broadcast_like(ds_gr[\"DBZH\"])\nvol_gr = vol_gr.assign_coords({\"lon\": ds_gr[\"lon\"], \"lat\": ds_gr[\"lat\"]})\n\n# Compute SR gates volumes\nrange_distance = ds_sr[\"range_distance_from_satellite\"]\nvol_sr = ds_sr.gpm.retrieve(\"gate_volume\", beam_width=ds_sr[\"crossTrackBeamWidth\"], range_distance=range_distance)\nvol_sr.isel(along_track=0).gpm.plot_cross_section()\nvol_sr.isel(range=-1).gpm.plot_map()\n\n# Assuming fixed beamwidth with SR leads to volume difference up to 0.35 km3\nvol_sr1 = ds_sr.gpm.retrieve(\"gate_volume\", beam_width=0.71, range_distance=range_distance)\ndiff = vol_sr - vol_sr1\ndiff.isel(along_track=0).gpm.plot_cross_section()\ndiff.isel(range=-1).gpm.plot_map()\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-radar-gates-volumes","position":27},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve SR gate resolution"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-sr-gate-resolution","position":28},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve SR gate resolution"},"content":"In this subsection we derive the horizontal and vertical SR gate resolution.\n\nThe SR horizontal resolution change for each radar gate, while the vertical resolution varies only across SR footprints.\nNote that the vertical resolution here derived is equivalent to the GPM L2 product variable height.\n\nAssuming a fixed beamwidth of 0.71 can leads to variations in horizontal resolution estimates up to 400 m on the outer-track.\n\n# Compute horizontal and vertical SR gate resolution\nrange_distance = ds_sr[\"range_distance_from_satellite\"]\nh_res_sr, v_res_sr = ds_sr.gpm.retrieve(\"gate_resolution\", beam_width=ds_sr[\"crossTrackBeamWidth\"], range_distance=range_distance)\nh_radius = h_res_sr / 2\n\n# Validate v_res_sr [OK !]\ndiff = -ds_sr[\"height\"].diff(dim=\"range\") - v_res_sr\ndiff.isel(along_track=0).gpm.plot_cross_section(y=\"range\")\nplt.show()\n\n# Validate h_res [PROBLEMATIC WITH FIXED BEAM WIDTH]\nh_res1_sr, _ = ds_sr.gpm.retrieve(\"gate_resolution\", beam_width=None, range_distance=range_distance)  # Use 0.71\ndiff = h_res_sr - h_res1_sr\ndiff.isel(along_track=0).gpm.plot_cross_section(y=\"range\")\ndiff.isel(range=-1).gpm.plot_map()\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-sr-gate-resolution","position":29},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve Bright Band (BB) Ratio"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-bright-band-bb-ratio","position":30},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve Bright Band (BB) Ratio"},"content":"Here we derive the bright band ratio, which is defined as follow:\n\nA BB ratio of < 0 indicates that a bin is located below the melting layer (ML).\n\nA BB ratio of > 0 indicates that a bin is located above the ML.\n\nA BB ratio with values in between 0 and 1 indicates tha the radar is inside the ML.\n\nda_bb_ratio, da_bb_mask = ds_sr.gpm.retrieve(\"bright_band_ratio\", return_bb_mask=True)\nda_bb_ratio.isel(cross_track=24).gpm.plot_cross_section(vmin=0, vmax=1)\nda_bb_ratio.isel(range=0).gpm.plot_map()  # top\nda_bb_ratio.isel(range=-1).gpm.plot_map()  # bottom\n\n# Show difference between L2 qualityBB and custom derived BB mask\nds_sr[\"qualityBB\"].gpm.plot_map()\nda_bb_mask.gpm.plot_map()\nds_sr[\"qualityBB\"].attrs\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-bright-band-bb-ratio","position":31},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve Precipitation and Hydrometeors Types"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-precipitation-and-hydrometeors-types","position":32},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve Precipitation and Hydrometeors Types"},"content":"\n\n# Retrieve precipitation type classification\nds_sr[\"flagPrecipitationType\"] = ds_sr.gpm.retrieve(\"flagPrecipitationType\", method=\"major_rain_type\")\nds_sr[\"flagPrecipitationType\"].gpm.plot_map()\nds_sr[\"flagPrecipitationType\"].attrs\n\n# Retrieve hydrometeors classification\nds_sr[\"flagHydroClass\"] = ds_sr.gpm.retrieve(\"flagHydroClass\")\nds_sr[\"flagHydroClass\"].isel(cross_track=24).gpm.plot_cross_section()\nds_sr[\"flagHydroClass\"].attrs\n\n# Visualize cross-section\nprecip_type3d = xr.ones_like(ds_sr[\"flagHydroClass\"]) * ds_sr[\"flagPrecipitationType\"]\nprecip_type3d = precip_type3d.where(ds_sr[\"zFactorFinal\"] > 10)\nprecip_type3d.name = ds_sr[\"flagPrecipitationType\"].name\n\nprecip_type3d.isel(cross_track=24).gpm.plot_cross_section()\nds_sr[\"flagHydroClass\"].where(ds_sr[\"flagHydroClass\"] > 0).isel(cross_track=24).gpm.plot_cross_section()\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-precipitation-and-hydrometeors-types","position":33},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Convert SR Ku-band to S-band"},"type":"lvl2","url":"/sr-gr-matching-procedure#convert-sr-ku-band-to-s-band","position":34},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Convert SR Ku-band to S-band"},"content":"\n\nHere we convert reflectivities from Ku-band to S-band based on \n\nCao et al., (2013).\n\nWhen filtering the SR/GR matched samples, plase consider to select:\n\nonly reflectivities below 35 dBZ for S-band GR radars to avoid non-rayleigh scattering\n\nonly reflectivities below 25 dBZ for C/X-band GR radars\n\n# With attenuation corrected reflectivity\nda_z_s_final = ds_sr.gpm.retrieve(\"s_band_cao2013\", reflectivity=\"zFactorFinal\", bb_ratio=None, precip_type=None)\nda_z_ku_final = ds_sr[\"zFactorFinal\"]\ndfr_s_ku_final = da_z_s_final - da_z_ku_final\ndfr_s_ku_final.name = \"DRF_S_Ku\"\n\ndfr_s_ku_final.isel(cross_track=24).gpm.plot_cross_section()\nda_z_ku_final.isel(cross_track=24).gpm.plot_cross_section()\nda_z_s_final.isel(cross_track=24).gpm.plot_cross_section()\n\n# With measured reflectivity\nda_z_s_measured = ds_sr.gpm.retrieve(\"s_band_cao2013\", reflectivity=\"zFactorMeasured\", bb_ratio=None, precip_type=None)\nda_z_ku_measured = ds_sr[\"zFactorMeasured\"]\ndfr_s_ku_measured = da_z_s_measured - da_z_ku_measured\ndfr_s_ku_measured.name = \"DRF_S_Ku\"\n\ndfr_s_ku_measured.isel(cross_track=24).gpm.plot_cross_section()\nda_z_ku_measured.isel(cross_track=24).gpm.plot_cross_section()\nda_z_s_measured.isel(cross_track=24).gpm.plot_cross_section()\n\n# Compute attenuation correction in S-band\nda_z_s_correction = da_z_s_final - da_z_s_measured\nda_z_s_correction.isel(cross_track=24).gpm.plot_cross_section()\n\n","type":"content","url":"/sr-gr-matching-procedure#convert-sr-ku-band-to-s-band","position":35},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Convert SR Ku-band to X and C-band"},"type":"lvl2","url":"/sr-gr-matching-procedure#convert-sr-ku-band-to-x-and-c-band","position":36},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Convert SR Ku-band to X and C-band"},"content":"Here we convert reflectivities from Ku-band to X and C-band.\n\nWe welcome contributions to improve this portion of code !\n\nda_z_c = ds_sr.gpm.retrieve(\"c_band_tan\", bb_ratio=None, precip_type=None)\nda_z_x = ds_sr.gpm.retrieve(\"x_band_tan\", bb_ratio=None, precip_type=None)\n\nda_z_c.isel(cross_track=24).gpm.plot_cross_section()\nda_z_x.isel(cross_track=24).gpm.plot_cross_section()\n\n","type":"content","url":"/sr-gr-matching-procedure#convert-sr-ku-band-to-x-and-c-band","position":37},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Convert GR S-band to Ku-band"},"type":"lvl2","url":"/sr-gr-matching-procedure#convert-gr-s-band-to-ku-band","position":38},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Convert GR S-band to Ku-band"},"content":"Here we provide some code to convert GR S-band reflectivities to Ku-band.\n\nHowever, the resulting reflectivities are not used in the rest of the tutorial.\n\nThe methodology we adopt currently use only an average bright band height to discern between liquid and solid phase precipitation, and it does not account for mixed-phase precipitation and the phase transition.\n\nWe welcome contributions to improve this portion of code ;)\n\n# Estimate bright band height\nbright_band_height = np.nanmean(ds_sr[\"heightBB\"])\n# Retrieve Ku-band reflectivities from GR S-band reflectivities\nda_gr_ku = convert_s_to_ku_band(ds_gr=ds_gr, bright_band_height=bright_band_height)\n\nda_gr_s = ds_gr[\"DBZH\"]\nda_gr_s.xradar_dev.plot_map(vmin=0, vmax=50)\nplt.show()\n\nda_gr_ku.xradar_dev.plot_map(vmin=0, vmax=50)\nplt.show()\n\ndiff = da_gr_ku - da_gr_s\ndiff.rename(\"diff\").xradar_dev.plot_map()\nplt.show()\n\n","type":"content","url":"/sr-gr-matching-procedure#convert-gr-s-band-to-ku-band","position":39},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Identify SR gates intersecting GR sweep"},"type":"lvl2","url":"/sr-gr-matching-procedure#identify-sr-gates-intersecting-gr-sweep","position":40},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Identify SR gates intersecting GR sweep"},"content":"Here we define the mask used to select SR footprints intersecting the GR sweep gates.\nUsing other terms, we can describe this task as finding SR gates that, once aggregated, “match” with the GR sweep plane-position-indicator (PPI) display.\n\nTo this end, we need to filter SR gates by GR range distance and elevation angle.\n\nSince the GR CRS is centered on the GR radar location, we can define the SR range mask using the “GR” range coordinate.\nSo here below, we define the SR range mask with GR range between min_gr_range_lb and max_gr_range_ub.\nWe suggest to specify min_gr_range_lb and max_gr_range_ub not to restrictively, and rather perform more aggressive filtering once the SR/GR matched database is obtained.\n\nThe SR elevation mask is obtained by selecting SR gates with elevation angle between the GR sweep elevation angle minus/plus its half beamwidth.\n\nImportant note:\n\nHere we currently use the GR range computed at the SR gate centroids (instead of at the SR gate lower and upper bound)\n\nHere we currently use the GR elevation computed at the SR gate centroids (instead of at the SR gate lower and upper bound)\n\n# Define mask of SR footprints within GR range\nr = np.sqrt(x_sr**2 + y_sr**2)\nmask_sr_within_gr_range = r < ds_gr[\"range\"].max().item()\nmask_sr_within_gr_range.isel(range=-1).gpm.plot_map()\n\nmask_sr_within_gr_range_interval = (r >= min_gr_range_lb) & (r <= max_gr_range_ub)\n\n# Show how elevation angle (of GR) varies along SR scan angles\nelevation_sr.isel(cross_track=0).gpm.plot_cross_section(vmin=0, y=\"range\")\nelevation_sr.isel(cross_track=24).gpm.plot_cross_section(vmin=0, y=\"range\")\nelevation_sr.isel(cross_track=-1).gpm.plot_cross_section(vmin=0, y=\"range\")\n\n# Show SR/GR matched elevation\nmask_sr_matched_elevation = (elevation_sr >= (ds_gr[\"sweep_fixed_angle\"] - elevation_beamwidth_gr / 2.0)) & (\n    elevation_sr <= (ds_gr[\"sweep_fixed_angle\"] + elevation_beamwidth_gr / 2.0)\n)\nmask_sr_matched_elevation.isel(cross_track=0).gpm.plot_cross_section()\nmask_sr_matched_elevation.isel(cross_track=24).gpm.plot_cross_section()\nmask_sr_matched_elevation.isel(cross_track=-1).gpm.plot_cross_section()\n\n# Define mask of SR footprints matching GR gates\nmask_ppi = mask_sr_matched_elevation & mask_sr_within_gr_range_interval\n\n# Show mask (as SR map)\nmask_ppi.any(dim=\"range\").gpm.plot_map(vmin=0)\nmask_ppi.isel(range=-10).gpm.plot_map(vmin=0)\nmask_ppi.isel(range=-30).gpm.plot_map(vmin=0)\n\n# Show mask (as SR cross-section)\nmask_ppi.isel(cross_track=24).gpm.plot_cross_section()\nmask_ppi.isel(cross_track=-1).gpm.plot_cross_section()\nmask_ppi.isel(cross_track=-1, along_track=slice(10, 60), range=slice(-40, None)).gpm.plot_cross_section()\n\n","type":"content","url":"/sr-gr-matching-procedure#identify-sr-gates-intersecting-gr-sweep","position":41},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Define SR Masks"},"type":"lvl2","url":"/sr-gr-matching-procedure#define-sr-masks","position":42},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Define SR Masks"},"content":"Here we start by defining and analysing various SR masks that can be used to subset SR footprints to be matched with the GR sweep.\n\n# Select scan with \"normal\" dataQuality (for entire cross-track scan)\nmask_sr_quality = ds_sr[\"dataQuality\"] == 0\n\n# Select beams with detected precipitation\nds_sr[\"flagPrecip\"].gpm.plot_map()\nmask_sr_precip = ds_sr[\"flagPrecip\"] > 0\nmask_sr_precip.name = \"mask_precip\"\nmask_sr_precip.gpm.plot_map()\nds_sr[\"flagPrecip\"].attrs\n\n# Select above minimum SR reflectivity\nmask_sr_minimum_z = ds_sr[\"zFactorFinal\"] > z_min_threshold_sr\nmask_sr_minimum_z.name = \"Minimum_Reflectitvity\"\nmask_sr_minimum_z.any(dim=\"range\").gpm.plot_map()\n\n# Select only 'normal' data\n# mask_sr_quality_data = ds_sr[\"qualityData\"] == 0\n# mask_sr_quality_data.gpm.plot_map()\n\n# Select only 'high quality' data\n# - qualityFlag derived from qualityData.\n# - qualityFlag == 1 indicates low quality retrievals\n# - qualityFlag == 2 indicates bad/missing retrievals\nmask_sr_quality_data = ds_sr[\"qualityFlag\"] == 0\n\n# Select only beams with detected bright band\nds_sr[\"qualityBB\"].gpm.plot_map()\nmask_sr_quality_bb = ds_sr[\"qualityBB\"] == 1\nmask_sr_quality_bb.name = \"mask_bb\"\nmask_sr_quality_bb.gpm.plot_map()\n\n# Select only beams with confident precipitation type\nds_sr[\"qualityTypePrecip\"].gpm.plot_map()\nmask_sr_quality_precip = ds_sr[\"qualityTypePrecip\"] == 1\nmask_sr_quality_precip.name = \"mask_precip_type\"\nmask_sr_quality_precip.gpm.plot_map()\n\n# Select only stratiform precipitation\nds_sr[\"flagPrecipitationType\"].gpm.plot_map()\nmask_sr_stratiform = ds_sr[\"flagPrecipitationType\"] == 1\nmask_sr_stratiform.name = \"mask_stratiform\"\nmask_sr_stratiform.gpm.plot_map()\n\n# Select only beams with reduced path attenuation\n# ...\nds_sr[\"piaFinal\"].gpm.plot_map()  # PIA from DSD module\nds_sr[\"pathAtten\"].gpm.plot_map()  # PIAeff\nds_sr[\"reliabFlag\"].gpm.plot_map()  # reliability of PIAeff\n\n# Select only beams with limited attenuation correction\n# ...\nds_sr[\"zFactorCorrection\"].isel(cross_track=24).gpm.plot_cross_section(vmin=0, vmax=3, zoom=False)\nds_sr[\"zFactorCorrection\"].isel(range=-20).gpm.plot_map(vmin=0, vmax=6)\n\nHere we define the actual SR mask used to select the SR footprints on which the SR/GR matching will be performed.\nOnce again, we suggest to avoid, at this stage, being too restrictive in the selection of SR footprints.\n\n# Define 3D mask of SR gates matching GR PPI gates\n# - TIP: do not mask eccessively here ... but rather at final stage\nmask_matched_ppi_3d = mask_ppi & mask_sr_precip & mask_sr_quality\n\n# Define 2D mask of SR beams matching the GR PPI\nmask_matched_ppi_2d = mask_matched_ppi_3d.any(dim=\"range\")\nmask_matched_ppi_2d.gpm.plot_map()\n\n# Number of matching SR gates per beam\nn_matching_sr_gates = mask_matched_ppi_3d.sum(dim=\"range\")\nn_matching_sr_gates.where(n_matching_sr_gates > 0).gpm.plot_map()\n\n# Beam indices with at least one matching bin\ncross_track_indices, along_track_indices = np.where(mask_matched_ppi_3d.sum(dim=\"range\"))\n\n# Number of beams with at least one valid bin\nlen(along_track_indices)\n\n","type":"content","url":"/sr-gr-matching-procedure#define-sr-masks","position":43},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Aggregate SR radar gates"},"type":"lvl2","url":"/sr-gr-matching-procedure#aggregate-sr-radar-gates","position":44},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Aggregate SR radar gates"},"content":"In this subsection, we aggregate SR radar gates intersecting the GR sweep.\n\nSR reflectivities are averaged along the SR beam (approximately vertically) between the half-power points of the GR sweep.\n\nTo select SR radar gates for aggregation, the following criteria must be met:\n\nThe SR footprints must contain precipitation.\n\nThe SR radar gates must overlap with GR gates.\n\nThe SR radar gates must fall within a specified GR range distance, defined by min_gr_range and max_gr_range.\n\nThe min_gr_range ensures that the GR beamwidth is not smaller than the SR gate spacing.\n\nImportant Notes:\n\nReflectivity must not be aggregated in dBZ, but rather in mm6 m−3\n\n# Add variables to SR dataset\nds_sr[\"zFactorMeasured_Ku\"] = ds_sr[\"zFactorMeasured\"]\nds_sr[\"zFactorFinal_Ku\"] = ds_sr[\"zFactorFinal\"]\nds_sr[\"zFactorFinal_S\"] = da_z_s_final\nds_sr[\"zFactorMeasured_S\"] = da_z_s_measured\nds_sr[\"zFactorCorrection_Ku\"] = ds_sr[\"zFactorCorrection\"]\nds_sr[\"zFactorCorrection_S\"] = da_z_s_correction\nds_sr[\"hres\"] = h_res_sr\nds_sr[\"vres\"] = v_res_sr\nds_sr[\"gate_volume\"] = vol_sr\nds_sr[\"x\"] = x_sr\nds_sr[\"y\"] = y_sr\nds_sr[\"z\"] = z_sr\n\n# Compute path-integrated reflectivities\nds_sr[\"zFactorFinal_Ku_cumsum\"] = ds_sr[\"zFactorFinal\"].gpm.idecibel.cumsum(\"range\").gpm.decibel\nds_sr[\"zFactorFinal_Ku_cumsum\"] = ds_sr[\"zFactorFinal_Ku_cumsum\"].where(np.isfinite(ds_sr[\"zFactorFinal_Ku_cumsum\"]))\nds_sr[\"zFactorMeasured_Ku_cumsum\"] = ds_sr[\"zFactorMeasured\"].gpm.idecibel.cumsum(\"range\").gpm.decibel\nds_sr[\"zFactorMeasured_Ku_cumsum\"] = ds_sr[\"zFactorMeasured_Ku_cumsum\"].where(\n    np.isfinite(ds_sr[\"zFactorMeasured_Ku_cumsum\"]),\n)\nds_sr[\"zFactorFinal_S_cumsum\"] = ds_sr[\"zFactorFinal_S\"].gpm.idecibel.cumsum(\"range\").gpm.decibel\nds_sr[\"zFactorFinal_S_cumsum\"] = ds_sr[\"zFactorFinal_S_cumsum\"].where(np.isfinite(ds_sr[\"zFactorFinal_S_cumsum\"]))\nds_sr[\"zFactorMeasured_S_cumsum\"] = ds_sr[\"zFactorMeasured_S\"].gpm.idecibel.cumsum(\"range\").gpm.decibel\nds_sr[\"zFactorMeasured_S_cumsum\"] = ds_sr[\"zFactorMeasured_S_cumsum\"].where(\n    np.isfinite(ds_sr[\"zFactorMeasured_S_cumsum\"]),\n)\n\n# Add variables to the spaceborne dataset\nz_variables = [\"zFactorFinal_Ku\", \"zFactorFinal_S\", \"zFactorMeasured_Ku\", \"zFactorMeasured_S\"]\nsr_variables = [\n    *z_variables,\n    \"zFactorCorrection_Ku\",\n    \"zFactorCorrection_S\",\n    \"precipRate\",\n    \"airTemperature\",\n    \"zFactorFinal_Ku_cumsum\",\n    \"zFactorMeasured_Ku_cumsum\",\n    \"zFactorFinal_S_cumsum\",\n    \"zFactorMeasured_S_cumsum\",\n    \"hres\",\n    \"vres\",\n    \"gate_volume\",\n    \"x\",\n    \"y\",\n    \"z\",\n]\n\n# Initialize Dataset where to add aggregated SR gates\nds_sr_match_ppi = xr.Dataset()\n\n# Mask SR gates not matching the GR PPI\nds_sr_ppi = ds_sr[sr_variables].where(mask_matched_ppi_3d)\n\n# Compute aggregation statistics\nds_sr_ppi_min = ds_sr_ppi.min(\"range\")\nds_sr_ppi_max = ds_sr_ppi.max(\"range\")\nds_sr_ppi_sum = ds_sr_ppi.sum(dim=\"range\", skipna=True)\nds_sr_ppi_mean = ds_sr_ppi.mean(\"range\")\nds_sr_ppi_std = ds_sr_ppi.std(\"range\")\n\n# Aggregate reflectivities (in mm6/mm3)\nfor var in z_variables:\n    ds_sr_ppi_mean[var] = ds_sr_ppi[var].gpm.idecibel.mean(\"range\").gpm.decibel\n    ds_sr_ppi_std[var] = ds_sr_ppi[var].gpm.idecibel.std(\"range\").gpm.decibel\n    # If only 1 value, std=0, log transform become -inf --> Set to 0\n    is_inf = np.isinf(ds_sr_ppi_std[var])\n    ds_sr_ppi_std[var] = ds_sr_ppi_std[var].where(~is_inf, 0)\n\n# Compute counts and fractions above sensitivity thresholds\nsr_sensitivity_thresholds = [10, 12, 14, 16, 18]\nds_sr_match_ppi[\"SR_counts\"] = mask_matched_ppi_3d.sum(dim=\"range\")\nds_sr_match_ppi[\"SR_counts_valid\"] = (~np.isnan(ds_sr_ppi[\"zFactorFinal_Ku\"])).sum(dim=\"range\")\nfor var in z_variables:\n    for thr in sr_sensitivity_thresholds:\n        fraction = (ds_sr_ppi[var] >= thr).sum(dim=\"range\") / ds_sr_match_ppi[\"SR_counts\"]\n        ds_sr_match_ppi[f\"SR_{var}_fraction_above_{thr}dBZ\"] = fraction\n\n# Compute fraction of hydrometeor types\nda_hydro_class = ds_sr[\"flagHydroClass\"].where(mask_matched_ppi_3d)\nds_sr_match_ppi[\"SR_fraction_no_precip\"] = (da_hydro_class == 0).sum(dim=\"range\") / ds_sr_match_ppi[\"SR_counts\"]\nds_sr_match_ppi[\"SR_fraction_rain\"] = (da_hydro_class == 1).sum(dim=\"range\") / ds_sr_match_ppi[\"SR_counts\"]\nds_sr_match_ppi[\"SR_fraction_snow\"] = (da_hydro_class == 2).sum(dim=\"range\") / ds_sr_match_ppi[\"SR_counts\"]\nds_sr_match_ppi[\"SR_fraction_hail\"] = (da_hydro_class == 3).sum(dim=\"range\") / ds_sr_match_ppi[\"SR_counts\"]\nds_sr_match_ppi[\"SR_fraction_melting_layer\"] = (da_hydro_class == 4).sum(dim=\"range\") / ds_sr_match_ppi[\"SR_counts\"]\nds_sr_match_ppi[\"SR_fraction_clutter\"] = (da_hydro_class == 5).sum(dim=\"range\") / ds_sr_match_ppi[\"SR_counts\"]\nds_sr_match_ppi[\"SR_fraction_below_isotherm\"] = (ds_sr_ppi[\"airTemperature\"] >= 273.15).sum(\n    dim=\"range\",\n) / ds_sr_match_ppi[\"SR_counts\"]\nds_sr_match_ppi[\"SR_fraction_above_isotherm\"] = (ds_sr_ppi[\"airTemperature\"] < 273.15).sum(\n    dim=\"range\",\n) / ds_sr_match_ppi[\"SR_counts\"]\n\n# Add aggregation statistics\nfor var in ds_sr_ppi_mean.data_vars:\n    ds_sr_match_ppi[f\"SR_{var}_mean\"] = ds_sr_ppi_mean[var]\nfor var in ds_sr_ppi_std.data_vars:\n    ds_sr_match_ppi[f\"SR_{var}_std\"] = ds_sr_ppi_std[var]\nfor var in ds_sr_ppi_sum.data_vars:\n    ds_sr_match_ppi[f\"SR_{var}_sum\"] = ds_sr_ppi_sum[var]\nfor var in ds_sr_ppi_max.data_vars:\n    ds_sr_match_ppi[f\"SR_{var}_max\"] = ds_sr_ppi_max[var]\nfor var in ds_sr_ppi_min.data_vars:\n    ds_sr_match_ppi[f\"SR_{var}_min\"] = ds_sr_ppi_min[var]\nfor var in ds_sr_ppi_min.data_vars:\n    ds_sr_match_ppi[f\"SR_{var}_range\"] = ds_sr_ppi_max[var] - ds_sr_ppi_min[var]\n\n# Compute coefficient of variation\nfor var in z_variables:\n    ds_sr_match_ppi[f\"SR_{var}_cov\"] = ds_sr_match_ppi[f\"SR_{var}_std\"] / ds_sr_match_ppi[f\"SR_{var}_mean\"]\n\n# Add SR L2 variables (useful for final filtering and analysis)\nvar_l2 = [\n    \"flagPrecip\",\n    \"flagPrecipitationType\",\n    \"dataQuality\",\n    \"sunLocalTime\",\n    \"SCorientation\",\n    \"qualityFlag\",\n    \"qualityTypePrecip\",\n    \"qualityBB\",\n    \"pathAtten\",\n    \"piaFinal\",\n    \"reliabFlag\",\n]\nfor var in var_l2:\n    ds_sr_match_ppi[f\"SR_{var}\"] = ds_sr[var]\n\n# Add SR time\nds_sr_match_ppi[\"SR_time\"] = ds_sr_match_ppi[\"time\"]\nds_sr_match_ppi = ds_sr_match_ppi.drop(\"time\")\n\n# Mask SR beams not matching the GR PPI\nds_sr_match_ppi = ds_sr_match_ppi.where(mask_matched_ppi_2d)\n\n# Remove unecessary coordinates\nunecessary_coords = [\n    \"radar_frequency\",\n    \"sweep_mode\",\n    \"prt_mode\",\n    \"follow_mode\",\n    \"latitude\",\n    \"longitude\",\n    \"altitude\",\n    \"crs_wkt\",\n    \"time\",\n    \"crsWGS84\",\n    \"dataQuality\",\n    \"sunLocalTime\",\n    \"SCorientation\",\n]\nfor coord in unecessary_coords:\n    if coord in ds_sr_match_ppi:\n        ds_sr_match_ppi = ds_sr_match_ppi.drop(coord)\n    if coord in mask_matched_ppi_2d.coords:\n        mask_matched_ppi_2d = mask_matched_ppi_2d.drop(coord)\n\n# Stack aggregated dataset to beam dimension index\nds_sr_stack = ds_sr_match_ppi.stack(sr_beam_index=(\"along_track\", \"cross_track\"))\nda_mask_matched_ppi_stack = mask_matched_ppi_2d.stack(sr_beam_index=(\"along_track\", \"cross_track\"))\n\n# Drop beams not matching the GR PPI\nds_sr_match = ds_sr_stack.isel(sr_beam_index=da_mask_matched_ppi_stack)\n\n","type":"content","url":"/sr-gr-matching-procedure#aggregate-sr-radar-gates","position":45},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Display aggregated SR variables"},"type":"lvl2","url":"/sr-gr-matching-procedure#display-aggregated-sr-variables","position":46},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Display aggregated SR variables"},"content":"\n\n# Original SR near surface reflectivity\np = ds_sr[\"zFactorFinalNearSurface\"].gpm.plot_map(vmin=10, vmax=40)\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\n\n# Original GR reflectivities\np = ds_gr[\"DBZH\"].where(mask_gr).xradar_dev.plot_map(vmin=10, vmax=40)\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\nds_sr.gpm.plot_swath_lines(ax=p.axes)\n\n# SR reflectivity statistics matching the GR PPI (using xr.Dataset)\np = ds_sr_ppi_max[\"zFactorFinal_Ku\"].gpm.plot_map(cmap=cmap, vmin=10, vmax=40)\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\n\np = ds_sr_ppi_mean[\"zFactorFinal_Ku\"].gpm.plot_map(cmap=cmap, vmin=10, vmax=40)\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\n\np = ds_sr_ppi_mean[\"zFactorMeasured_Ku\"].gpm.plot_map(cmap=cmap, vmin=10, vmax=40)\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\n\n# Show difference between using Ku mean and max !\ndiff = ds_sr_ppi_max[\"zFactorFinal_Ku\"] - ds_sr_ppi_mean[\"zFactorFinal_Ku\"]\ndiff.name = \"Difference between Z max and Z mean\"\np = diff.gpm.plot_map(cmap=\"Spectral_r\")\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\n\n# Show SR mean precip rate\np = ds_sr_ppi_mean[\"precipRate\"].gpm.plot_map()\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\n\n# Display reflectivity in 3D\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection=\"3d\")\nax.scatter(\n    ds_sr_match[\"SR_x_mean\"].values,\n    ds_sr_match[\"SR_y_mean\"].values,\n    ds_sr_match[\"SR_z_mean\"].values,\n    c=ds_sr_match[\"SR_zFactorFinal_Ku_mean\"].values,\n    cmap=\"turbo\",\n    vmin=10,\n    vmax=40,\n    s=5,\n)\n\n# Disply SR footprint horizontal resolution\np = ds_sr_ppi_max[\"hres\"].gpm.plot_map(cmap=\"turbo\")\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\nplt.show()\n\n# Display SR depth over which data are integrated\np = ds_sr_ppi_sum[\"vres\"].gpm.plot_map(cmap=\"turbo\")\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\nplt.show()\n\n# Display SR volume over which data are integrated\np = ds_sr_ppi_sum[\"gate_volume\"].gpm.plot_map(cmap=\"turbo\")\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\nplt.show()\n\n# Display GR radar volume\np = vol_gr.xradar_dev.plot_map()\np.axes.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\nplt.show()\n\n","type":"content","url":"/sr-gr-matching-procedure#display-aggregated-sr-variables","position":47},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve the SR footprints polygons"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-the-sr-footprints-polygons","position":48},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve the SR footprints polygons"},"content":"Here we retrieve SR footprints polygons and then we construct a geopandas.DataFrame with the aggregated SR reflectivities.\n\n# Retrieve SR footprint polygons (using the footprint radius in AEQD x,y coordinates)\nxy_mean_sr = np.stack([ds_sr_match[\"SR_x_mean\"], ds_sr_match[\"SR_y_mean\"]], axis=-1)\nfootprint_radius = ds_sr_match[\"SR_hres_max\"].to_numpy() / 2\nsr_poly = [Point(x, y).buffer(footprint_radius[i]) for i, (x, y) in enumerate(xy_mean_sr)]\n\n# Create geopandas DataFrame\ndf_sr_match = ds_sr_match.to_dataframe()\ngdf_sr = gpd.GeoDataFrame(df_sr_match, crs=crs_gr, geometry=sr_poly)\ngdf_sr.columns\n\n# Extract radar gate polygon on the range-azimuth axis\nsr_poly = np.array(gdf_sr.geometry)\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-the-sr-footprints-polygons","position":49},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve the GR gates polygons"},"type":"lvl2","url":"/sr-gr-matching-procedure#retrieve-the-gr-gates-polygons","position":50},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Retrieve the GR gates polygons"},"content":"Here we retrieve GR gates polygons and then we construct a geopandas.DataFrame containing the GR measurements.\n\nCurrently the GR gates polygons are derived inferring the quadmesh around the GR gate centroids (using the x and y GR CRS coordinates).\n\nMore accurate GR gates polygons could be derived using the GR beamwidth. We welcome contributions addressing this point !\n\n# Add variables to GR dataset\nds_gr[\"gate_volume\"] = vol_gr\nds_gr[\"vres\"] = v_res_gr\nds_gr[\"hres\"] = h_res_gr\n\n# Add path_integrated_reflectivities\nds_gr[\"Z_cumsum\"] = ds_gr[\"DBZH\"].gpm.idecibel.cumsum(\"range\").gpm.decibel\nds_gr[\"Z_cumsum\"] = ds_gr[\"Z_cumsum\"].where(np.isfinite(ds_gr[\"Z_cumsum\"]))\n\n# Mask reflectivites above minimum GR Z threshold\nmask_gr = ds_gr[\"DBZH\"] > z_min_threshold_gr  # important !\n\n# Subset gates in range distance interval\nds_gr_subset = ds_gr.sel(range=slice(min_gr_range_lb, max_gr_range_ub)).where(mask_gr)\n\n# Retrieve geopandas dataframe\ngdf_gr = ds_gr_subset.xradar_dev.to_geopandas()  # here we currently infer the quadmesh using the x,y coordinates\ndisplay(gdf_gr)\n\n# Extract radar gate polygon on the range-azimuth axis\ngr_poly = np.array(gdf_gr.geometry)\n\n","type":"content","url":"/sr-gr-matching-procedure#retrieve-the-gr-gates-polygons","position":51},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Aggregate GR data on SR footprints"},"type":"lvl2","url":"/sr-gr-matching-procedure#aggregate-gr-data-on-sr-footprints","position":52},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Aggregate GR data on SR footprints"},"content":"\n\nTo aggregate GR radar gates onto SR beam polygon footprints, we will use the PolyAggregator.\nThe PolyAggregator enable custom aggregation of source (GR) polygons data intesecting the target (SR) polygons.\n\nWhen aggregating the data, you can use a combination of weighting schemes\nBy default, PolyAggregator applies area_weighting, which assigns weights based on the proportion of\nsource polygon area that intersects the target polygon.\n\nCustom Weighting Schemes\n\nSeveral additional weighting schemes can be utilized, typically derived as a function of the horizontal distance between the centroids of the source and target polygons. Examples include:\n\nInverse Distance Weighting: \\text{weights} = \\frac{1}{\\text{dist}^{\\text{order}}}\n\nBarnes Gaussian Weighting: \\text{weights} = \\exp\\left(-\\frac{\\text{dist}^2}{\\kappa^2}\\right)\n\nCressman Weighting: \\text{weights} = \\frac{\\text{max\\_distance}^2 - \\text{dist}^2}{\\text{max\\_distance}^2 + \\text{dist}^2}\n\nFor example, the Barnes Gaussian Distance Weighting Scheme weights values proportionally to the distance measured from the center of the SR footprint to the center of the GR radar gate. This approach can partially account  for the nonuniform distribution of\npower within the SR beam.\n\nCustom weights can however also be passed to PolyAggregator, which will automatically handle normalization.\n\nIn the context of SR/GR matching, it may be beneficial to adopt a Volume Weighting Scheme, using the volumes of GR radar gates as weights so that larger volumes are weighted more heavily.\n\nIn the code here below, we currently apply only the Area Weighting Scheme:\n\n# Define PolyAggregator\naggregator = PolyAggregator(source_polygons=gr_poly, target_polygons=sr_poly)\n\n# Aggregate GR reflecitvities and compute statistics\n# - Timestep of acquisition\ntime_gr = aggregator.first(values=gdf_gr[\"time\"])\n\n# - Total number of gates aggregated\ncounts = aggregator.counts()\ncounts_valid = aggregator.apply(lambda x, weights: np.sum(~np.isnan(x)), values=gdf_gr[\"DBZH\"])  # noqa\n\n# - Total gate volume\nsum_vol = aggregator.sum(values=gdf_gr[\"gate_volume\"])\n\n# - Fraction of SR area covered\nfraction_covered_area = aggregator.fraction_covered_area()\n\n# - Reflectivity statistics\nz_mean = wrl.trafo.decibel(aggregator.average(values=wrl.trafo.idecibel(gdf_gr[\"DBZH\"])))\nz_std = wrl.trafo.decibel(aggregator.std(values=wrl.trafo.idecibel(gdf_gr[\"DBZH\"])))\nz_std[np.isinf(z_std)] = 0  # If only 1 value, std=0, log transform become -inf --> Set to 0\nz_max = aggregator.max(values=gdf_gr[\"DBZH\"])\nz_min = aggregator.min(values=gdf_gr[\"DBZH\"])\nz_range = z_max - z_min\nz_cov = z_std / z_mean  # coefficient of variation\n\nNow we create a geopandas.DataFrame with aggregated GR statistics:\n\n# Create DataFrame with GR matched statistics\ndf = pd.DataFrame(\n    {\n        \"GR_Z_mean\": z_mean,\n        \"GR_Z_std\": z_std,\n        \"GR_Z_max\": z_max,\n        \"GR_Z_min\": z_min,\n        \"GR_Z_range\": z_range,\n        \"GR_Z_cov\": z_cov,\n        \"GR_time\": time_gr,\n        \"GR_gate_volume_sum\": sum_vol,\n        \"GR_fraction_covered_area\": fraction_covered_area,\n        \"GR_counts\": counts,\n        \"GR_counts_valid\": counts_valid,\n    },\n    index=gdf_sr.index,\n)\ngdf_gr_match = gpd.GeoDataFrame(df, crs=crs_gr, geometry=aggregator.target_polygons)\ngdf_gr_match.head()\n\n# Add GR range statistics\ngdf_gr_match[\"GR_range_max\"] = aggregator.max(values=gdf_gr[\"range\"])\ngdf_gr_match[\"GR_range_mean\"] = aggregator.mean(values=gdf_gr[\"range\"])\ngdf_gr_match[\"GR_range_min\"] = aggregator.min(values=gdf_gr[\"range\"])\n\n# Fraction above sensitivity thresholds\ngr_sensitivity_thresholds = [8, 10, 12, 14, 16, 18]\nfor thr in sr_sensitivity_thresholds:\n    fraction = aggregator.apply(lambda x, weights: np.sum(x > thr), values=gdf_gr[\"DBZH\"]) / counts  # noqa\n    gdf_gr_match[f\"GR_Z_fraction_above_{thr}dBZ\"] = fraction\n\n# Compute further aggregation statistics\nstats_var = [\"vres\", \"hres\", \"x\", \"y\", \"z\", \"Z_cumsum\"]\nfor var in stats_var:\n    gdf_gr_match[f\"GR_{var}_mean\"] = aggregator.average(values=gdf_gr[var])\n    gdf_gr_match[f\"GR_{var}_min\"] = aggregator.min(values=gdf_gr[var])\n    gdf_gr_match[f\"GR_{var}_max\"] = aggregator.max(values=gdf_gr[var])\n    gdf_gr_match[f\"GR_{var}_std\"] = aggregator.std(values=gdf_gr[var])\n    gdf_gr_match[f\"GR_{var}_range\"] = gdf_gr_match[f\"GR_{var}_max\"] - gdf_gr_match[f\"GR_{var}_min\"]\n\n# Compute horizontal distance between centroids\nfunc_dict = {\"min\": np.min, \"mean\": np.mean, \"max\": np.max}\nfor suffix, func in func_dict.items():\n    arr = np.zeros(aggregator.n_target_polygons) * np.nan\n    arr[aggregator.target_intersecting_indices] = np.array(\n        [func(dist) for i, dist in aggregator.dict_distances.items()],\n    )\n    gdf_gr_match[f\"distance_horizontal_{suffix}\"] = arr\n\n\n\nTo compute custom statistics, you can use the following approaches. Remember that the function must have the values and weights arguments. Add the weights argument also if they are not used in your function !\n\ndef weighted_mean(values, weights):\n    return np.average(values, weights=weights)\n\n\naggregated_values = aggregator.apply(weighted_mean, values=gdf_gr[\"DBZH\"], area_weighting=True)\naggregated_values = aggregator.apply(\n    lambda x, weights: np.average(x, weights=weights),\n    values=gdf_gr[\"DBZH\"],\n    area_weighting=True,\n)\n\nHere below we compare the usage of Inverse Distance Weighting, Barnes Gaussian Distance Weighting, Cressman Weighting, and Volume Weighting.\n\nfrom gpm.utils.zonal_stats import BarnesGaussianWeights, CressmanWeights, InverseDistanceWeights, PolyAggregator\n\ngdf_gr_match1 = gdf_gr_match.copy()\n\n# Weighted by intersection area\ngdf_gr_match1[\"GR_Z_area\"] = aggregator.mean(values=gdf_gr[\"DBZH\"], area_weighting=True)\n\n# Weighted by ntersection area and Inverse Distance Weighting\ngdf_gr_match1[\"GR_Z_idw\"] = aggregator.mean(\n    values=gdf_gr[\"DBZH\"],\n    area_weighting=True,\n    distance_weighting=InverseDistanceWeights(order=1),\n)\n# Weighted by intersection area and Cressman Weighting\ngdf_gr_match1[\"GR_Z_cressman\"] = aggregator.mean(\n    values=gdf_gr[\"DBZH\"],\n    area_weighting=True,\n    distance_weighting=CressmanWeights(max_distance=2000),\n)\n# Weighted by intersection area and Barnes Gaussian Weighting (kappa=SR_hres_mean)\ngdf_gr_match1[\"GR_Z_barnes\"] = aggregator.mean(\n    values=gdf_gr[\"DBZH\"],\n    area_weighting=True,\n    distance_weighting=BarnesGaussianWeights(kappa=gdf_sr[\"SR_hres_mean\"]),\n)\n# Weighted Barnes Gaussian Weighting (kappa=SR_radius_mean)\ngdf_gr_match1[\"GR_Z_barnes_without_area\"] = aggregator.mean(\n    values=gdf_gr[\"DBZH\"],\n    area_weighting=False,\n    distance_weighting=BarnesGaussianWeights(kappa=gdf_sr[\"SR_hres_mean\"]),\n)\n# Weighted by intersection area and by GR volume\ngdf_gr_match1[\"GR_Z_volume\"] = aggregator.mean(\n    values=gdf_gr[\"DBZH\"],\n    weights=gdf_gr[\"gate_volume\"],\n    area_weighting=True,\n)\n\ngdf_gr_match1.plot(column=\"GR_Z_area\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=40)\ngdf_gr_match1.plot(column=\"GR_Z_idw\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=40)\ngdf_gr_match1.plot(column=\"GR_Z_cressman\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=40)\ngdf_gr_match1.plot(column=\"GR_Z_barnes\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=40)\ngdf_gr_match1.plot(column=\"GR_Z_volume\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=40)\n\n# Impact of Barnes with and without area-weighting\ngdf_gr_match1[\"DIFF_Barnes_Without_Area\"] = gdf_gr_match1[\"GR_Z_barnes\"] - gdf_gr_match1[\"GR_Z_barnes_without_area\"]\ngdf_gr_match1.plot(column=\"DIFF_Barnes_Without_Area\", legend=True, cmap=\"Spectral_r\", vmin=-0.25, vmax=0.25)\n\n# Impact of Barnes with area-weighting and default area weighting\ngdf_gr_match1[\"DIFF_Barnes_Naive\"] = gdf_gr_match1[\"GR_Z_area\"] - gdf_gr_match1[\"GR_Z_barnes\"]\ngdf_gr_match1.plot(column=\"DIFF_Barnes_Naive\", legend=True, cmap=\"Spectral_r\", vmin=-0.25, vmax=0.25)\n\n","type":"content","url":"/sr-gr-matching-procedure#aggregate-gr-data-on-sr-footprints","position":53},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Create the SR/GR Database"},"type":"lvl2","url":"/sr-gr-matching-procedure#create-the-sr-gr-database","position":54},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Create the SR/GR Database"},"content":"Let’s back to our main task and merge SR/GR aggregated variables into an unique database:\n\n# Create DataFrame with matched variables\ngdf_match = gdf_gr_match.merge(gdf_sr, on=\"geometry\")\n\n# Compute ratio SR/GR volume\ngdf_match[\"VolumeRatio\"] = gdf_match[\"SR_gate_volume_sum\"] / gdf_match[\"GR_gate_volume_sum\"]\n\n# Compute difference in SR/GR gate volume\ngdf_match[\"VolumeDiff\"] = gdf_match[\"SR_gate_volume_sum\"] - gdf_match[\"GR_gate_volume_sum\"]\n\n# Compute time difference [in seconds]\ngdf_match[\"time_difference\"] = gdf_match[\"GR_time\"] - gdf_match[\"SR_time\"]\ngdf_match[\"time_difference\"] = gdf_match[\"time_difference\"].dt.total_seconds().astype(int)\n\n# Compute lower bound and upper bound height\ngdf_match[\"GR_z_lower_bound\"] = gdf_match[\"GR_z_min\"] - gdf_match[\"GR_vres_mean\"] / 2\ngdf_match[\"GR_z_upper_bound\"] = gdf_match[\"GR_z_max\"] + gdf_match[\"GR_vres_mean\"] / 2\n\ngdf_match[\"SR_z_lower_bound\"] = gdf_match[\"SR_z_min\"] - gdf_match[\"SR_vres_mean\"] / 2\ngdf_match[\"SR_z_upper_bound\"] = gdf_match[\"SR_z_max\"] + gdf_match[\"SR_vres_mean\"] / 2\n\n","type":"content","url":"/sr-gr-matching-procedure#create-the-sr-gr-database","position":55},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Analyse the SR/GR Database"},"type":"lvl2","url":"/sr-gr-matching-procedure#analyse-the-sr-gr-database","position":56},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Analyse the SR/GR Database"},"content":"\n\n# Show fraction SR footprint horizontal area covered by GR\ngdf_match.plot(column=\"GR_fraction_covered_area\", legend=True, cmap=\"Spectral_r\")\n\n# Show ratio SR/GR volume\ngdf_match.plot(column=\"VolumeRatio\", legend=True, cmap=\"Spectral_r\")\n\n# Show difference in total gate volume\ngdf_match.plot(column=\"VolumeDiff\", legend=True, cmap=\"Spectral_r\")\n\ngdf_gr_match.plot(column=\"distance_horizontal_max\", legend=True, cmap=\"Spectral_r\")\ngdf_gr_match.plot(column=\"distance_horizontal_mean\", legend=True, cmap=\"Spectral_r\")\ngdf_gr_match.plot(column=\"distance_horizontal_min\", legend=True, cmap=\"Spectral_r\")\n\n# Analyse variations in gate resolution\ngdf_match.plot(column=\"GR_vres_mean\", legend=True, cmap=\"Spectral_r\")\ngdf_match.plot(column=\"SR_vres_mean\", legend=True, cmap=\"Spectral_r\")\n\n# Analyse variations in minimum and maximum gate elevation\ngdf_match.plot(column=\"GR_z_upper_bound\", legend=True, cmap=\"Spectral_r\")\ngdf_match.plot(column=\"SR_z_upper_bound\", legend=True, cmap=\"Spectral_r\")\n\ngdf_match.plot(column=\"GR_z_lower_bound\", legend=True, cmap=\"Spectral_r\")\ngdf_match.plot(column=\"SR_z_lower_bound\", legend=True, cmap=\"Spectral_r\")\n\n# Analyse fraction hydrometeors and sensitivity\ngdf_match.plot(column=\"SR_counts\", legend=True, cmap=\"Spectral_r\", vmin=0)\ngdf_match.plot(column=\"SR_counts_valid\", legend=True, cmap=\"Spectral_r\", vmin=0)\n\ngdf_match.plot(column=\"SR_fraction_clutter\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n\n# gdf_match.plot(column=\"SR_fraction_melting_layer\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n# gdf_match.plot(column=\"SR_fraction_hail\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n# gdf_match.plot(column=\"SR_fraction_snow\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n# gdf_match.plot(column=\"SR_fraction_rain\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n# gdf_match.plot(column=\"SR_fraction_no_precip\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n# gdf_match.plot(column=\"SR_fraction_below_isotherm\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n# gdf_match.plot(column=\"SR_fraction_above_isotherm\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n\n# Analyse sensitivity\ngdf_match.plot(column=\"GR_Z_fraction_above_10dBZ\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n# gdf_match.plot(column=\"GR_Z_fraction_above_12dBZ\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n# gdf_match.plot(column=\"GR_Z_fraction_above_14dBZ\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n\ngdf_match.plot(column=\"SR_zFactorFinal_Ku_fraction_above_12dBZ\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n# gdf_match.plot(column=\"SR_zFactorFinal_Ku_fraction_above_14dBZ\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n# gdf_match.plot(column=\"SR_zFactorFinal_Ku_fraction_above_16dBZ\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n\n# Analyse SR attenuation statistics\ngdf_match.plot(column=\"SR_reliabFlag\", legend=True, cmap=\"Spectral_r\")\ngdf_match.plot(column=\"SR_pathAtten\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=5)\ngdf_match.plot(column=\"SR_piaFinal\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=5)\ngdf_match.plot(column=\"SR_zFactorCorrection_Ku_max\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=5)\n\n# Analyse SR NUBF\ngdf_match.plot(column=\"SR_zFactorFinal_Ku_std\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=8)\ngdf_match.plot(column=\"GR_Z_std\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=8)\n\n# gdf_match.plot(column=\"SR_zFactorFinal_Ku_range\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=8)\n# gdf_match.plot(column=\"GR_Z_range\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=20)\n\n# gdf_match.plot(column=\"SR_zFactorFinal_Ku_cov\", legend=True, cmap=\"Spectral_r\")\n# gdf_match.plot(column=\"GR_Z_cov\", legend=True, cmap=\"Spectral_r\")\n\n# gdf_match[\"SR_zFactorFinal_Ku_range_rel\"] = gdf_match[\"SR_zFactorFinal_Ku_range\"]/gdf_match[\"SR_zFactorFinal_Ku_mean\"]\n# gdf_match.plot(column=\"SR_zFactorFinal_Ku_range_rel\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=1)\n\n# gdf_match[\"GR_Z_range_rel\"] = gdf_match[\"GR_Z_range\"]/gdf_match[\"GR_Z_mean\"]\n# gdf_match.plot(column=\"GR_Z_range_rel\", legend=True, cmap=\"Spectral_r\")\n\n# Compare reflectivities\nextent_xy = gdf_sr.total_bounds[[0, 2, 1, 3]]\np = gdf_match.plot(\n    column=\"SR_zFactorFinal_Ku_mean\",\n    legend=True,\n    legend_kwds={\"label\": \"SR Reflectivity (dBz)\"},\n    cmap=\"Spectral_r\",\n    vmin=10,\n    vmax=40,\n)\np.axes.set_xlim(extent_xy[0:2])\np.axes.set_ylim(extent_xy[2:4])\np.axes.set_title(\"SR\")\nplt.xlabel(\"x (m)\", fontsize=12)\nplt.ylabel(\"y (m)\", fontsize=12)\nplt.grid(lw=0.25, color=\"grey\")\n\np = gdf_match.plot(\n    column=\"GR_Z_mean\",\n    legend=True,\n    legend_kwds={\"label\": \"GR Reflectivity (dBz)\"},\n    cmap=\"Spectral_r\",\n    vmin=10,\n    vmax=40,\n)\np.axes.set_xlim(extent_xy[0:2])\np.axes.set_ylim(extent_xy[2:4])\np.axes.set_title(\"GR\")\nplt.xlabel(\"x (m)\", fontsize=12)\nplt.ylabel(\"y (m)\", fontsize=12)\nplt.grid(lw=0.25, color=\"grey\")\n\n# Compute difference (also with bias removed)\ngdf_match[\"DIFF_Z_SR_GR\"] = gdf_match[\"SR_zFactorFinal_Ku_mean\"] - gdf_match[\"GR_Z_mean\"]\ngdf_match[\"DIFF_Z_GR_SR\"] = gdf_match[\"GR_Z_mean\"] - gdf_match[\"SR_zFactorFinal_Ku_mean\"]\nbias_gr_sr = np.nanmedian(gdf_match[\"DIFF_Z_GR_SR\"]).round(2)\nbias_sr_gr = np.nanmedian(gdf_match[\"DIFF_Z_SR_GR\"]).round(2)\np = gdf_match.plot(\n    column=\"DIFF_Z_SR_GR\",\n    legend_kwds={\"label\": \"SR-GR Reflectivity Difference (dBz)\"},\n    cmap=\"RdBu\",\n    legend=True,\n    vmax=10,\n)\np.axes.set_xlim(extent_xy[0:2])\np.axes.set_ylim(extent_xy[2:4])\np.axes.set_title(\"SR - GR\")\nplt.xlabel(\"x (m)\", fontsize=12)\nplt.ylabel(\"y (m)\", fontsize=12)\nplt.grid(lw=0.25, color=\"grey\")\n\ngdf_match[\"DIFF_Z_GR_SR_unbiased\"] = gdf_match[\"DIFF_Z_GR_SR\"] - bias_gr_sr\np = gdf_match.plot(\n    column=\"DIFF_Z_GR_SR_unbiased\",\n    legend_kwds={\"label\": \"SR-GR Reflectivity Difference (wihout bias) (dBz)\"},\n    cmap=\"RdBu\",\n    legend=True,\n    vmin=-4,\n    vmax=4,\n)\np.axes.set_xlim(extent_xy[0:2])\np.axes.set_ylim(extent_xy[2:4])\np.axes.set_title(\"SR - GR\")\nplt.xlabel(\"x (m)\", fontsize=12)\nplt.ylabel(\"y (m)\", fontsize=12)\nplt.grid(lw=0.25, color=\"grey\")\n\n\n\nHere we show how to explore interactively the reflectivity fields using Folium:\n\ngdf_match1 = gdf_match.copy()\ngdf_match1.explore(column=\"GR_Z_mean\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=40)\n\n\n\nHere we show how to plot cartopy maps in WGS84 and GR CRS AEQD.\n\n# Define Cartopy AEQD CRS\nccrs_aeqd = ccrs.AzimuthalEquidistant(\n    central_longitude=ds_gr[\"longitude\"].item(),\n    central_latitude=ds_gr[\"latitude\"].item(),\n)\n\n# Define Cartopy WGS84 CRS\nccrs_wgs84 = ccrs.PlateCarree()\n\n# Print CRS of geopandas geometries\ngdf_match.crs\n\n# Plot in AEQD CRS (same crs of geopandas geometries)\nfig, ax = plt.subplots(subplot_kw={\"projection\": ccrs_aeqd})\ngdf_match.plot(ax=ax, column=\"GR_Z_mean\", cmap=\"turbo\", legend=True)\n\n# Convert geopandas dataframe to another crs\ngdf_match_wgs84 = gdf_match.to_crs(crs_sr)\n# Plot in WGS84 CRS\nfig, ax = plt.subplots(subplot_kw={\"projection\": ccrs_wgs84})\n# plot_cartopy_background(ax)\ngdf_match_wgs84.plot(ax=ax, column=\"GR_Z_mean\", cmap=\"turbo\", legend=True)\nax.set_extent(ds_gr.xradar_dev.extent(max_distance=max_gr_range))\n\n","type":"content","url":"/sr-gr-matching-procedure#analyse-the-sr-gr-database","position":57},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Filter the SR/GR Database"},"type":"lvl2","url":"/sr-gr-matching-procedure#filter-the-sr-gr-database","position":58},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Filter the SR/GR Database"},"content":"When calibrating or comparing SR and GR data, there is a necessary tradeoff between the strictness of filtering criteria filtering and the number of available samples. Here below we provide some general recommendations for effective filtering:\n\nSensitivity Thresholds: Retain only those radar beams where the aggregated gate reflectivities exceed the instrument sensitivities.\nThe GR_Z_fraction_above_<thr>dBZ and SR_zFactorFinal_Ku_fraction_above_<thr>dBZ variables can be used filter the samples.\n\nStratiform Precipitation:  If the purpose of your analysis is to assess the calibration bias of GR data, it is suggested to focus on stratiform precipitation that ocurrs outside the melting layer (i.e. avoiding the bright band). Only stratiform samples above the melting layer are used in ground validation of the GPM DPR (W. Petersen 2017, personal communication).\nConvective SR footprints are typically excluded to avoid dealing with:\n\nthe high spatial variability in the precipitation field and issues with non-uniform beam filling (NUBF),\n\nthe potential biases introduced by the SR attenuation correction,\n\nthe potential biases in GR reflectivities, especially at C and X band, due to beam attenuation,\n\nthe multiple scattering signature caused by hail particles.\n\nReflectivity Range: According to Warren et al. (2018), volume-averaged SR and GR reflectivity values should be selected within the range of 24 to 36 dBZ. This range minimizes the impact of low SR sensitivity,  SR beam attenuation and non-rayleigh scattering effects.\n\nClutter Removal: Exclude SR/GR samples that are contaminated by ground clutter, anomalous propagation, or beam blockage.\n\nVolume matching: Exclude SR/GR samples where there are excessive differences in the total gate volume.\n\n# Define mask\nmasks = [\n    # Select SR scan with \"normal\" dataQuality (for entire cross-track scan)\n    gdf_match[\"SR_dataQuality\"] == 0,\n    # Select SR beams with detected precipitation\n    gdf_match[\"SR_flagPrecip\"] > 0,\n    # Select only 'high quality' SR data\n    # - qualityFlag == 1 indicates low quality retrievals\n    # - qualityFlag == 2 indicates bad/missing retrievals\n    gdf_match[\"SR_qualityFlag\"] == 0,\n    # Select SR beams with SR above minimum reflectivity\n    gdf_match[\"SR_zFactorFinal_Ku_fraction_above_12dBZ\"] > 0.95,\n    # Select SR beams with GR above minimum reflectivity\n    gdf_match[\"GR_Z_fraction_above_10dBZ\"] > 0.95,\n    # Select only SR beams with detected bright band\n    gdf_match[\"SR_qualityBB\"] == 1,\n    # Select only beams with confident precipitation type\n    gdf_match[\"SR_qualityTypePrecip\"] == 1,\n    # Select only stratiform precipitation\n    # - SR_flagPrecipitationType == 2 indicates convective\n    gdf_match[\"SR_flagPrecipitationType\"] == 1,\n    # Select only SR beams with reliable attenuation correction\n    gdf_match[\"SR_reliabFlag\"].isin((1, 2)),  # or == 1\n    # Select only beams with reduced path attenuation\n    # gdf_match[\"SR_zFactorCorrection_Ku_max\"]\n    # gdf_match[\"SR_piaFinal\"]\n    # gdf_match[\"SR_pathAtten\"]\n    # Select only SR beams with matching SR gates with no clutter\n    gdf_match[\"SR_fraction_clutter\"] == 0,\n    # Select only SR beams with matching SR gates not in the melting layer\n    gdf_match[\"SR_fraction_melting_layer\"] == 0,\n    # Select only SR beams with matching SR gates with precipitation\n    gdf_match[\"SR_fraction_no_precip\"] == 0,\n    # Select only SR beams with matching SR gates with no hail\n    # gdf_match[\"SR_fraction_hail\"] == 0,\n    # Select only SR beams with matching SR gates with rain\n    # gdf_match[\"SR_fraction_hail\"] == 1,\n    # Select only SR beams with matching SR gates with snow\n    # gdf_match[\"SR_fraction_snow\"] == 1,\n    # Discard SR beams with high NUBF\n    # gdf_match[\"SR_zFactorFinal_Ku_range\"] > 5,\n    # gdf_match[\"SR_zFactorFinal_Ku_cov\"] < 0.5,\n    # gdf_match[\"GR_Z_cov\"] < 0.5,\n    # gdf_match[\"GR_Z_range\"] > 5,\n    # Select only interval of reflectivities\n    # - Warren et al., 2018:  between 24 and 36 dBZ\n    # (gdf_match[\"SR_zFactorFinal_Ku_mean\"] > 24) & (gdf_match[\"SR_zFactorFinal_Ku_mean\"] < 36),\n    # (gdf_match[\"GR_Z_mean\"] > 24) & (gdf_match[\"GR_Z_mean\"] < 36),\n    # Select SR beams only within given GR radius interval\n    # (gdf_match[\"GR_range_min\"] > min_gr_range) & (gdf_match[\"GR_range_max\"] < max_gr_range),\n    # Discard SR beams where scanning time difference (provided in seconds)\n    gdf_match[\"time_difference\"] < 5 * 60,  # 5 min\n    # Discard SR beams where GR gates does not cover 80% of the horizontal area\n    # gdf_match[\"GR_fraction_covered_area\"] > 0.8,\n    # Filter footprints where volume ratio exceeds 60\n    # gdf_match[\"VolumeRatio\"] > 60,\n    # Filter footprints where GR affected by beam blockage\n    # TODO: Filtering by beam blockage\n]\n\n# Define final mask\nmask_final = reduce(np.logical_and, masks)\n\n# Dsplay final filtering mask\ngdf_match[\"filtering_mask\"] = mask_final\ngdf_match.plot(column=\"filtering_mask\", legend=True, cmap=\"Spectral\")\ngdf_match.plot(column=\"SR_zFactorFinal_Ku_mean\", legend=True, cmap=\"Spectral\")\n\n# Filter matching dataset\ngdf_final = gdf_match[mask_final]\n\n# Plot results\ngdf_final.plot(column=\"SR_zFactorFinal_Ku_mean\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=40)\ngdf_final.plot(column=\"GR_Z_mean\", legend=True, cmap=\"Spectral_r\", vmin=0, vmax=40)\n\n","type":"content","url":"/sr-gr-matching-procedure#filter-the-sr-gr-database","position":59},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Determine the GR Calibration Bias"},"type":"lvl2","url":"/sr-gr-matching-procedure#determine-the-gr-calibration-bias","position":60},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Determine the GR Calibration Bias"},"content":"\n\n# Compute statistics\nbias = np.nanmean(gdf_match[\"DIFF_Z_GR_SR\"]).round(2)\nrobBias = np.nanmedian(gdf_match[\"DIFF_Z_GR_SR\"]).round(2)\n\n# R2 (pearson, spearman rank)\nprint(f\"Th ZH Calibration offset is (mean): {bias} dB\")\nprint(f\"Th ZH Calibration offset is (median): {robBias} dB\")\n\n# Comparison of GR vs SR reflectivities\nhue_variable = \"VolumeDiff\"\nhue_title = \"Difference in volume between SR and GR [m³]\"\n\n# - Histograms\nfig = plt.figure(figsize=(12, 5))\nax = fig.add_subplot(121, aspect=\"equal\")\nplt.scatter(\n    gdf_match[\"GR_Z_mean\"],\n    gdf_match[\"SR_zFactorFinal_Ku_mean\"],\n    marker=\"+\",\n    c=gdf_match[hue_variable],\n    cmap=\"turbo\",\n)\nplt.colorbar(label=hue_title)\nplt.plot([0, 60], [0, 60], linestyle=\"solid\", color=\"black\")\nplt.xlim(10, 50)\nplt.ylim(10, 50)\nplt.xlabel(\"GR reflectivity (dBZ)\")\nplt.ylabel(\"SR reflectivity (dBZ)\")\nplt.title(f\"Offset GR-SR: {bias} dBZ\")\nax = fig.add_subplot(122)\nplt.hist(\n    gdf_match[\"GR_Z_mean\"][gdf_match[\"GR_Z_mean\"] > z_min_threshold_gr],\n    bins=np.arange(10, 60, 5),\n    edgecolor=\"None\",\n    label=\"GR\",\n)\nplt.hist(\n    gdf_match[\"SR_zFactorFinal_Ku_mean\"][gdf_match[\"SR_zFactorFinal_Ku_mean\"] > z_min_threshold_sr],\n    bins=np.arange(10, 60, 5),\n    edgecolor=\"red\",\n    facecolor=\"None\",\n    label=\"SR\",\n)\nplt.xlabel(\"Reflectivity (dBZ)\")\nplt.legend()\nfig.suptitle(\"GR vs SR\")\n\n","type":"content","url":"/sr-gr-matching-procedure#determine-the-gr-calibration-bias","position":61},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Next Steps"},"type":"lvl2","url":"/sr-gr-matching-procedure#next-steps","position":62},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Next Steps"},"content":"\n\nCongratulations on reaching the end of this tutorial!\nIf you have suggestions for improving this tutorial or the SR/GR matching process, please feel free to open\na Pull Request or create a GitHub issue on the \n\nGPM-API GitHub repository.\n\nThe code for the SR/GR matching process is encapsulated in the volume_matching function contained in the \n\ngpm.gv module. User are free to use or adapt such function to accomplish their tasks.\nThe \n\nSpaceborne-Ground Radar Calibration Applied Tutorial shows how to assess the GR calibration bias by abstracting away the complexities discussed in this tutorial.\n\n","type":"content","url":"/sr-gr-matching-procedure#next-steps","position":63},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"References"},"type":"lvl2","url":"/sr-gr-matching-procedure#references","position":64},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"References"},"content":"\n\nCao, Q., Y. Hong, Y. Qi, Y. Wen, J. Zhang, J. J. Gourley, and L. Liao, 2013: Empirical conversion of the vertical profile of reflectivity from Ku-band to S-band frequency. J. Geophys. Res. Atmos., 118, 1814–1825, https://doi.org/10.1002/jgrd.50138\n\nSchwaller, MR, and Morris, KR. 2011. A ground validation network for the Global Precipitation Measurement mission. J. Atmos. Oceanic Technol., 28, 301-319.28, https://doi.org/10.1175/2010JTECHA1403.1\n\nWarren, R.A., A. Protat, S.T. Siems, H.A. Ramsay, V. Louf, M.J. Manton, and T.A. Kane, 2018. Calibrating ground-based radars against TRMM and GPM. J. Atmos. Oceanic Technol., 35, 323–346, https://doi.org/10.1175/JTECH-D-17-0128.1\n\n","type":"content","url":"/sr-gr-matching-procedure#references","position":65},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Citation"},"type":"lvl2","url":"/sr-gr-matching-procedure#citation","position":66},{"hierarchy":{"lvl1":"Spaceborne-Ground Radar Matching (Methodology)","lvl2":"Citation"},"content":"\n\nThis notebook is part of the \n\nGPM-API  documentation.\n\nLarge portions of this tutorials were adapted and derived from an old \\omega radlib  tutorial.\n\nCopyright: \\omega radlib  and GPM-API developers.\nDistributed under the MIT License. See \n\nGPM-API license for more info.","type":"content","url":"/sr-gr-matching-procedure#citation","position":67},{"hierarchy":{"lvl1":"Introduction to GPM-API"},"type":"lvl1","url":"/gpm-api-intro","position":0},{"hierarchy":{"lvl1":"Introduction to GPM-API"},"content":"In this tutorial, we will provide the foundations to use GPM-API to download, manipulate and analyze data from the Global Precipitation Measurement (GPM) spaceborne radars.\n\nPlease note that GPM-API also enable access and analysis tools for the entire GPM constellation of passive microwave sensors as well as the IMERG precipitation products.\nFor detailed information and additional tutorials, please refer to the \n\nofficial GPM-API documentation.\n\nFirst, let’s import the package required in this tutorial.\n\nimport datetime\nimport gpm\nimport fsspec\nimport numpy as np\nimport ximage  # noqa\nimport xarray as xr\nfrom xarray.backends.api import open_datatree\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nfrom gpm.utils.geospatial import (\n    get_country_extent,\n    get_geographic_extent_around_point,\n    get_circle_coordinates_around_point,\n)\nfrom gpm.gv import volume_matching, compare_maps, calibration_summary\n\nUsing the available_products function, users can obtain a list of all GPM products that can be downloaded and opened into CF-compliant xarray datasets.\n\ngpm.available_products(product_types=\"RS\")  # research products\n\nLet’s have a look at the available RADAR products:\n\ngpm.available_products(product_categories=\"RADAR\", product_levels=\"1B\")\n\ngpm.available_products(product_categories=\"RADAR\", product_levels=\"2A\")\n\nIn this tutorial, we will use the 2A-DPR product which provides the GPM Dual-frequency Precipitation Radar (DPR) reflectivities and associated precipitation retrievals.\n\nSince we are running this tutorial on a Binder environment, we will not execute the following gpm.download and gpm.open_dataset sections, and directly load the 2A.GPM.DPR.V9-20211125.20230820-S213941-E231213.053847.V07B.HDF5 granule file,which has been preconverted to a Zarr Store and uploaded on the Pythia Cloud Bucket to simplify access to the data.\n\n","type":"content","url":"/gpm-api-intro","position":1},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"1. Download Data"},"type":"lvl2","url":"/gpm-api-intro#id-1-download-data","position":2},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"1. Download Data"},"content":"\n\nNow let’s download the 2A-DPR product over a couple of hours.\n\nTo download GPM data with GPM-API, you have to previously create a \n\nNASA Earthdata and/or \n\nNASA PPS account.\nWe provide a step-by-step guide on how to set up your accounts in the \n\nofficial GPM-API documentation.\n\n# Specify the time period you are interested in\nstart_time = datetime.datetime.strptime(\"2023-08-20 22:12:00\", \"%Y-%m-%d %H:%M:%S\")\nend_time = datetime.datetime.strptime(\"2023-08-20 22:13:45\", \"%Y-%m-%d %H:%M:%S\")\n# Specify the product and product type\nproduct = \"2A-DPR\"  # 2A-PR\nproduct_type = \"RS\"\nstorage = \"GES_DISC\"\n# Specify the version\nversion = 7\n\n# Download the data\n\n# gpm.download(\n#     product=product,\n#     product_type=product_type,\n#     version=version,\n#     start_time=start_time,\n#     end_time=end_time,\n#     storage=storage,\n#     force_download=False,\n#     verbose=True,\n#     progress_bar=True,\n#     check_integrity=False,\n# )\n\nOnce, the data are downloaded on disk, let’s load the 2A-DPR product and look at the dataset structure.\n\n","type":"content","url":"/gpm-api-intro#id-1-download-data","position":3},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"2. Load Data"},"type":"lvl2","url":"/gpm-api-intro#id-2-load-data","position":4},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"2. Load Data"},"content":"\n\nWith GPM-API, the name granule is used to refer to a single file, while the name dataset is used to refer to a collection of granules.\n\nGPM-API enables to open single or multiple granules into an xarray.Dataset, an object designed for working with labeled multi-dimensional arrays.\n\nThe gpm.open_granule(filepath) opens a single file into xarray by providing the path of the file of interest.\n\nThe gpm.open_dataset function enables to open a collection of granules over a period of interest.\n\n# Load the 2A-DPR dataset\n\n# ds = gpm.open_dataset(\n#     product=product,\n#     product_type=product_type,\n#     version=version,\n#     start_time=start_time,\n#     end_time=end_time,\n# )\n# ds\n\nHere we directly read the data required for this tutorial from the Pythia Cloud Bucket so that you don’t have to register a NASA account and download the data beforehand.\n\nbucket_url = \"https://js2.jetstream-cloud.org:8001\"\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=bucket_url))\nfile = fs.get_mapper(\n    f\"pythia/radar/erad2024/gpm_api/2A.GPM.DPR.V9-20211125.20230820-S213941-E231213.053847.V07B.zarr\"\n)\nds = xr.open_zarr(file, consolidated=True, chunks={})\n\n","type":"content","url":"/gpm-api-intro#id-2-load-data","position":5},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"3. Basic Manipulations"},"type":"lvl2","url":"/gpm-api-intro#id-3-basic-manipulations","position":6},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"3. Basic Manipulations"},"content":"\n\nYou can list variables, coordinates and dimensions with the following methods:\n\n# Available variables\nprint(\"Available variables: \", list(ds.data_vars))\n# Available coordinates\nprint(\"Available coordinates: \", list(ds.coords))\n# Available dimensions\nprint(\"Available dimensions: \", list(ds.dims))\n# Spatial dimension:\nprint(\"Spatial dimensions: \", ds.gpm.spatial_dimensions)\n# Vertical dimension:\nprint(\"Vertical dimension: \", ds.gpm.vertical_dimension)\n\nThrough the use of the xarray gpm accessor, you can access various methods that simplify for example the listing of variables according to their dimensions.\n\nFor example, using ds.gpm.spatial_3d_variables you can list all dataset variables with spatial horizontal and vertical dimensions, while with\nds.gpm.spatial_2d_variables you can list all dataset variables with only spatial horizontal dimensions.\n\nTo directly obtain a dataset with the variables of interest, you can also call the ds.gpm.select_spatial_2d_variables or ds.gpm.select_spatial_3d_variables  methods.\n\nPlease keep in mind that to create a spatial map, it is necessary to select spatial 2D variables, while for extracting vertical cross-sections it is necessary to slice across spatial 3D variables.\n\nprint(ds.gpm.spatial_2d_variables)\nds.gpm.select_spatial_2d_variables()\n\nprint(ds.gpm.spatial_3d_variables)\nds.gpm.select_spatial_3d_variables()\n\nSome variables also have a frequency dimension. You can list or subset such variables using ds.gpm.frequency_variables and ds.gpm.'select_frequency_variables respectively.\n\nprint(ds.gpm.frequency_variables)\nds.gpm.select_frequency_variables()\n\nUsing the ds.gpm.bin_variables or ds.gpm.select_bin_variables you can instead list or select the variables that contains “pointers” to specific radar gates.\nThe bin variables are useful to slice or extract data across the “range” dimension of the dataset.\nBin variables values range from 1 (the ellipsoid surface) to the size of the range dimension (in the upper atmosphere).\n\nprint(ds.gpm.bin_variables)\nds.gpm.select_bin_variables()\n\nTo select the DataArray corresponding to a single variable you do:\n\nvariable = \"precipRateNearSurface\"\nda = ds[variable]\nprint(\" Array Class: \", type(da.data))\nda\n\nIf the array class is dask.Array, it means that the data are not yet loaded into RAM memory.\nTo put the data into memory, you need to call the method compute, either on the xarray object or on the numerical array.\n\nda = da.compute()\nprint(\"Array Class: \", type(da.data))\nda\n\nTo check if the Dataset or the DataArray you selected has only spatial horizontal and/or vertical dimensions, you can use the xarray accessor gpm.is_spatial_2d and gpm.is_spatial_3d properties.\n\nprint(\n    ds.gpm.is_spatial_2d\n)  # False because the xarray.Dataset also contains the range and frequency dimensions !\nprint(\n    ds.gpm.is_spatial_3d\n)  # False because the xarray.Dataset also contains frequency dimensions !\n\nprint(\n    ds[\"zFactorFinal\"].isel(range=0).sel(radar_frequency=\"Ka\").gpm.is_spatial_2d\n)  # True\nprint(ds[\"precipRateNearSurface\"].gpm.is_spatial_2d)\n\nYou can select the reflectivity volumes at a given frequency using the radar band name with the sel method:\n\nds[\"zFactorFinal\"].sel(radar_frequency=\"Ka\")\n\nSince xarray does not yet allow subsetting by value along non-dimensional coordinates, the gpm.sel method provides you this functionality.\n\nAs an example, you can subset the dataset by time:\n\nstart_time = datetime.datetime.strptime(\"2023-08-20 22:12:00\", \"%Y-%m-%d %H:%M:%S\")\nend_time = datetime.datetime.strptime(\"2023-08-20 22:13:45\", \"%Y-%m-%d %H:%M:%S\")\nds_subset = ds.gpm.sel(time=slice(start_time, end_time))\nds_subset[\"time\"]\n\nRemember that you can get the start time and end time of your GPM xarray object with the gpm accessor methods start_time and end_time.\n\nprint(ds_subset.gpm.start_time)\nprint(ds_subset.gpm.end_time)\n\nYou can also subset your GPM xarray object by gpm_id, gpm_cross_track_id or gpm_range_id coordinates, which act as reference identifiers for the along-track, cross-track and range dimensions.\nSelecting across coordinates by value is useful for example to:\n\nalign multiple GPM xarray objects that might have been subsetted differently across the cross_track, along_track or range dimensions.\n\nto retrieve a specific portion of a GPM granule indipendently of the previous subsetting operations.\n\nThe gpm_id is defined as <gpm_granule_number>-<gpm_along_track_id>, while the others <gpm_*_id> coordinates start at 0 and increase incrementally by 1 along each granule dimension.\n\n# Subset by gpm_id\nstart_gpm_id = \"53847-2768\"\nend_gpm_id = \"53847-2918\"\nds_subset = ds.gpm.sel(gpm_id=slice(start_gpm_id, end_gpm_id))\nds_subset[\"gpm_id\"].data\n\nTo check whether the GPM 2A-DPR product has contiguous along-track scans (with no missing scans), you can use:\n\nprint(ds.gpm.has_contiguous_scans)\nprint(ds.gpm.is_regular)\n\nIn case there are non-contiguous scans, you can obtain the along-track slices over which the dataset is regular:\n\nlist_slices = ds.gpm.get_slices_contiguous_scans()\nprint(list_slices)\n\nYou can then select a regular portion of the dataset with:\n\nslc = list_slices[0]\nprint(slc)\nds_regular = ds.isel(along_track=slc)\n\n","type":"content","url":"/gpm-api-intro#id-3-basic-manipulations","position":7},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"4. Plot Maps"},"type":"lvl2","url":"/gpm-api-intro#id-4-plot-maps","position":8},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"4. Plot Maps"},"content":"\n\nThe GPM-API provides two ways of displaying 2D spatial fields:\n\nThe plot_map method plot the data in a geographic projection using the \n\nCartopy pcolormesh method.\n\nThe plot_image method plot the data as an image using the xarray imshow method.\n\nLet’s start by plotting the entire GPM DPR granule in the geographic space:\n\nds[variable].gpm.plot_map()\n\nBy focusing on a narrow region, it’s possible to better visualize the spatial field:\n\np = ds[variable].gpm.sel(gpm_id=slice(start_gpm_id, end_gpm_id)).gpm.plot_map()\np.axes.set_title(ds[variable].gpm.title(add_timestep=False))\n\nUsing the gpm.plot_image method is possible to visualize the data in the so-called “swath scan view”:\n\nds[variable].gpm.plot_image()\n\nds[variable].gpm.sel(gpm_id=slice(start_gpm_id, end_gpm_id)).gpm.plot_image()\n\nWhen we visualize different product variables, GPM-API will automatically try to use different appropriate colormaps and colorbars.\nYou can observe this in the following example:\n\nds_subset = ds.gpm.sel(gpm_id=slice(start_gpm_id, end_gpm_id), radar_frequency=\"Ku\")\np = ds_subset[\"zFactorFinalNearSurface\"].gpm.plot_map()\np = ds_subset[\"zFactorFinalNearSurface\"].gpm.plot_map(\n    cmap=\"RdYlBu_r\", vmin=15, vmax=45\n)  # ex: enable to modify defaults parameters on the fly\np = ds_subset[\"flagPrecip\"].gpm.plot_map()  # ex: defaults to categorical colorbar\n\nGPM-API provides colormaps and colorbars tailored to GPM product variables with the goal of simplifying the data analysis and make it more reproducible.\n\nThe default colormap and colorbar configurations are defined into YAML files into the \n\ngpm/etc/colorbars directory of the software.\n\nHowever, users are free to override, add and/or customize the colorbars configurations using the pycolorbar (\n\nhttps://​pycolorbar​.readthedocs​.io​/en​/latest​/index​.html) registry.\n\nThe registered colorbar configurations can be displayed using gpm.colorbars.show_colorbars() and the plot_kwargs and cbar_kwargs required to customize the figure can be obtained by calling the gpm.get_plot_kwargs function. Here below we provide an example on how to display DPR precipitation rates estimates using the same colorbar used by NASA to display IMERG liquid precipitation estimates.\n\nplot_kwargs, cbar_kwargs = gpm.get_plot_kwargs(\"IMERG_Liquid\")\nds_subset[\"precipRateNearSurface\"].gpm.plot_map(cbar_kwargs=cbar_kwargs, **plot_kwargs)\n\nSince GPM Datasets are characterized by multiple dimensions, GPM-API provides the capabilities to generate FacetGrid Cartopy plots following the classical xarray syntax:\n\nds_subset = ds.gpm.sel(gpm_id=slice(start_gpm_id, end_gpm_id))\n\n# Plot reflectivity at various levels\nvariable = \"zFactorFinal\"\nda = ds_subset[variable].sel(range=[100, 125, 150, 170])\nfc = da.gpm.plot_map(row=\"radar_frequency\", col=\"range\")\n\n# Surface reflectivity at Ku and Ka band\nvariable = \"zFactorFinalNearSurface\"\nda = ds_subset[variable]\nfc = da.gpm.plot_map(col=\"radar_frequency\", col_wrap=2)\n\n","type":"content","url":"/gpm-api-intro#id-4-plot-maps","position":9},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"5. Plot Cross-Sections"},"type":"lvl2","url":"/gpm-api-intro#id-5-plot-cross-sections","position":10},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"5. Plot Cross-Sections"},"content":"\n\nAn easy way to derive a vertical cross-section is to slice the data along the cross-track or along-track dimension.\nWe can then plot the cross-section calling the gpm.plot_cross_section() method.\n\nds_subset = ds.gpm.sel(\n    gpm_id=slice(start_gpm_id, end_gpm_id), radar_frequency=\"Ku\"\n).compute()\nds_subset[\"zFactorFinal\"].isel(cross_track=24).gpm.plot_cross_section(zoom=True)\nds_subset[\"zFactorFinal\"].isel(along_track=30).gpm.plot_cross_section(\n    y=\"height_km\", x=\"horizontal_distance_km\", zoom=True\n)\n\nThe cross-section transect can be visualized calling the gpm.plot_transect_line method:\n\nds_transect = ds_subset.isel(cross_track=24)\ntext_kwargs = {\n    \"bbox\": dict(\n        facecolor=\"white\", alpha=0.6, edgecolor=\"black\", boxstyle=\"round,pad=0.2\"\n    )\n}\np = ds_subset[\"zFactorFinalNearSurface\"].gpm.plot_map()\nds_transect.gpm.plot_transect_line(ax=p.axes, text_kwargs=text_kwargs)\n\nThe cross-section variables available in a transect dataset can be listed or selected with gpm.cross_section_variables or gpm.select_cross_section_variables() respectively:\n\nds_transect = ds_subset.isel(cross_track=24)\nprint(ds_transect.gpm.cross_section_variables)\nds_transect.gpm.select_cross_section_variables()\n\nGPM-API provides accessor methods to facilitate the extraction of cross-section:\n\naround a point\n\nbetween points\n\nand along a trajectory.\n\nda_cross = ds_subset[\"zFactorFinal\"].gpm.extract_transect_between_points(\n    start_point=(-118, 32), end_point=(-118, 36), steps=60\n)\nda_cross.gpm.plot_cross_section(zoom=True)\n\npoints = np.ones((100, 2))\npoints[:, 0] = -118\npoints[:, 1] = np.linspace(32, 36, 100)\nda_cross = ds_subset[\"zFactorFinal\"].gpm.extract_transect_at_points(points=points)\nda_cross.gpm.plot_cross_section(zoom=True)\n\nda_cross = ds_subset[\"zFactorFinal\"].gpm.extract_transect_around_point(\n    point=(-118, 34), azimuth=0, distance=100_000, steps=100\n)  # azimuth [0, 360]\nda_cross.gpm.plot_cross_section(zoom=True)\n\n","type":"content","url":"/gpm-api-intro#id-5-plot-cross-sections","position":11},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"6. Community-based retrievals"},"type":"lvl2","url":"/gpm-api-intro#id-6-community-based-retrievals","position":12},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"6. Community-based retrievals"},"content":"\n\nGPM-API aims to be a platform where scientist can share their algorithms and retrievals with the community.\n\nBased on the GPM product you are working with, you will have a series of retrievals available to you.\nFor example, GPM-API currently provide the following retrievals for the 2A-DPR product:\n\nds.gpm.available_retrievals()\n\nThe gpm.retrieve method enables you to apply specific retrievals to your dataset.\nHere below we provide a couple of examples:\n\nds_subset = ds.gpm.sel(\n    gpm_id=slice(start_gpm_id, end_gpm_id), radar_frequency=\"Ku\"\n).compute()\n\nds_subset[\"EchoTopHeight40dBZ\"] = ds_subset.gpm.retrieve(\"EchoTopHeight\", threshold=40)\nds_subset[\"EchoTopHeight40dBZ\"].gpm.plot_map()\n\nds_subset[\"EchoDepthSolid30dBZ\"] = ds_subset.gpm.retrieve(\n    \"EchoDepth\", threshold=30, mask_liquid_phase=True\n)\nds_subset[\"EchoDepthSolid30dBZ\"].gpm.plot_map()\n\nds_subset[\"VIL\"] = ds_subset.gpm.retrieve(\"VIL\")\nds_subset[\"VIL\"].gpm.plot_map()\n\nds_subset[\"flagPrecipitationType\"] = ds_subset.gpm.retrieve(\n    \"flagPrecipitationType\", method=\"major_rain_type\"\n)\nds_subset[\"flagPrecipitationType\"].gpm.plot_map()\n\nds_subset[\"flagHydroClass\"] = ds_subset.gpm.retrieve(\n    \"flagHydroClass\"\n)  # this return a 3D array !\nds_subset[\"flagHydroClass\"].isel(cross_track=24).gpm.plot_cross_section()\n\n","type":"content","url":"/gpm-api-intro#id-6-community-based-retrievals","position":13},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"7. Advanced Manipulations"},"type":"lvl2","url":"/gpm-api-intro#id-7-advanced-manipulations","position":14},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"7. Advanced Manipulations"},"content":"\n\nWhen working with spaceborne radar data, it is often necessary to slice, extract or mask portions of data across the range dimension.\nThe xarray gpm accessor provides a series of methods to facilitate various tasks.\n\nIf you wish to extract the values at specific range gate position varying over each radar beam, you can use the slice_range_at_bin method.\nFor example, to extract values near the surface where radar gates are not more contaminated by ground clutter, you can use the bin variable \"binClutterFreeBottom\":\n\nds_surface = ds_subset.gpm.slice_range_at_bin(\n    bins=\"binClutterFreeBottom\"\n)  # or ds.gpm.slice_range_at_bin(bins=ds[\"binClutterFreeBottom\"])\nds_surface[\"precipRate\"].gpm.plot_map()  # precipRate is originally a 3D variable !\nds_surface[\"zFactorFinal\"].gpm.plot_map()  # zFactorFinal is originally a 3D variable !\n\nOther slicing methods provide capabilities to retrieve values at a given height, along isothermals, or at the range gates where the minimum, maximum or closest value of a given variable occur:\n\nds_isothermal = ds_subset.gpm.slice_range_at_temperature(\n    273.15\n)  # use by default the airTemperature variable\nds_3000 = ds_subset.gpm.slice_range_at_height(3000)\nds_max_z = ds_subset.gpm.slice_range_at_max_value(variable=\"zFactorFinal\")\nds_min_z = ds_subset.gpm.slice_range_at_min_value(variable=\"zFactorFinal\")\nds_at_z_30 = ds_subset.gpm.slice_range_at_value(variable=\"zFactorFinal\", value=30)\n\nIf you want to focus your analysis in the portion of radar gates with valid values (e.g., excluding upper atmosphere regions without reflectivities) or values ranging in a specific interval of interest, you can use the subset_range_with_valid_data and subset_range_where_values methods respectively:\n\nds_valid = ds_subset.gpm.subset_range_with_valid_data(variable=\"zFactorFinal\")\nds_intense = ds_subset.gpm.subset_range_where_values(\n    variable=\"precipRate\", vmin=200, vmax=300\n)  # mm/hr\nprint(\"Range with valid data:\", ds_valid[\"range\"].data)\nprint(\"Range with intense precipitation:\", ds_intense[\"range\"].data)\n\nIf you wish to extract radar gates above/below spatially-varying bin position, you can use the extract_dataset_above_bin and extract_dataset_below_bin methods.\nPlease note that these methods shifts the arrays beam-wise, returning datasets with a new range coordinate and the bin variables updated accordingly.\n\nds_below_melting_layer = ds_subset.gpm.extract_dataset_below_bin(\n    \"binBBBottom\"\n)  # the first new range index corresponds to original binBBBottom\nds_above_melting_layer = ds_subset.gpm.extract_dataset_above_bin(\n    \"binBBTop\"\n)  # the last new range index corresponds to original binBBTop\n\nIf instead you wish to mask the data above/below or in between radar gates positions, you can use the mask_above_bin, mask_below_bin and mask_between_bins methods:\n\nds_rain = ds_subset.gpm.mask_above_bin(\"binZeroDeg\")\nds_snow = ds_subset.gpm.mask_below_bin(\"binZeroDeg\")\nds_masked_melting_layer = ds_subset.gpm.mask_between_bins(\n    bottom_bins=\"binBBBottom\", top_bins=\"binBBTop\"\n)\n\n","type":"content","url":"/gpm-api-intro#id-7-advanced-manipulations","position":15},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"8. Geospatial Manipulations"},"type":"lvl2","url":"/gpm-api-intro#id-8-geospatial-manipulations","position":16},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"8. Geospatial Manipulations"},"content":"\n\nGPM-API provides methods to easily spatially subset orbits by extent, country or continent.\n\nNote however, that an area can be crossed by multiple orbits depending on the size of your GPM satellite dataset.\nIn other words, multiple orbit slices in along-track direction can intersect the area of interest.\n\nThe method get_crop_slices_by_extent, get_crop_slices_by_country and  get_crop_slices_by_continent enable to retrieve the orbit portions intersecting the area of interest.\n\n# Define the variable to display\nvariable = \"precipRateNearSurface\"\n\n# Crop by country\nlist_isel_dict = ds.gpm.get_crop_slices_by_country(\"United States\")\nprint(list_isel_dict)\n\n# Crop by extent\nextent = get_country_extent(\"United States\")\nlist_isel_dict = ds.gpm.get_crop_slices_by_extent(extent)\nprint(list_isel_dict)\n\n# Plot the swaths crossing the country\nfor isel_dict in list_isel_dict:\n    da_subset = ds[variable].isel(isel_dict)\n    slice_title = da_subset.gpm.title(add_timestep=True)\n    p = da_subset.gpm.plot_map()\n    p.axes.set_extent(extent)\n    p.axes.set_title(label=slice_title)\n\n# Define the variable to display\nvariable = \"precipRateNearSurface\"\n\n# Crop around a point (i.e. radar location)\nlon = -117.0418\nlat = 32.9190\ndistance = 200_000  # 200 km\nlist_isel_dict = ds.gpm.get_crop_slices_around_point(\n    lon=lon, lat=lat, distance=distance\n)\nprint(list_isel_dict)\n\nextent = get_geographic_extent_around_point(lon=lon, lat=lat, distance=distance)\nlist_isel_dict = ds.gpm.get_crop_slices_by_extent(extent)\nprint(list_isel_dict)\n\n# Define ROI coordinates\ncircle_lons, circle_lats = get_circle_coordinates_around_point(\n    lon, lat, radius=distance, num_vertices=360\n)\n\n# Plot the swaths crossing the ROI\nfor isel_dict in list_isel_dict:\n    da_subset = ds[variable].isel(isel_dict)\n    slice_title = da_subset.gpm.title(add_timestep=True)\n    p = da_subset.gpm.plot_map()\n    p.axes.plot(circle_lons, circle_lats, \"r-\", transform=ccrs.Geodetic())\n    p.axes.scatter(lon, lat, c=\"black\", marker=\"X\", s=100, transform=ccrs.Geodetic())\n    p.axes.set_extent(extent)\n\n# Alternatives if working with a single granule:\n\n# ds_subset = ds.gpm.crop_by_extent(extent)\n# ds_subset = ds.gpm.crop_by_country(\"United States\")\n\nYou can also easily obtain the extent around a given point (i.e. ground radar location) using the get_geographic_extent_around_point function and use\nthe gpm accessor methods get_crop_slices_around_point or crop_around_point to subset your dataset:\n\n# Define the variable to display\nvariable = \"precipRateNearSurface\"\n\n# Crop around a point (i.e. radar location)\nlon = -117.0418\nlat = 32.9190\ndistance = 200_000  # 200 km\nlist_isel_dict = ds.gpm.get_crop_slices_around_point(\n    lon=lon, lat=lat, distance=distance\n)\nprint(list_isel_dict)\n\nextent = get_geographic_extent_around_point(lon=lon, lat=lat, distance=distance)\nlist_isel_dict = ds.gpm.get_crop_slices_by_extent(extent)\nprint(list_isel_dict)\n\n# Define ROI coordinates\ncircle_lons, circle_lats = get_circle_coordinates_around_point(\n    lon, lat, radius=distance, num_vertices=360\n)\n\n# Plot the swaths crossing the ROI\nfor isel_dict in list_isel_dict:\n    da_subset = ds[variable].isel(isel_dict)\n    slice_title = da_subset.gpm.title(add_timestep=True)\n    p = da_subset.gpm.plot_map()\n    p.axes.plot(circle_lons, circle_lats, \"r-\", transform=ccrs.Geodetic())\n    p.axes.scatter(lon, lat, c=\"black\", marker=\"X\", s=100, transform=ccrs.Geodetic())\n    p.axes.set_extent(extent)\n\n# Alternatives if working with a single granule:\n\n# ds_subset = ds.gpm.crop_around_point(lon=lon, lat=lat, distance=distance)\n\nPlease keep in mind that you can easily retrieve the extent of a GPM xarray object using the extent method.\n\nThe optional argument padding allows to expand/shrink the geographic extent by custom lon/lat degrees, while the size argument allows\nto obtain an extent centered on the GPM object with the desired size.\n\nprint(da_subset.gpm.extent(padding=0.1))  # expanding\nprint(da_subset.gpm.extent(padding=-0.1))  # shrinking\nprint(da_subset.gpm.extent(size=0.5))\nprint(da_subset.gpm.extent(size=0))  # centroid\n\n","type":"content","url":"/gpm-api-intro#id-8-geospatial-manipulations","position":17},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"9. Storm Labeling"},"type":"lvl2","url":"/gpm-api-intro#id-9-storm-labeling","position":18},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"9. Storm Labeling"},"content":"\n\nUsing the xarray ximage accessor, it is possible to easily delineate (label) the precipitating areas. The label array is added to the dataset as a new coordinate.\n\n# Retrieve labeled xarray object\nlabel_name = \"label\"\nds = ds.ximage.label(\n    variable=\"precipRateNearSurface\",\n    min_value_threshold=1,\n    min_area_threshold=5,\n    footprint=5,  # assign same label to precipitating areas 5 pixels apart\n    sort_by=\"area\",  # \"maximum\", \"minimum\", <custom_function>\n    sort_decreasing=True,\n    label_name=label_name,\n)\n# Plot full label array\nds[label_name].ximage.plot_labels()\n\nLet’s zoom in a specific region:\n\ngpm.plot_labels(ds[label_name].isel(along_track=slice(2700, 3500)))\n\n","type":"content","url":"/gpm-api-intro#id-9-storm-labeling","position":19},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"10. Patch Extraction"},"type":"lvl2","url":"/gpm-api-intro#id-10-patch-extraction","position":20},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"10. Patch Extraction"},"content":"\n\nWith the xarray ximage accessor, it is also possible to extract patches around the precipitating areas. Here we provide a minimal example on how to proceed:\n\n# Define the patch generator\nda_patch_gen = ds[\"precipRateNearSurface\"].ximage.label_patches(\n    label_name=label_name,\n    patch_size=(49, 49),\n    # Output options\n    n_patches=4,\n    # Patch extraction Options\n    padding=0,\n    centered_on=\"max\",\n    # Tiling/Sliding Options\n    debug=False,\n    verbose=False,\n)\n\n# # Retrieve list of patches\nlist_label_patches = list(da_patch_gen)\nlist_da = [da for label, da in list_label_patches]\n\n# Display patches\ngpm.plot_patches(list_label_patches)\n\nYou can exploit the xarray manipulations and FacetGrid capabilities to quickly create the following figure:\n\nlist_da_without_coords = [da.drop_vars([\"lon\", \"lat\"]) for da in list_da]\nda_patch = xr.concat(list_da_without_coords, dim=\"patch\")\nda_patch.isel(patch=slice(0, 4)).gpm.plot_image(col=\"patch\", col_wrap=2)\n\n","type":"content","url":"/gpm-api-intro#id-10-patch-extraction","position":21},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"11. Spaceborne/Ground Radar Matching"},"type":"lvl2","url":"/gpm-api-intro#id-11-spaceborne-ground-radar-matching","position":22},{"hierarchy":{"lvl1":"Introduction to GPM-API","lvl2":"11. Spaceborne/Ground Radar Matching"},"content":"\n\nIn this final subsection, we now provide also brief overview on how to match spaceborne (SR) and ground (GR) radar measurements.\n\nA step-by-step guide on the methodology to obtain spatially and temporally coincident radar samples is provided in\nthe \n\nSpaceborne-Ground Radar Matching Tutorial,\nwhile an applied example is provided in the \n\nSpaceborne-Ground Radar Calibration Applied Tutorial.\n\nTo start let’s open the NEXRAD ground radar data coincident with the GPM DPR overpass. We have preprocessed the native NEXRAD radar with xradar and uploaded it into Zarr format on the Pythia Cloud Bucket.\n\nbucket_url = \"https://js2.jetstream-cloud.org:8001\"\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=bucket_url))\nfile = fs.get_mapper(f\"pythia/radar/erad2024/gpm_api/KNKX20230820_221341_V06.zarr\")\ndt_gr = open_datatree(file, engine=\"zarr\", consolidated=True, chunks={})\ndisplay(dt_gr)\n\nNow, let’s select the GR sweep to match with GPM DPR.\n\nsweep_idx = 0\nsweep_group = f\"sweep_{sweep_idx}\"  # GR sweep (elevation to be used)\nds_gr = dt_gr[sweep_group].to_dataset().compute()\n\nLet’s quickly display the PPI for the horizontally and vertically polarized reflectivity. You will notice that the radar is quite miscalibrated !\n\nds_gr[\"DBZH\"].where(ds_gr[\"DBZH\"] > -10).xradar_dev.plot_map()\nds_gr[\"DBZV\"] = (ds_gr[\"DBZH\"].gpm.idecibel / ds_gr[\"ZDR\"].gpm.idecibel).gpm.decibel\nds_gr[\"DBZV\"].where(ds_gr[\"DBZV\"] > -10).xradar_dev.plot_map()\n# ds_gr[\"ZDR\"].where(ds_gr[\"DBZV\"] > -10).xradar_dev.plot_map()\n\nLet’s define some SR/GR volume matching settings ...\n\nradar_band = \"S\"\nbeamwidth_gr = 1\nz_min_threshold_gr = 0\nz_min_threshold_sr = 10\n\n... and then apply the SR/GR volume matching. If the GPM Dataset is not specified, volume_matching automatically download and load the required SR radar data.\n\ngdf_match = volume_matching(\n    ds_gr=ds_gr,\n    ds_sr=ds,  # optional\n    z_variable_gr=\"DBZH\",\n    radar_band=radar_band,\n    beamwidth_gr=beamwidth_gr,\n    z_min_threshold_gr=z_min_threshold_gr,\n    z_min_threshold_sr=z_min_threshold_sr,\n    min_gr_range=0,\n    max_gr_range=150_000,\n    # gr_sensitivity_thresholds=None,\n    # sr_sensitivity_thresholds=None,\n    download_sr=False,  # require NASA accounts and internet connection !\n    display_quicklook=True,\n)\ndisplay(gdf_match)\n\nNow let’s display the SR/GR matched/aggregated reflectivities and the preliminary calibration summary:\n\nsr_z_column = f\"SR_zFactorFinal_{radar_band}_mean\"\ngr_z_column = \"GR_Z_mean\"\n\n# Compare reflectivities\nfig = compare_maps(\n    gdf_match,\n    sr_column=sr_z_column,\n    gr_column=gr_z_column,\n    sr_label=\"SR Reflectivity (dBz)\",\n    gr_label=\"GR Reflectivity (dBz)\",\n    cmap=\"Spectral_r\",\n    unified_color_scale=True,\n    vmin=15,\n    # vmax=40\n)\nfig.tight_layout()\n\n# Display calibration summary\nfig = calibration_summary(\n    df=gdf_match,\n    gr_z_column=gr_z_column,\n    sr_z_column=sr_z_column,\n    # Histogram options\n    bin_width=2,\n    # Scatterplot options\n    # hue_column=\"GR_gate_volume_sum\",\n    hue_column=\"SR_fraction_clutter\",\n    # gr_range=[15, 50]\n    # sr_range=[15, 50]\n    marker=\"+\",\n    cmap=\"Spectral\",\n)\nfig.tight_layout()\n\nIf you are interested in this application, please read the \n\nSpaceborne-Ground Radar Calibration Applied Tutorial to investigate and apply filtering criteria to improve the matching process and the calibration of GR data.","type":"content","url":"/gpm-api-intro#id-11-spaceborne-ground-radar-matching","position":23},{"hierarchy":{"lvl1":"How to Cite"},"type":"lvl1","url":"/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite"},"content":"The material in this short course is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/how-to-cite","position":1},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis"},"type":"lvl1","url":"/dd-tornado-erad24","position":0},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis"},"content":"","type":"content","url":"/dd-tornado-erad24","position":1},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"type":"lvl2","url":"/dd-tornado-erad24#course-open-radar-open-source-software-tools-for-radar-data-processing","position":2},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"content":"","type":"content","url":"/dd-tornado-erad24#course-open-radar-open-source-software-tools-for-radar-data-processing","position":3},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl3":"ERAD - Rome, 9-13 September 2024","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"type":"lvl3","url":"/dd-tornado-erad24#erad-rome-9-13-september-2024","position":4},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl3":"ERAD - Rome, 9-13 September 2024","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"content":"This notebook contains some high-level literature background for the multi-doppler analysis exercise at ERAD 2024.\n\nData acknowledgment: The data for the case used in the exercise is provided by the Meteorological Service of Catalonia.\n\n\n\n","type":"content","url":"/dd-tornado-erad24#erad-rome-9-13-september-2024","position":5},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl3":"Multi Doppler analysis","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"type":"lvl3","url":"/dd-tornado-erad24#multi-doppler-analysis","position":6},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl3":"Multi Doppler analysis","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"content":"Multi-Doppler analysis consists on obtaining 3D wind fields using the radial observed velocity from two or more independent (non-collinearly located) Doppler radars.\nTechniques using Cylindrical and Cartesian coordinates systems are explained in Armijo 1969, Ray and Wagner 1976, and Ray and Sangren 1983, for instance.\nThe mean radial velocity from every single radar is related to the rectangular components of the mean velocity (u,v, and w) through the azimuth (\\phi), and elevation (\\epsilon) angles (Fig.1).\n\n\n\nFig 1: Dual-Doppler Cartesian geometry from two radars. Adapted from Rauber and Nesbitt (2018).\n\nIt is possible to obtain a unique solution for the horizontal and vertical velocities at a given point by combining the radial velocities in a closed equation system (more than two radars), or by applying boundary conditions on the vertical velocity and the terminal velocity of the hydrometeors (w_t), and integrating the mass continuity equation (Miller and Strauch, 1974):V_r = u\\cdot sin(\\phi) cos(\\epsilon) + v \\cdot cos(\\phi) cos(\\epsilon) +(w + w_t) sin(\\epsilon)- \\frac{\\partial \\rho w}{\\partial z} = \\frac{\\partial \\rho u}{\\partial x} + \\frac{\\partial \\rho v }{\\partial y}\n\n","type":"content","url":"/dd-tornado-erad24#multi-doppler-analysis","position":7},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl3":"Dual Doppler coverage (2 radars)","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"type":"lvl3","url":"/dd-tornado-erad24#dual-doppler-coverage-2-radars","position":8},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl3":"Dual Doppler coverage (2 radars)","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"content":"Keep in mind: The accuracy of our analysis (retrieving $u$,$v$, and $w$) is strongly dependent on geometric configuration and radar spatial resolution.\n\nWe want our storm to be placed in the “optimal area” region, for which we need to know what is our Dual Doppler coverage and the optimal spatial resolution to resolve storm-related winds.\n\nThese are some things to consider:\n\nThe variance on the horizontal wind field is represented by the standard deviation of the local u and v components of the wind: \\sigma^{2}_u and \\sigma^{2}_v.\n\nThe variance of the radial velocity from each radar (spectral width) is represented by \\sigma^{2}_1 and \\sigma^{2}_2.\n\nBoth variances represent the beam-crossing angle between the two radars (\\beta), and consequently the “dual-Doppler lobes”:\\frac{\\sigma^{2}_u + \\sigma^{2}_v}{\\sigma^{2}_1 + \\sigma^{2}_2} = \\sin^{-2}\\beta\n\nNote: The dual lobes define the points on which the beams of both radars intersect at an angle $\\beta$, and where equal values of the geometric error of the horizontal wind field fall.\n\nLiterature demonstrates that $\\beta$=30º is one of the most suitable ones (e.g. Davies-Jones, 1979; Lhermitt and Miller, 1970; Friedrich and Hagen, 2004). This keeps the horizontal wind error below 3 m/s ($\\sigma^{2}_u$ and $\\sigma^{2}_v$) in convective situations*. The dual lobes centers are located perpendicular to the bisection of the baseline ($b$). The baseline is the distance separating the two radars (Fig. 2). The dual-lobes area is defined by: $$ A(\\beta) = 2 (\\frac{b}{2}\\csc \\beta )^{2} (\\pi -2\\beta +\\sin 2\\beta ) $$\n\n\n\nFig 2: Dual-Doppler configuration with beam crossing angle ($\\beta$), in black, and constant spatial resolution (s) for a beamwidht of 1.2° and a baseline b = 47.33 km. Adapted from (Davies-Jones, 1979)\n\nFinally, it is also important to consider the spatial resolution s.\n\nThe paired radars must be able to resolve horizontal scales below 3-6 km. This compromises the beam-crossing angle \\beta and the baseline b. If b is too big, the data will degrade at the edges of the dual lobes due to the beam spread and elevation.\n\nWe will consider that the spatial resolution s is proportional to the range R, and approximately to the beam height:s=\\frac{R\\pi \\Delta }{180}\n\nwhere \\Delta is half of the beam width and 180º is expressed in degrees (Davies-Jones, 1979).\n\nThe area representing the region where points are at a distance R, with a spatial resolution s for 0º beam height is described in the following equation:A(R)=2R^{2} \\cos ^{-1} \\left\\{ \\frac{b}{2R} -\\frac{b}{2R} \\left[ 1- ( \\frac{b}{2R} )^{2} \\right]^{1/2} \\right\\}\n\nNote: To retrieve the best wind estimates, there must exist a compromise between the area that we can cover with the optimum dual-lobe and the area in which we can correctly solve the thunderstorms because of the resolution. This constitutes the intersection of both areas and depends on the radar beam width and the maximum resolution desired.\n\n","type":"content","url":"/dd-tornado-erad24#dual-doppler-coverage-2-radars","position":9},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl3":"Case of analysis: Tornado in Catalonia -  Jan 7, 2018","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"type":"lvl3","url":"/dd-tornado-erad24#case-of-analysis-tornado-in-catalonia-jan-7-2018","position":10},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl3":"Case of analysis: Tornado in Catalonia -  Jan 7, 2018","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"content":"","type":"content","url":"/dd-tornado-erad24#case-of-analysis-tornado-in-catalonia-jan-7-2018","position":11},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl4":"Dual Doppler coverage in Catalonia","lvl3":"Case of analysis: Tornado in Catalonia -  Jan 7, 2018","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"type":"lvl4","url":"/dd-tornado-erad24#dual-doppler-coverage-in-catalonia","position":12},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl4":"Dual Doppler coverage in Catalonia","lvl3":"Case of analysis: Tornado in Catalonia -  Jan 7, 2018","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"content":"The XRAD (Xarxa de RADars) is the radar network of the Meteorological Service of Catalonia (NE of Spain). The network is formed by four C-band single-Doppler radars, covering an area of ~ 32,114 km^{2} with complex terrain.\n\nDel Moral Méndez 2020, and del Moral Méndez et al., 2020 explore the possible dual-Doppler coverage for the operational XRAD network and establish that with a maximum resolution of 2 km at the farthest point, and with 320deg dual-lobes, CDV-PBE and CDV-LMI are the two most suitable pairs of radars for dual-Doppler analysis.\n\nThe two radars selected to analyse the tornado case are CDV-PBE, and the coverage  is represeted in Fig. 3 (right). Notice that the “optimal area” is the intersection of the desired dual-lobe and the optimal resolution area. In this case, these two are the same.\nFor this case and radar configuration, the baseline b is 47.33 km, the farthest point is located at 94.66 km with a minimum resolution of 1.98 km. The lobes cover a total area of 13.30^{3} km^3 and with only 0.61% of topography blockage (del Moral et al. 2020)\n\n\n\nDual Doppler\n\n\n\nDual Doppler\n\nFig 3: Dual-Doppler coverage for the CDV-PBE and CDV-LMI pairs of radars (in red). The 30° dual-lobe is shown in dotted black circles.\n\n \n\n","type":"content","url":"/dd-tornado-erad24#dual-doppler-coverage-in-catalonia","position":13},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl4":"Tornado track","lvl3":"Case of analysis: Tornado in Catalonia -  Jan 7, 2018","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"type":"lvl4","url":"/dd-tornado-erad24#tornado-track","position":14},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl4":"Tornado track","lvl3":"Case of analysis: Tornado in Catalonia -  Jan 7, 2018","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"content":"The severe weather event on 6-7 January 2018 occurred outside the convective season in the northwestern Mediterranean.\nSeveral rain bands with a predominant southeasterly flow affected the area. Within those bands, embedded convective cells produced severe weather, causing two significant tornadoes, both rated EF2.\nThe tornado in the central region of Catalonia was the result of a nocturnal supercell propagating NW and channeling through a narrow valley, and achieving speeds up tp 180 km/h with a 500 m diameter.\n\n\n\nFig 4: Track of the nocturnal winter storm that produced the tornado on Central Catalonia on 7 January 2018. Part of the 30° CDV-PBE pair dual lobes is depicted in the dotted lines. Dots indicate supercell centroid times labeled in UTC.\n\nFigure 5 shows the CDV radar reflectivity and radial velocity fields for the tornado on January 7, 2018, depicting a hook echo and a mesocyclone, respectively. This is the timestep we will analyse with SAMURAI.\n\n\n\nFig 5: (a) Reflectivity (dBZ) and (b) doppler velocity (m/s) for the supercell case on 7 January 2018 at 0042UTC and 2° elevation angle.\n\n","type":"content","url":"/dd-tornado-erad24#tornado-track","position":15},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl3":"References:","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"type":"lvl3","url":"/dd-tornado-erad24#references","position":16},{"hierarchy":{"lvl1":"Introduction to Multidoppler Analysis","lvl3":"References:","lvl2":"COURSE: Open Radar - Open Source Software Tools for Radar Data Processing"},"content":"Armijo, L., 1967. A theory for the determination of wind and precipitation velocities with Doppler radars (Vol. 35). Institutes for Environmental Research, National Severe Storms Laboratory\n\nDavies-Jones, R.P., 1979. Dual-Doppler radar coverage area as a function of measurement accuracy and spatial resolution. Journal of Applied Meteorology (1962-1982), pp.1229-1233\n\ndel Moral Méndez, A., 2020. Radar-based nowcasting of severe thunderstorms: A better understanding of the dynamical influence of complex topography and the sea\n\ndel Moral Méndez, A.D., Weckwerth, T.M., Rigo, T., Bell, M.M. and Llasat Botija, M.D.C., 2020. C-Band Dual-Doppler Retrievals in Complex Terrain: Improving the Knowledge of Severe Storm Dynamics in Catalonia. Remote Sensing, 2020, vol. 12, num. 18, p. 2930\n\nFriedrich, K. and Hagen, M., 2004. On the use of advanced Doppler radar techniques to determine horizontal wind fields for operational weather surveillance. Meteorological Applications, 11(2), pp.155-171\n\nLhermitte, R.M. and Miller, L.J., 1970. Doppler radar methodology for the observation of convective storms\n\nMiller, L.J. and Strauch, R.G., 1974. A dual Doppler radar method for the determination of wind velocities within precipitating weather systems. Remote Sensing of Environment, 3(4), pp.219-235\n\nRauber, R.M. and Nesbitt, S.W., 2018. Radar meteorology: A first course. John Wiley & Sons\n\nRay, P.S. and Sangren, K.L., 1983. Multiple-Doppler radar network design. Journal of climate and applied meteorology, pp.1444-1454\n\nRay, P.S. and Wagner, K.K., 1976. Multiple Doppler radar observations of storms. Geophysical Research Letters, 3(3), pp.189-191","type":"content","url":"/dd-tornado-erad24#references","position":17},{"hierarchy":{"lvl1":"An Introduction to LROSE"},"type":"lvl1","url":"/lrose-basics","position":0},{"hierarchy":{"lvl1":"An Introduction to LROSE"},"content":" \n\nThe Lidar Radar Open Software Environment (LROSE) is an National Science Foundation (NSF) supported project to develop common software for the Lidar, Radar, and Profiler community based on collaborative, open source development.  The core package is being jointly developed by Colorado State University (CSU) and the Earth Observing Laboratory at the NSF National Center for Atmospheric Research (NSF NCAR/EOL). The current LROSE release is called Colette (a versatile climbing rose).\n\nMore information on LROSE can be found on the \n\nLROSE wiki.","type":"content","url":"/lrose-basics","position":1},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"Notebook Summary"},"type":"lvl3","url":"/lrose-basics#notebook-summary","position":2},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"Notebook Summary"},"content":"This notebook will cover the following:\n\nLROSE Overview\n\nLROSE on the Command Line\n\nLROSE Parameter Files\n\nInspect the Data\n\nFormat Conversion\n\nSimple Gridding\n\nBasic Data Display\n\n","type":"content","url":"/lrose-basics#notebook-summary","position":3},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"LROSE Overview"},"type":"lvl3","url":"/lrose-basics#lrose-overview","position":4},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"LROSE Overview"},"content":"\n\nLROSE encompasses six key toolsets that define a core lidar/radar workflow: Convert, Display, QC, Grid, Echo, and Winds. Colette focuses on high-quality, well-tested, well-maintained and well-documented key applications as ‘building blocks’, allowing users to assemble trusted, reproducible workflows to accomplish more complex scientific tasks.","type":"content","url":"/lrose-basics#lrose-overview","position":5},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Installation","lvl3":"LROSE Overview"},"type":"lvl4","url":"/lrose-basics#installation","position":6},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Installation","lvl3":"LROSE Overview"},"content":"LROSE is available for download through \n\nGitHub. Installation is supported for Linux (source, packages) and Mac OS (source, Homebrew). Conda-forge development is underway.","type":"content","url":"/lrose-basics#installation","position":7},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"LROSE Tutorials","lvl3":"LROSE Overview"},"type":"lvl4","url":"/lrose-basics#lrose-tutorials","position":8},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"LROSE Tutorials","lvl3":"LROSE Overview"},"content":"We’re developing a Science Gateway where LROSE tools are installed on NSF’s Jetstream2 supercomputer. The tutorials from that Gateway can also be found on GitHub.\n\nhttps://​github​.com​/nsf​-lrose​/lrose​-hub","type":"content","url":"/lrose-basics#lrose-tutorials","position":9},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Issues?","lvl3":"LROSE Overview"},"type":"lvl4","url":"/lrose-basics#issues","position":10},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Issues?","lvl3":"LROSE Overview"},"content":"For problems running LROSE or general questions, please reach out on the LROSE \n\nforum.\n\nPlease submit bugs on \n\nGitHub.","type":"content","url":"/lrose-basics#issues","position":11},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Listserv","lvl3":"LROSE Overview"},"type":"lvl4","url":"/lrose-basics#listserv","position":12},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Listserv","lvl3":"LROSE Overview"},"content":"We maintain a listserv to alert the LROSE community of new LROSE releases, workshops, and other general communication. Email traffic is generally minimal.\n\nhttps://​lists​.colostate​.edu​/cgi​-bin​/mailman​/listinfo​/lrose​-users\n\n","type":"content","url":"/lrose-basics#listserv","position":13},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Initialize python","lvl3":"LROSE Overview"},"type":"lvl4","url":"/lrose-basics#initialize-python","position":14},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Initialize python","lvl3":"LROSE Overview"},"content":"\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport fsspec\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as plticker\nfrom matplotlib.lines import Line2D\nimport cartopy.crs as ccrs\nimport cartopy.io.shapereader as shpreader\nimport cartopy.geodesic as cgds\nfrom cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\nfrom cartopy import feature as cfeature\nimport xarray as xr\nimport pyart\n\n# Set directory variable to call LROSE\nos.environ[\"LROSE_DIR\"] = \"/usr/local/lrose/bin\"\n\n# Set the URL and path to access the data on the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = f\"pythia/radar/erad2024\"\n\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=URL))\n\nfs.glob(f\"{path}/20240522_MeteoSwiss_ARPA_Lombardia/Data/Cband/*\")\n\nfiles = fs.glob(\n    f\"{path}/20240522_MeteoSwiss_ARPA_Lombardia/Data/Cband/*.nc\"\n)  #### FIX PATH\nlocal_files = [\n    fsspec.open_local(\n        f\"simplecache::{URL}{i}\", s3={\"anon\": True}, filecache={\"cache_storage\": \".\"}\n    )\n    for i in files\n]\n\nfiles[0]\n\n# create a directory\n!mkdir -p ./raw\n\n# LROSE prefers files to have .nc extension, so create a softlink with the actual filename\n# We'll use the first file as an example!\nos.system(\"ln -sf \" + local_files[0] + \" ./raw/\" + files[0].split(\"/\")[-1])\n\n!pwd\n\n","type":"content","url":"/lrose-basics#initialize-python","position":15},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"LROSE on the Command Line"},"type":"lvl3","url":"/lrose-basics#lrose-on-the-command-line","position":16},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"LROSE on the Command Line"},"content":"Each LROSE application has different command line options for running. To see all the available options, use the -h flag.  RadxPrint -h\n\n# view the command line options\n!${LROSE_DIR}/RadxPrint -h\n\n","type":"content","url":"/lrose-basics#lrose-on-the-command-line","position":17},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"LROSE Parameter Files"},"type":"lvl3","url":"/lrose-basics#lrose-parameter-files","position":18},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"LROSE Parameter Files"},"content":"All LROSE applications have a detailed parameter file, which is read in at startup. The parameters allow the user to control the processing in the LROSE apps. To generate a default parameter file, you use the -print_params option for the app.\n\nFor example, for RadxConvert you would use:  RadxConvert -print_params > RadxConvert.nexrad\n\nand then edit RadxConvert.nexrad appropriately.\n\nAt runtime you would use:  RadxConvert -params RadxConvert.nexrad ... etc ...\n\n# view the default parameters\n!${LROSE_DIR}/RadxPrint -print_params\n\n# save the default parameters to a file\n!${LROSE_DIR}/RadxPrint -print_params > ./RadxPrint_params\n\n# if you have an existing parameter file and want to update it (e.g., a new LROSE version is released),\n# you could run a command similar to the following, just update the parameter file names\n# !${LROSE_DIR}/RadxPrint -f ./path/to/RadxPrint_params -print_params > ./RadxPrint_params_new\n\n# View the param file\n!cat ./RadxPrint_params\n\n","type":"content","url":"/lrose-basics#lrose-parameter-files","position":19},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"Inspect the Data"},"type":"lvl3","url":"/lrose-basics#inspect-the-data","position":20},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"Inspect the Data"},"content":"RadxPrint can print out file metadata, information about the variables, and other data. It’s an alternative to ncdump, depending on the information you want.\n\n# Print the metadata for the file we linked to earlier (-f flag links to files)\n!${LROSE_DIR}/RadxPrint -f ./raw/*.nc\n\n# Examine ray-specific metadata\n!${LROSE_DIR}/RadxPrint -summary -f ./raw/*.nc | tail -200\n\n","type":"content","url":"/lrose-basics#inspect-the-data","position":21},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"Format Conversion"},"type":"lvl3","url":"/lrose-basics#format-conversion","position":22},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"Format Conversion"},"content":"RadxConvert can convert many different file types into CfRadial files, which are used by most LROSE applications. You can specify specific parameters in a parameter file, but most of the time, RadxConvert works with a simple command.\n\n# Convert file (already cfradial, but you get the idea)\n# this will create a new subdirectory called convert along with a subdirectory YYYYMMDD that contains the file\n!${LROSE_DIR}/RadxConvert -f ./raw/*.nc -outdir ./convert\n\n","type":"content","url":"/lrose-basics#format-conversion","position":23},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"Simple Gridding"},"type":"lvl3","url":"/lrose-basics#simple-gridding","position":24},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"Simple Gridding"},"content":"Another commonly-used applicated is Radx2Grid, which regrids data onto a Cartesian grid. Usually, a user will want to specify parameters in a parameter file, but for the sake of time, we’ll just use the defaults to show how the application works.\n\n!${LROSE_DIR}/Radx2Grid -f ./convert/*/*.nc -outdir ./gridded\n\n","type":"content","url":"/lrose-basics#simple-gridding","position":25},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"Basic Data Display"},"type":"lvl3","url":"/lrose-basics#basic-data-display","position":26},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl3":"Basic Data Display"},"content":"With these files, we can plot the output to look at the data. Here, we’ll use Py-ART to plot the data in the CfRadial file and xarray/matplotlib to plot the gridded data.\n\n","type":"content","url":"/lrose-basics#basic-data-display","position":27},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Plotting CfRadial data with Py-ART","lvl3":"Basic Data Display"},"type":"lvl4","url":"/lrose-basics#plotting-cfradial-data-with-py-art","position":28},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Plotting CfRadial data with Py-ART","lvl3":"Basic Data Display"},"content":"\n\n# Read CfRadial file into radar object\nfilePath = os.path.join(\n    \"./\", \"convert/20240522/cfrad.20240522_125501.000_to_20240522_125944.950_L_SUR.nc\"\n)\nradar = pyart.io.read_cfradial(filePath)\nradar.info(\"compact\")\n\ndisplay = pyart.graph.RadarDisplay(radar)\nfig = plt.figure(1, (10, 10))\n\n# DBZ\n\naxDbz = fig.add_subplot(221)\ndisplay.plot_ppi(\n    \"reflectivity\",\n    0,\n    vmin=-32,\n    vmax=64.0,\n    axislabels=(\"x(km)\", \"y(km)\"),\n    colorbar_label=\"DBZ\",\n)\ndisplay.plot_range_rings([50, 100, 150, 200])\ndisplay.plot_cross_hair(200.0)\n\n# velocity\n\naxKdp = fig.add_subplot(222)\ndisplay.plot_ppi(\n    \"velocity\",\n    0,\n    vmin=-15,\n    vmax=15,\n    axislabels=(\"x(km)\", \"y(km)\"),\n    colorbar_label=\"velocity (m/s)\",\n)\ndisplay.plot_range_rings([50, 100, 150, 200])\ndisplay.plot_cross_hair(200.0)\n\n# spectrum width\n\naxHybrid = fig.add_subplot(223)\ndisplay.plot_ppi(\n    \"spectrum_width\", 0, axislabels=(\"x(km)\", \"y(km)\"), colorbar_label=\"sw (m/s)\"\n)\ndisplay.plot_range_rings([50, 100, 150, 200])\ndisplay.plot_cross_hair(200.0)\n\n# NCAR PID (computed)\n\naxPID = fig.add_subplot(224)\ndisplay.plot_ppi(\n    \"differential_reflectivity\",\n    0,\n    axislabels=(\"x(km)\", \"y(km)\"),\n    colorbar_label=\"ZDR (dB)\",\n)\ndisplay.plot_range_rings([50, 100, 150, 200])\ndisplay.plot_cross_hair(200.0)\n\nfig.tight_layout()\nplt.show()\n\n","type":"content","url":"/lrose-basics#plotting-cfradial-data-with-py-art","position":29},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Plotting Gridded Data with xarray and matplotlib","lvl3":"Basic Data Display"},"type":"lvl4","url":"/lrose-basics#plotting-gridded-data-with-xarray-and-matplotlib","position":30},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Plotting Gridded Data with xarray and matplotlib","lvl3":"Basic Data Display"},"content":"\n\n# Read in example radar mosaic for a single time\n\nfilePathGridded = os.path.join(\"./\", \"gridded/20240522/ncf_20240522_125944.nc\")\ndsGridded = xr.open_dataset(filePathGridded)\nprint(\"Radar mosaic file path: \", filePathGridded)\nprint(\"Radar mosaic data set: \", dsGridded)\n\n# Compute time\n\nstart_time = dsGridded[\"start_time\"]\nstartTimeStr = start_time.dt.strftime(\"%Y/%m/%d-%H:%M:%S UTC\")[0].values\nprint(\"Start time: \", startTimeStr)\n\nminLonMosaic = 7\nmaxLonMosaic = 11\nminLatMosaic = 44.5\nmaxLatMosaic = 47\n\n\n# Create map for plotting lat/lon grids\ndef new_map(fig):\n\n    ## Create projection centered on data\n    proj = ccrs.PlateCarree()\n\n    ## New axes with the specified projection:\n    ax = fig.add_subplot(1, 1, 1, projection=proj)\n\n    ## Set extent the same as radar mosaic\n    # ax.set_extent([minLonMosaic, maxLonMosaic, minLatMosaic, maxLatMosaic])\n\n    ## Add grid lines & labels:\n    gl = ax.gridlines(\n        crs=ccrs.PlateCarree(),\n        draw_labels=True,\n        linewidth=1,\n        color=\"lightgray\",\n        alpha=0.5,\n        linestyle=\"--\",\n    )\n    gl.top_labels = False\n    gl.left_labels = True\n    gl.right_labels = False\n    gl.xlines = True\n    gl.ylines = True\n    gl.xformatter = LONGITUDE_FORMATTER\n    gl.yformatter = LATITUDE_FORMATTER\n    gl.xlabel_style = {\"size\": 8, \"weight\": \"bold\"}\n    gl.ylabel_style = {\"size\": 8, \"weight\": \"bold\"}\n\n    return ax\n\n# Plot column-max reflectivity\nfigDbzComp = plt.figure(figsize=(8, 8), dpi=150)\naxDbzComp = new_map(figDbzComp)\nplt.imshow(\n    dsGridded[\"reflectivity\"].sel(z0=4.5).isel(time=0),\n    cmap=\"pyart_Carbone42\",\n    interpolation=\"bilinear\",\n    origin=\"lower\",\n    extent=([minLonMosaic, maxLonMosaic, minLatMosaic, maxLatMosaic]),\n)\naxDbzComp.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor=\"black\")\naxDbzComp.add_feature(cfeature.STATES, linewidth=0.3, edgecolor=\"brown\")\n# axDbzComp.coastlines('10m', 'darkgray', linewidth=1, zorder=0)\nplt.colorbar(label=\"DBZ\", orientation=\"vertical\", shrink=0.5)\nplt.title(\"Radar DBZ: \" + startTimeStr)\n\n","type":"content","url":"/lrose-basics#plotting-gridded-data-with-xarray-and-matplotlib","position":31},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Hawkeye","lvl3":"Basic Data Display"},"type":"lvl4","url":"/lrose-basics#hawkeye","position":32},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Hawkeye","lvl3":"Basic Data Display"},"content":"We also have an application called HawkEye that displays CfRadial radar data. It’s useful for switching between different sweeps and files.\n\n\n\n","type":"content","url":"/lrose-basics#hawkeye","position":33},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl2":"Afternoon preview"},"type":"lvl2","url":"/lrose-basics#afternoon-preview","position":34},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl2":"Afternoon preview"},"content":"Want to learn how to run multi-Doppler analysis using FRACTL and SAMURAI? Join us in the afternoon!","type":"content","url":"/lrose-basics#afternoon-preview","position":35},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Additional resources","lvl2":"Afternoon preview"},"type":"lvl4","url":"/lrose-basics#additional-resources","position":36},{"hierarchy":{"lvl1":"An Introduction to LROSE","lvl4":"Additional resources","lvl2":"Afternoon preview"},"content":"More tutorials can be found on our Gateway GitHub repo:\n\n\nhttps://​github​.com​/nsf​-lrose​/lrose​-hub\n\nThe LROSE wiki can be found here:\n\n\nhttp://​wiki​.lrose​.net​/index​.php​/Main​_Page#\n\nThe LROSE forum can be found here:\n\n\nhttp://​forum​.lrose​.net/","type":"content","url":"/lrose-basics#additional-resources","position":37},{"hierarchy":{"lvl1":"LROSE Wind Tutorial"},"type":"lvl1","url":"/lrose-erad-fractl-samurai","position":0},{"hierarchy":{"lvl1":"LROSE Wind Tutorial"},"content":"\n\nThis interactive tutorial takes you through the steps of how to run \n\nFRACTL and \n\nSAMURAI. FRACTL is a fast traditional solver with integrated interpolation using LROSE infrastructure, and it is able to perform both gridding and multi-Doppler synthesis for airborne radars and multiple ground-based radars. This is different than Radx2Grid which is only capable of gridding data for a single ground-based radar. FRACTL adopts techniques from older REORDER and CEDRIC software, but with some new improvements. In contrast to the older tools, in which interpolation is followed by synthesis, FRACTL does both steps together. FRACTL doesn’t require the CfRadial file with an aggregation of the sweeps, which is different than Radx2Grid. FRACTL performs a nearest neighbor interpolation of the reflectivity instead of bilinear interpolation in Radx2Grid. It combines the Doppler velocities together using the traditional ‘normal’ equations but with singular value decomposition of raw velocities in spherical space rather than Cramer’s rule in gridded space like CEDRIC.\n\nSAMURAI is a variational analysis technique that is described in \n\nBell et al. (2012), \n\nFoerster et al. (2014), \n\nFoerster and Bell (2017), \n\nCha and Bell (2021), \n\nCha and Bell (2023), and other publications. The SAMURAI analysis yields a maximum likelihood estimate of the atmospheric state for a given set of observations and error estimates by minimizing a variational cost function. SAMMURAI employs a finite element approach using a series of overlapping cubic B-spline basis functions.\nThis approach offers several advantages over a conventional grid-point representation, including:\n\nAllowing for a scaled-controlled analysis that can incorporate multiple spatial filters in the background error covariance and analytic spatial derivatives in observational space.\n\nNo need to interpolate irregular data distributions to a Cartesian grid, and the data can be used in the variational minimization in their native locations.\n\nSpatial derivative constraints are considered as pseudo-observations, which can be implicitely integrated during the cost function minimmization at any point in their native coordinate.\n\nIt has more features and more development than FRACTL, and is generally recommended over the former for publication-quality analysis. The two programs together provide a powerful combination to produce high quality multi-Doppler wind fields from ground-based, airborne, or mixed configurations.\n\n","type":"content","url":"/lrose-erad-fractl-samurai","position":1},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl3":"Tutorial Overview"},"type":"lvl3","url":"/lrose-erad-fractl-samurai#tutorial-overview","position":2},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl3":"Tutorial Overview"},"content":"","type":"content","url":"/lrose-erad-fractl-samurai#tutorial-overview","position":3},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"1. Setup","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#id-1-setup","position":4},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"1. Setup","lvl3":"Tutorial Overview"},"content":"","type":"content","url":"/lrose-erad-fractl-samurai#id-1-setup","position":5},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"QC-ed input data, a parameter file, and a center file:","lvl4":"1. Setup","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#qc-ed-input-data-a-parameter-file-and-a-center-file","position":6},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"QC-ed input data, a parameter file, and a center file:","lvl4":"1. Setup","lvl3":"Tutorial Overview"},"content":"a. QC-ed radar data files are provided (courtesy Meteorological Service of Catalonia, an overview of the tornado case can be found in \n\nDD​_Tornado​_ERAD24​.ipynb):\n\nCDV\n\nPBE\n\ncfrad.20180107_004225.662_to_20180107_004240.662_CREU_DEL_SUR.nc\n\ncfrad.20180107_004230.125_to_20180107_004245.125_PUIG_BER_SUR.nc\n\ncfrad.20180107_004244.092_to_20180107_004259.092_CREU_DEL_SUR.nc\n\ncfrad.20180107_004247.823_to_20180107_004301.823_PUIG_BER_SUR.nc\n\ncfrad.20180107_004301.347_to_20180107_004316.347_CREU_DEL_SUR.nc\n\ncfrad.20180107_004304.358_to_20180107_004319.358_PUIG_BER_SUR.nc\n\ncfrad.20180107_004318.235_to_20180107_004332.235_CREU_DEL_SUR.nc\n\ncfrad.20180107_004322.342_to_20180107_004337.342_PUIG_BER_SUR.nc\n\ncfrad.20180107_004335.672_to_20180107_004350.672_CREU_DEL_SUR.nc\n\ncfrad.20180107_004340.760_to_20180107_004355.760_PUIG_BER_SUR.nc\n\ncfrad.20180107_004351.684_to_20180107_004406.684_CREU_DEL_SUR.nc\n\ncfrad.20180107_004359.360_to_20180107_004414.360_PUIG_BER_SUR.nc\n\ncfrad.20180107_004409.010_to_20180107_004423.010_CREU_DEL_SUR.nc\n\ncfrad.20180107_004416.403_to_20180107_004431.403_PUIG_BER_SUR.nc\n\ncfrad.20180107_004426.910_to_20180107_004441.910_CREU_DEL_SUR.nc\n\ncfrad.20180107_004435.419_to_20180107_004450.419_PUIG_BER_SUR.nc\n\ncfrad.20180107_004444.218_to_20180107_004459.218_CREU_DEL_SUR.nc\n\ncfrad.20180107_004453.420_to_20180107_004508.420_PUIG_BER_SUR.nc\n\ncfrad.20180107_004501.640_to_20180107_004516.640_CREU_DEL_SUR.nc\n\ncfrad.20180107_004510.725_to_20180107_004525.725_PUIG_BER_SUR.nc\n\ncfrad.20180107_004519.306_to_20180107_004534.306_CREU_DEL_SUR.nc\n\ncfrad.20180107_004529.202_to_20180107_004544.202_PUIG_BER_SUR.nc\n\ncfrad.20180107_004535.929_to_20180107_004550.929_CREU_DEL_SUR.nc\n\ncfrad.20180107_004546.178_to_20180107_004601.178_PUIG_BER_SUR.nc\n\ncfrad.20180107_004554.649_to_20180107_004608.649_CREU_DEL_SUR.nc\n\ncfrad.20180107_004605.722_to_20180107_004620.722_PUIG_BER_SUR.nc\n\ncfrad.20180107_004612.565_to_20180107_004626.565_CREU_DEL_SUR.nc\n\ncfrad.20180107_004625.394_to_20180107_004640.394_PUIG_BER_SUR.nc\n\ncfrad.20180107_004630.909_to_20180107_004645.909_CREU_DEL_SUR.nc\n\ncfrad.20180107_004645.119_to_20180107_004700.119_PUIG_BER_SUR.nc\n\ncfrad.20180107_004649.801_to_20180107_004704.801_CREU_DEL_SUR.nc\n\ncfrad.20180107_004704.310_to_20180107_004719.310_PUIG_BER_SUR.nc\n\n*The QC process is not included in this tutorial. An example of one type of QC can be found in the QC tutorial and HawkEdit/solo are another tool to use for QC-ing data.\n\nb. A terrain file for SAMURAI is provided in order to activate wind retrievals over complex terrain\n\nterrain.hgt\n\n*If a user wishes to retrieve wind flows over complex terrain, a terrain.hgt is required to be included in the data folder. More details about how to generate a terrain.hgt can be found in Section X.","type":"content","url":"/lrose-erad-fractl-samurai#qc-ed-input-data-a-parameter-file-and-a-center-file","position":7},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"2. Basic FRACTL and SAMURAI “how to”","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#id-2-basic-fractl-and-samurai-how-to","position":8},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"2. Basic FRACTL and SAMURAI “how to”","lvl3":"Tutorial Overview"},"content":"Both FRACTL and SAMURAI are run on the command line, using simple commands like this:\n\nfractl -params /path/to/fractl.params\n\nsamurai -params /path/to/samurai.params\n\nAll of the information about how FRACTL and SAMURAI should analyze data (e.g., paths to input data, variable names, grids, filters) is defined in parameter files for each application. Therefore, most of the work to run FRACTL and SAMURAI goes into setting up the parameter files and placing files in the correct location.\n\nFRACTL requirements:\n\nradar data (CfRadial)\n\nparameter file\n\nSAMURAI requirements:\n\ndata (e.g., radar data, radiosondes, in-situ aircraft data)\n\ncenter file\n\nparameter file\n\noptional: terrain file\n\noptional: background file","type":"content","url":"/lrose-erad-fractl-samurai#id-2-basic-fractl-and-samurai-how-to","position":9},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"How to set up FRACTL","lvl4":"2. Basic FRACTL and SAMURAI “how to”","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#how-to-set-up-fractl","position":10},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"How to set up FRACTL","lvl4":"2. Basic FRACTL and SAMURAI “how to”","lvl3":"Tutorial Overview"},"content":"a. Set up directory structure:\n\nAll data that FRACTL will use need to be in the same directory. This tutorial will set up input and output directories for the initial FRACTL exercises. For additional FRACTL runs, we recommend creating new input and output directories to keep all analyses separate.\n\nb. Parameter files:\n\nFRACTL’s parameter file contains information about data I/O, the cartesian grid, and variable names. In this tutorial, the user will create their own parameter file from scratch and fill in the important parameters.","type":"content","url":"/lrose-erad-fractl-samurai#how-to-set-up-fractl","position":11},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"How to set up SAMURAI","lvl4":"2. Basic FRACTL and SAMURAI “how to”","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#how-to-set-up-samurai","position":12},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"How to set up SAMURAI","lvl4":"2. Basic FRACTL and SAMURAI “how to”","lvl3":"Tutorial Overview"},"content":"a. Set up directory structure:\n\nAll data and the center file defining the Cartesian grid that SAMURAI will use need to be in the same directory. This tutorial will set up input and output directories for the initial SAMURAI exercises. For additional SAMURAI runs, we recommend creating new input and output directories to keep all analyses separate.\n\nb. Center file:\n\nThe .cen file will be generated by the user through the provided Perl script. SAMURAI uses the center file to define the Cartesian frame of reference for the analysis, which be either be static or moving. It can be used to time-space correct the position of radar data in a moving storm system. It also sets the temporal limits for data to be included in the analysis. The center files are named according to the following convention: YYYYMMDD.cen\n\nProvided: Generate_center.pl\n\nc. Parameter files:\nSAMURAI’s parameter file contains information about data I/O, the cartesian grid, variable names, filters, and other scientific choices. In this tutorial, the user will create their own parameter file from scratch and fill in the important parameters.\n\n","type":"content","url":"/lrose-erad-fractl-samurai#how-to-set-up-samurai","position":13},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"Environment and packages¶","lvl4":"2. Basic FRACTL and SAMURAI “how to”","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#environment-and-packages","position":14},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"Environment and packages¶","lvl4":"2. Basic FRACTL and SAMURAI “how to”","lvl3":"Tutorial Overview"},"content":"First, we import the required python packages to run this notebook. Most of the LROSE processing can be done with the os package and shell commands.\n\nimport os\nimport fsspec\n\n#### Need to modify later\nos.environ[\"LROSE_DIR\"] = \"/usr/local/lrose/bin\"\n\n# Set the URL and path to access the data on the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = f\"pythia/radar/erad2024\"\n\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=URL))\n\nfs.glob(f\"{path}/lrose/*/*.nc\")\n\nfiles = fs.glob(f\"{path}/lrose/*/*.nc\")  # paths .../lrose/CDV_0042, .../lrose/PBE_004\nlocal_files = [\n    fsspec.open_local(\n        f\"simplecache::{URL}{i}\", s3={\"anon\": True}, filecache={\"cache_storage\": \".\"}\n    )\n    for i in files\n]\n\nfiles\n\nWe will copy the required data to one directory as SAMURAI requires and organize the directory by performing the following commands:\n\n# make parameter directory\n!mkdir -p ./lrose_params\n\n# make subdirectories for samurai and fractl input\n!mkdir -p ./fractl_input\n!mkdir -p ./samurai_input\n\n# create SAMURAI output directory\n!mkdir -p ./output_sam\n\n# create FRACTL output directory\n!mkdir -p ./output_frac\n\n# create links to cfradial files for fractl and rsync for SAMURAI (having issues with links)\nfor i in range(len(local_files)):\n    os.system('ln -sf '+local_files[i]+' ./fractl_input/'+files[i].split('/')[-1])\n    os.system('rsync -av '+local_files[i]+' ./samurai_input/'+files[i].split('/')[-1])\n\n\n\n","type":"content","url":"/lrose-erad-fractl-samurai#environment-and-packages","position":15},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"2. Prepare data for analysis","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#id-2-prepare-data-for-analysis","position":16},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"2. Prepare data for analysis","lvl3":"Tutorial Overview"},"content":"In this tutorial, the provided data have already been QC-ed. For a standard procedure, users are recommended to perform the following procedure:\n\nConvert radar data from level 2 or other native format to CfRadial using RadxConvert\n\nSAMURAI can also incorporate non-radar data, and can read many commonly used formats. All data files in the input directory will be included in the analysis. The read subroutine for each datatype is determined by the file suffix.\n\nQuality-controlled raw data by desired QC-tools. See the QC tutorial for an example of how QC can be done; HawkEdit and Solo can also be used to QC data.\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-2-prepare-data-for-analysis","position":17},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"3. Setup the FRACTL parameter file","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#id-3-setup-the-fractl-parameter-file","position":18},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"3. Setup the FRACTL parameter file","lvl3":"Tutorial Overview"},"content":"","type":"content","url":"/lrose-erad-fractl-samurai#id-3-setup-the-fractl-parameter-file","position":19},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"3.1 Generate the parameter file","lvl4":"3. Setup the FRACTL parameter file","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#id-3-1-generate-the-parameter-file","position":20},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"3.1 Generate the parameter file","lvl4":"3. Setup the FRACTL parameter file","lvl3":"Tutorial Overview"},"content":"First, we need to generate the parameter file! LROSE applications use a standard -print_params flag to generate parameter files with the defaults. We just need to specify the location and name of the parameter file. We have already set up a directory where you can place the parameter files. Feel free to change the name of the file if you prefer.\n\nTask: Create the FRACTL parameter file. Copy the following command into the open cell below and run it! !${LROSE_DIR}/fractl -print_params > ./lrose_params/fractl_params\n\n\n\nNow that we have generated the parameter file, we can inspect the file. In JupyterHub, you can edit the file either in a terminal with vi or by opening the text file via the lefthand menu - whichever you prefer! The file should be located here: /home/jovyan/lrose-hub/params/wind_guided\n\nTask: Open the parameter file for modification.\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-3-1-generate-the-parameter-file","position":21},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"3.2 Modify the parameter file","lvl4":"3. Setup the FRACTL parameter file","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#id-3-2-modify-the-parameter-file","position":22},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"3.2 Modify the parameter file","lvl4":"3. Setup the FRACTL parameter file","lvl3":"Tutorial Overview"},"content":"Now we will step through and edit the parameter file.\n\nFirst, we’ll start with the parameters associated with the input/output data directories and filenames.\n\nParameter\n\nLine #\n\nDescription\n\ninDir\n\n391\n\nThe input data directory. It can be a relative path, but an absolute path is more certain.\n\nfileRegex\n\n399\n\nA regular expression to identify the files used for analysis. Usually ^cfrad, to find CfRadial files.\n\noutNc\n\n426\n\nThe output directory where the analysis will go.\n\noutTxt\n\n417\n\nthe name of the text file that will contain the verification of grid results.\n\nTask: change the inDir, fileRegex, and outNc parameters. Refer to the table above to find the parameters in the text file.\n\ninDir = \"./fractl_input\"\n\nfileRegex = \"^cfrad\"\n\noutNc = \"./output_frac/\"\n\noutTxt = \"./output_frac/fractl_output.txt\"\n\n\n\nNext, we’ll define the cartesian grid.\n\nParameter\n\nLine #\n\nDescription\n\nzGrid, yGrid, xGrid\n\n174, 182, 190\n\nThese determine the grid spacing and size of the domain. Provide either the grid spacing to determine the max and min from the data or provide “min,max,incr” for each parameter.\n\nprojLat0, projLon0\n\n229, 237\n\nThe origin is an arbitrarily chosen point, but should be relevant for your objective. For example, it can be the geographical center of your multi-radar domain, the physical location of a radar for a single-radar domain, or the location of a feature of interest within your dataset (such as storm center). The latitude and longitude of your chosen origin should be given in decimal degrees.\n\nradarAlt\n\n245\n\nAltitude of the radar (km). Sometimes mobile radars have the altitude entered in m, which can often cause errors in FRACTL.\n\nTask: set up the FRACTL grid using the following values. We have provided the grid information for you. In this example, we will make a small box around the tornado with 500 m grid spacing. The projLat0 and projLon0 correspond to the CDV radar location, so the reference point (x0, y0)=(0,0) corresponds to the CDV radar here.\n\nzGrid = \"0,10,0.5\"\n\nyGrid = \"10,40,0.5\"\n\nxGrid = \"10,35,0.5\"\n\nprojLat0 = 41.601666\n\nprojLon0 = 1.402777\n\nradarAlt = 0.631\n\n\n\nFinally, we’ll define the variable names so that FRACTL knows which variables to use in the analysis.\n\nParameter\n\nLine #\n\nDescription\n\nradialName\n\n440\n\nVariable name for the Doppler velocity.\n\ndbzName\n\n448\n\nVariable name for the radar reflectivity.\n\nncpName\n\n456\n\nVariable name for the normalized coherent power. This variable can be used to do some simple QC thresholding. If you don’t have NCP or SQI in your data then just point this to any other variable and select a value above which all data will be included.\n\nminDbz\n\n58\n\nAny values below the minimum reflectivity value will be tossed out. Example: -20.\n\nminNcp\n\n69\n\nAny values below the minimum NCP will be tossed out. Some radars do not have NCP, so the NCP variable can be replaced by any other variable to perform a simple quality control (e.g., SW < -1, dBZ < -20). This is generally intended for quick realtime quality control process.\n\nTask: look for the variable names for reflectivity, velocity, and whether NCP exists in each file.\n\nWe can use a couple applications to examine the variable names in our radar files (e.g., ncdump or RadxPrint). To limit the application output, you can also pipe information to commands like grep or head. Some example commands you can try are listed below.\n\nCopy them as is to try them out in the next Jupyter cell. If you prefer to run them in a terminal window, remove the “!” symbol, which is just for Jupyter notebooks.\n\n!ncdump -h $./fractl_input/cfrad.20180107_004225.662_to_20180107_004240.662_CREU_DEL_SUR.nc\n\n!ncdump -h ./fractl_input/cfrad.20180107_004230.125_to_20180107_004245.125_PUIG_BER_SUR.nc\n\n!${LROSE_DIR}/RadxPrint -f ./fractl_input/cfrad.20180107_004225.662_to_20180107_004240.662_CREU_DEL_SUR.nc\n\n!${LROSE_DIR}/RadxPrint -f ./fractl_input/cfrad.20180107_004230.125_to_20180107_004245.125_PUIG_BER_SUR.nc\n\n\n\nTask: define the radar variable names in the parameter file based on the output discovered above.\n\nCongrats! You’ve finished setting up the FRACTL parameter file!\n\n\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-3-2-modify-the-parameter-file","position":23},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"4. Run FRACTL","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#id-4-run-fractl","position":24},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"4. Run FRACTL","lvl3":"Tutorial Overview"},"content":"After modifying the parameter file, direct to the parameter file by using the -params flags\n\n!${LROSE_DIR}/fractl -params ./lrose_params/fractl_params\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-4-run-fractl","position":25},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"5. Plot FRACTL results","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#id-5-plot-fractl-results","position":26},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"5. Plot FRACTL results","lvl3":"Tutorial Overview"},"content":"","type":"content","url":"/lrose-erad-fractl-samurai#id-5-plot-fractl-results","position":27},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"Environment and packages","lvl4":"5. Plot FRACTL results","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#environment-and-packages-1","position":28},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"Environment and packages","lvl4":"5. Plot FRACTL results","lvl3":"Tutorial Overview"},"content":"Import the packages to plot the FRACTL output. These are pre-installed for this tutorial, but if you run this notebook on your own computer you may need to install them yourself using pip or conda.\n\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\nimport numpy as np\nimport xarray as xr\nimport matplotlib as mpl\nimport cartopy.crs as ccrs\nfrom metpy.plots import ctables\nfrom cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n\nmpl.rcParams[\"figure.dpi\"] = 300\n\nLoad the netcdf file\n\ninDir = \"./output_frac/20180107/\"\nfile = \"ncf_20180107_004719.nc\"\nds_radar = xr.open_dataset(inDir + file).squeeze()\nds_radar.load()\n\n## Get variables:\nda_DBZ = ds_radar[\"DBZ\"]\nda_U = ds_radar[\"U\"]\nda_V = ds_radar[\"V\"]\nda_W = ds_radar[\"W\"]\nda_CN = ds_radar[\"conditionNumber\"]\n\n# radar locations (PBE, CDV)\nradar_lats = [41.37, 41.96]\nradar_lons = [1.39, 1.4]\n\n## Set NWS reflectivity colorbar:\nref_norm, ref_cmap = ctables.registry.get_with_steps(\n    \"NWSStormClearReflectivity\", 0, 0.35\n)\nplotting_alt = 1.5 * 1000  # altitude at 1.5 km\nplotting_var = ds_radar.DBZ.sel(z0=plotting_alt).data\nplotting_var_u = ds_radar.U.sel(z0=plotting_alt).data\nplotting_var_v = ds_radar.V.sel(z0=plotting_alt).data\nplotting_lon = ds_radar.lon0\nplotting_lat = ds_radar.lat0\n\nfig = plt.figure(figsize=(12, 12))\nax = plt.axes(projection=ccrs.PlateCarree())\n# stamen_terrain = cimgt.Stamen('terrain')\n# ax.add_image(stamen_terrain, 8)\n\ncf1 = ax.pcolormesh(\n    plotting_lon,\n    plotting_lat,\n    plotting_var,\n    cmap=ref_cmap,\n    norm=ref_norm,\n    alpha=0.8,\n    shading=\"auto\",\n    transform=ccrs.PlateCarree(),\n)\nstep = 1\ncf_q = ax.quiver(\n    plotting_lon[::step, ::step],\n    plotting_lat[::step, ::step],\n    plotting_var_u[::step, ::step],\n    plotting_var_v[::step, ::step],\n    scale=1000,\n    width=0.004,\n    color=\"k\",\n    transform=ccrs.PlateCarree(),\n)\n\n\ngl = ax.gridlines(\n    crs=ccrs.PlateCarree(),\n    draw_labels=True,\n    linewidth=2,\n    color=\"gray\",\n    alpha=0.5,\n    linestyle=\"--\",\n)\ngl.top_labels = False\ngl.right_labels = False\ngl.xformatter = LONGITUDE_FORMATTER\ngl.yformatter = LATITUDE_FORMATTER\n\ncbar_ax = fig.add_axes([0.95, 0.3, 0.02, 0.4])\ncbar = fig.colorbar(cf1, cax=cbar_ax, fraction=0.04)\ncbar.ax.tick_params(labelsize=14)\ncbar.ax.set_title(\"[dBZ]\", fontsize=14, y=-0.1)\n\n","type":"content","url":"/lrose-erad-fractl-samurai#environment-and-packages-1","position":29},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"If you can see the above plot, then congratulations! You have successfully created and plotted a dual-Doppler analysis. Now let’s try SAMURAI","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#if-you-can-see-the-above-plot-then-congratulations-you-have-successfully-created-and-plotted-a-dual-doppler-analysis-now-lets-try-samurai","position":30},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"If you can see the above plot, then congratulations! You have successfully created and plotted a dual-Doppler analysis. Now let’s try SAMURAI","lvl3":"Tutorial Overview"},"content":"\n\n","type":"content","url":"/lrose-erad-fractl-samurai#if-you-can-see-the-above-plot-then-congratulations-you-have-successfully-created-and-plotted-a-dual-doppler-analysis-now-lets-try-samurai","position":31},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#id-6-set-the-samurai-parameters","position":32},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"content":"","type":"content","url":"/lrose-erad-fractl-samurai#id-6-set-the-samurai-parameters","position":33},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"6.1 Set up the center file","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#id-6-1-set-up-the-center-file","position":34},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"6.1 Set up the center file","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"content":"One difference between FRACTL and SAMURAI is the requirement of a centerfile, which allows for a moving domain. We will modify and run the Generate_center.pl perl script to generate a time-series of center locations by providing an estimation of the moving speed of the target and the reference location.\n\nParameter\n\nLine #\n\nDescription\n\nlat_origin, lon_origin\n\n13, 14\n\nLatitude and longitude of reference frame at origin time.\n\nu, v\n\n15, 16\n\nStorm motion.\n\nymd\n\n17\n\nDate of initial time (YYYYMMDD).\n\nhr, mn, sec\n\n18, 19, 20\n\nInitial hour, minute, second of track.\n\nduration\n\n21\n\nDuration of track in seconds.\n\norigintime\n\n22\n\nTime when the frame is at the latitude/longitude at the origin time in seconds from the initial time.\n\nTask: open the Generate_center.pl script and modify the parameters for this case.\n\nThe script can be found here: ./Generate_center.pl\n\nFor lat_origin and lon_origin, use the values that we defined above in the FRACTL parameter file.\n\nFor this example, we will use a moving domain. Set u and v can be set to 8.8 m/s.\n\nThe initial time set by ymd, hr, mn, and sec should be set such that the data all occur after the initial time. CfRadial files often contain the start time of the data in their file names. Look at the two files we are using and see when the data starts. Set your initial time before that time - usually 5-10 seconds is sufficient.\n\nDuration sets the length of the analysis. Similar to the initial time, look at the CfRadial filenames to determine the latest timestamp associated with the data. Then determine the number of seconds needed to encompass all the data from the two files. Feel free to round up a few seconds.\n\nFor a moving next, origintime will need to match the reference time in the SAMURAI parameter file, so pick a time within your time frame and note the HH:MM:SS for later.\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-6-1-set-up-the-center-file","position":35},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"6.2 Generate the center file","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#id-6-2-generate-the-center-file","position":36},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"6.2 Generate the center file","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"content":"Task: run the Perl script to generate the center file and move the center file to the wind_guided input directory. First, we need to make the script executable so we can run it. Run the following command to change the permissions.\n\n!chmod u+x ./Generate_center.pl\n\nGenerate the .cen file in the input directory using the following command:\n!Generate_center.pl\n\n\n\nGenerate_center.pl creates the file in the directory containing this notebook. We just need to move it to the input directory, which we can do with the following command. Using either a terminal or the nagivation at the left of the notebook, double check that the file is now in the input directory.\n\n!mv ./*.cen ./samurai_input\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-6-2-generate-the-center-file","position":37},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"6.3 Generate the SAMURAI parameter file","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#id-6-3-generate-the-samurai-parameter-file","position":38},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"6.3 Generate the SAMURAI parameter file","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"content":"Like FRACTL, SAMURAI uses the -print_params flag to generate parameter files with the defaults. We just need to specify the location and name of the parameter file. We have already set up a directory where you can place the parameter files. Feel free to change the name of the file if you prefer.\n\nTask: generate the SAMURAI parameter file. Copy the following command into the open cell below and run it!\n\n!${LROSE_DIR}/samurai -print_params > ./lrose_params/samurai_params\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-6-3-generate-the-samurai-parameter-file","position":39},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"6.4 Modify the SAMURAI parameter file","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#id-6-4-modify-the-samurai-parameter-file","position":40},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"6.4 Modify the SAMURAI parameter file","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"content":"Now we will step through and edit the parameter file.\n\nFirst, we’ll start with the parameters associated with the input/output data directories and filenames.\n\nParameter\n\nLine #\n\nDescription\n\ndata_directory\n\n171\n\nThe input data directory. It can be a relative path, but an absolute path is more certain.\n\noutput_directory\n\n181\n\nThe output directory where the analysis will go.\n\nTask: set the data directories.\n\nChange the data_directory and output_directory parameters to the following.\n\ndata_directory = “./samurai_input”\n\noutput_directory = “./output_sam”\n\n\n\nNext, we’ll define the cartesian grid.\n\nParameter\n\nLine #\n\nDescription\n\ni_min, i_max, i_incr\n\n254, 260, 266\n\nDefine the minimum and maximum extent and grid spacing in km of the first horizontal dimension (e.g., Cartesian ‘x’ dimension). For cylindrical analyses (RTZ mode), this is radius.\n\nj_min, j_max, j_incr\n\n272, 278, 284\n\nDefine the minimum and maximum extent and grid spacing of the second horizontal dimension (e.g., Cartesian ‘y’ dimension in km). For cylindrical analyses (RTZ mode), this is azimuth (degrees).\n\nk_min, k_max, k_incr\n\n290, 296, 302\n\nDefine the minimum and maximum extent and grid spacing in km of the vertical dimension (i.e., ‘z’ dimension). k_min should usually be 0.\n\nTask: set up the SAMURAI grid.\n\nUsing the grid spacing and span that we used to set up FRACTL, fill out these 9 parameters in the SAMURAI parameter file. Since we are creating a Cartesian analysis, i, j, and k correspond to x, y, and z.\n\n\n\nSAMURAI requires the user to set the background time.\n\nParameter\n\nLine #\n\nDescription\n\nref_time\n\n324\n\nThis is the reference time to which all data will be time-space corrected. It must be a valid time in the centerfile or an error will occur. The time should be the same as the origin time corresponding to the latitude/longitude in the Perl center file script.\n\nTask: define the reference time.\n\nThe reference time in SAMURAI should correspond to the same time as the origin time (not the start time) that was used in the Generate_center.pl script. The format is HH:MM:SS.\n\n\n\nNext, we’ll set some remaining parameters which define the radar variable names, radii of influence, and how much data is processed.\n\nParameter\n\nLine #\n\nDescription\n\nradar_skip\n\n352\n\nThis option can be used to skip beams in the radar data. When set to ‘1’, all beams are used. Setting it to 2 speeds up the calculation and is useful for preliminary analysis. It should generally be set to 1 for final analysis.\n\nradar_stride\n\n358\n\nThis option sets the number of gates over which averaging occurs along the beam. A stride of ‘1’ uses all data, and higher numbers average multiple gates of the given stride. Higher numbers speed up the calculation and can be used to thin the data to achieve desired spatial resolution of the input velocities.\n\nradar_dbz\n\n382\n\nThe name of the reflectivity field in the radar data.\n\nradar_vel\n\n392\n\nThe name of the Doppler velocity field in the radar data.\n\nradar_sw\n\n398\n\nThe name of the spectrum width field in the radar data. This value is used to set the observational error for the Doppler velocity. If you don’t have spectrum width, you can point it at another variable (like NCP) or create a simple uniform field.\n\ni_reflectivity_roi, j_reflectivity_roi, k_reflectivity_roi\n\n404, 410, 416\n\nThese variables set the radius of influence for the reflectivity interpolation. They should be similar to the grid increments defined above.\n\nmask_reflectivity\n\n428\n\nThe analysis can be set to missing data where there is no reflectivity. If set to ‘None’ then no masking is performed. A numerical value will be used as a threshold for the masking, with all data at nodes having less than the given reflectivity value removed. If you are not using a background field then it is generally a good idea to set this to some small number (like -10 dBZ) since the winds are not valid if there is no radar data.\n\nTask: fill out the radar-specific parameters\n\nThe radar_dbz and radar_vel parameters are the same names that were used in the FRACTL parameter file. The radar_sw parameter can be determined in a similar manner that we used earlier.\n\nFor the radii of influence, use a value of 0.5, similar to the grid spacings.\n\nFinally, mask_reflectivity can be set to a low value to remove weak echo regions. A value around -25 dBZ is often sufficient.\n\n\n\nFinally, we’ll correct some default parameters..\n\nParameter\n\nLine #\n\nDescription\n\nload_background\n\n93\n\nA first guess of the analysis stored in the samurai_Background.in will be loaded. This can come from a model, sounding, or other data source if available. Most of the time it is not available so it should be set to FALSE.\n\noutput_latlon_increment\n\n1028\n\nSAMURAI can produce XYP analyses, where the vertical coordinate is pressure. This parameter sets the lat/lon increment.\n\noutput_pressure_increment\n\n1034\n\nSAMURAI can produce XYP analyses, where the vertical coordinate is pressure. This parameter sets the pressure level increment. Set to -1 for XYZ analyses. This will be made a default of -1 in a future release.\n\nTask: fill out the radar-specific parameters\n\nSome of the default parameters have not been fixed in this version of SAMURAI. Set load_background to FALSE, and output_latlon_increment and output_pressure_increment to -1.\n\nFor a list of additional SAMURAI parameters, please refer to the appendix at the end of this notebook.\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-6-4-modify-the-samurai-parameter-file","position":41},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"6.5 Generate a terrain file","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#id-6-5-generate-a-terrain-file","position":42},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"6.5 Generate a terrain file","lvl4":"6. Set the SAMURAI parameters","lvl3":"Tutorial Overview"},"content":"\n\na. Data source and structure of input terrain file\n\nTerrain data is chosen by the user and can be obtained from different sources such as model data, ASTER-DEM, SRTM, and others. Users are required to save the file as terrain.hgt. The subroutine for reading the file is determined by its suffix (hgt).\n\nThe terrain file data should be structured as follows:\n\nLatitude\n\nLongitude\n\nTerrain-Height(m)\n\ndh/dx(unitless)\n\ndh/dy(unitless)\n\nX(km)\n\nY(km)\n\n41.692\n\n1.523\n\n636.789\n\n-0.002\n\n0.007\n\n10.0\n\n10.0\n\n41.696\n\n1.523\n\n640.075\n\n-0.001\n\n0.006\n\n10.0\n\n10.5\n\n41.701\n\n1.523\n\n642.975\n\n-0.001\n\n0.006\n\n10.0\n\n11.0\n\n41.705\n\n1.523\n\n645.635\n\n-0.001\n\n0.005\n\n10.0\n\n11.5\n\n41.71\n\n1.523\n\n647.869\n\n-0.0\n\n0.004\n\n10.0\n\n12.0\n\n41.714\n\n1.523\n\n649.542\n\n0.0\n\n0.003\n\n10.0\n\n12.5\n\n41.719\n\n1.523\n\n650.772\n\n0.001\n\n0.002\n\n10.0\n\n13.0\n\n41.723\n\n1.523\n\n651.559\n\n0.002\n\n0.001\n\n10.0\n\n13.5\n\n...\n\n...\n\n...\n\n...\n\n...\n\n...\n\n...\n\nX and Y should match the desired output grid which corresponds to the “GRID DEFINITION SECTION” in the parameter file.\n\nIn this tutorial, the terrain file is provided.\n\nb. Modify the SAMURAI parameter file related to the terrain boundary conditions\n\nNow, we can modify the weights associated with the terrain calculation. When a terrain file is included in the directory, users can determine the strength of the boundary condition by changing the magnitude of neumann_u_weight, neumann_v_weight, and dirichlet_w_weight. The neumann_u_weight, neumann_v_weight regulate the impermeability of the horizontal flow as it encounters the terrain, and the dirichlet_w_weight governs the vertical motion generated by topographic influences when horizontal flow interacts with the terrain.\n\nParameter\n\nLine #\n\nDescription\n\nneumann_u_weight\n\n1147-1149\n\nThis option sets the strength of the impermeability of the horizontal flow in u direction as it encounters the terrain.\n\nneumann_v_weight\n\n1157-1159\n\nThis option sets the strength of the impermeability of the horizontal flow in v direction as it encounters the terrain.\n\ndirichlet_w_weight\n\n1167-1169\n\nThis option sets the strength of the topographic forcing when horizontal flow interacts with the terrain.\n\nThe default value is 0.1 for all the boundary condition weights. However, the choice of settings must be carefully evaluated on a case-by-case basis and their interpretations should be made accordingly when drawing scientific conclusions.\n\nNow let’s take a look at the provided terrain.hgt text file:\n\nfile_path = \"./data/terrain.hgt\"\nterr_lat = []\nterr_lon = []\nterr_height = []  # Add more if there are more columns\nterr_x = []\nterr_y = []\n\n# Open and read the text file line by line\nwith open(file_path, \"r\") as file:\n    for line in file:\n        # Remove tab and newline characters from the line\n        line = line.replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n\n        # Split the line into columns (assuming space-separated values)\n        columns = line.split()  # You can change the delimiter inside split() if needed\n\n        # Append each column's data to the respective list\n        if len(columns) > 0:\n            terr_lat.append(float(columns[0]))\n        if len(columns) > 1:\n            terr_lon.append(float(columns[1]))\n        if len(columns) > 2:\n            terr_height.append(float(columns[2]))\n        if len(columns) > 5:\n            terr_x.append(float(columns[5]))\n        if len(columns) > 6:\n            terr_y.append(float(columns[6]))\n        # Add more if there are more columns\n\nfig = plt.figure(figsize=(12, 12))\nax = plt.axes(projection=ccrs.PlateCarree())\ncf1 = plt.scatter(\n    terr_lon, terr_lat, s=terr_height, c=terr_height, cmap=\"terrain\", vmin=0, vmax=1000\n)\n\ncbar_ax = fig.add_axes([0.95, 0.3, 0.02, 0.4])\ncbar = fig.colorbar(cf1, cax=cbar_ax, fraction=0.04)\ncbar.ax.tick_params(labelsize=14)\ncbar.ax.set_title(\"Terrain Height (m)\", fontsize=14)\n\ngl = ax.gridlines(\n    crs=ccrs.PlateCarree(),\n    draw_labels=True,\n    linewidth=2,\n    color=\"gray\",\n    alpha=0.5,\n    linestyle=\"--\",\n)\ngl.top_labels = False\ngl.right_labels = False\ngl.xformatter = LONGITUDE_FORMATTER\ngl.yformatter = LATITUDE_FORMATTER\n\n\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-6-5-generate-a-terrain-file","position":43},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"7. Run SAMURAI","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#id-7-run-samurai","position":44},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"7. Run SAMURAI","lvl3":"Tutorial Overview"},"content":"After modifying the parameter file, direct to the parameter file by using the -params flags\n\n!${LROSE_DIR}/samurai -params ./lrose_params/samurai_params\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-7-run-samurai","position":45},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"8. Plot SAMURAI results","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#id-8-plot-samurai-results","position":46},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"8. Plot SAMURAI results","lvl3":"Tutorial Overview"},"content":"\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-8-plot-samurai-results","position":47},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"Environment and packages¶","lvl4":"8. Plot SAMURAI results","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#environment-and-packages-2","position":48},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"Environment and packages¶","lvl4":"8. Plot SAMURAI results","lvl3":"Tutorial Overview"},"content":"The packages were already imported when we plotted the FRACTL results.\n\n","type":"content","url":"/lrose-erad-fractl-samurai#environment-and-packages-2","position":49},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"Load the netcdf file","lvl4":"8. Plot SAMURAI results","lvl3":"Tutorial Overview"},"type":"lvl5","url":"/lrose-erad-fractl-samurai#load-the-netcdf-file","position":50},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl5":"Load the netcdf file","lvl4":"8. Plot SAMURAI results","lvl3":"Tutorial Overview"},"content":"\n\ninDir_s = \"./output_sam/\"\nfile_s = \"samurai_XYZ_analysis.nc\"\nds_radar_s = xr.open_dataset(inDir_s + file_s).squeeze()\nds_radar_s.load()\n\n## Get variables:\nda_s_DBZ = ds_radar_s[\"DBZ\"]\nda_s_U = ds_radar_s[\"U\"]\nda_s_V = ds_radar_s[\"V\"]\nda_s_W = ds_radar_s[\"W\"]\nda_s_ABSVORT = ds_radar_s[\"ABSVORT\"]\nda_s_DIV = ds_radar_s[\"DIV\"]\n\nlon_s, lat_s = np.meshgrid(ds_radar_s.longitude, ds_radar_s.latitude)\n\n## Set NWS reflectivity colorbar:\nref_norm, ref_cmap = ctables.registry.get_with_steps(\n    \"NWSStormClearReflectivity\", 0, 0.35\n)\nplotting_alt = 3.5  # can change to different altitude\nplotting_var_s = ds_radar_s.DBZ.sel(altitude=plotting_alt)\nplotting_var_u_s = ds_radar_s.U.sel(altitude=plotting_alt).data\nplotting_var_v_s = ds_radar_s.V.sel(altitude=plotting_alt).data\nplotting_lon_s = ds_radar_s.longitude\nplotting_lat_s = ds_radar_s.latitude\n\nfig = plt.figure(figsize=(12, 12))\nax = plt.axes(projection=ccrs.PlateCarree())\n# stamen_terrain = cimgt.Stamen('terrain')\n# ax.add_image(stamen_terrain, 8)\n\ncf1 = ax.pcolormesh(\n    plotting_lon_s,\n    plotting_lat_s,\n    plotting_var_s,\n    cmap=ref_cmap,\n    norm=ref_norm,\n    alpha=0.8,\n    shading=\"auto\",\n    transform=ccrs.PlateCarree(),\n)\nstep = 1\ncf_q = ax.quiver(\n    plotting_lon_s[::step],\n    plotting_lat_s[::step],\n    plotting_var_u_s[::step, ::step],\n    plotting_var_v_s[::step, ::step],\n    scale=1000,\n    width=0.004,\n    color=\"k\",\n    transform=ccrs.PlateCarree(),\n)\nax.contour(\n    plotting_lon_s,\n    plotting_lat_s,\n    plotting_var_s,\n    levels=np.arange(35, 100, 100),\n    colors=\"k\",\n    linewidths=3,\n    transform=ccrs.PlateCarree(),\n)\ngl = ax.gridlines(\n    crs=ccrs.PlateCarree(),\n    draw_labels=True,\n    linewidth=2,\n    color=\"gray\",\n    alpha=0.5,\n    linestyle=\"--\",\n)\ngl.top_labels = False\ngl.right_labels = False\ngl.xformatter = LONGITUDE_FORMATTER\ngl.yformatter = LATITUDE_FORMATTER\n\ncbar_ax = fig.add_axes([0.95, 0.3, 0.02, 0.4])\ncbar = fig.colorbar(cf1, cax=cbar_ax, fraction=0.04)\ncbar.ax.tick_params(labelsize=14)\ncbar.ax.set_title(\"[dBZ]\", fontsize=14, y=-0.1)\n\n","type":"content","url":"/lrose-erad-fractl-samurai#load-the-netcdf-file","position":51},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"9. Apply FRACTL Condition Number","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#id-9-apply-fractl-condition-number","position":52},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"9. Apply FRACTL Condition Number","lvl3":"Tutorial Overview"},"content":"The FRACTL ‘Condition Number’ represents how well-posed the geometry is for a particular multi-Doppler retrieval. It is similar to the USTD and VSTD field from CEDRIC, which represent the standard deviation of the expected error in the resolved wind field based on the geometry. Since SAMURAI solves for the wind field globally using spline basis functions, it is difficult to calculate this error at each gridpoint. If a FRACTL analysis is run on the same domain, then it can be used to remove regions with poor geometry. Here, we use a value of 10 to threshold the SAMURAI analysis.\n\n# Read file into radar object\ninDir_f = \"./output_frac/20180107/\"\nfile_f = \"ncf_20180107_004719.nc\"\nds_radar_f = xr.open_dataset(inDir_f + file_f).squeeze()\nds_radar_f\n\nplotting_CN = ds_radar_f.conditionNumber.sel(z0=1.5 * 1000)\n\nCN_threshold = 10\ndbz_goodcondition = np.where(plotting_CN < CN_threshold, plotting_var_s, np.nan)\nu_goodcondition = np.where(plotting_CN < CN_threshold, plotting_var_u_s, np.nan)\nv_goodcondition = np.where(plotting_CN < CN_threshold, plotting_var_v_s, np.nan)\nw_goodcondition = np.where(plotting_CN < CN_threshold, plotting_var_w_s, np.nan)\nvort_goodcondition = np.where(plotting_CN < CN_threshold, plotting_var_vort_s, np.nan)\n\nfig = plt.figure(figsize=(10, 10))\nax = plt.axes(projection=ccrs.PlateCarree())\n\ncf1 = ax.pcolormesh(\n    plotting_lon_s,\n    plotting_lat_s,\n    dbz_goodcondition,\n    cmap=ref_cmap,\n    norm=ref_norm,\n    alpha=0.8,\n    shading=\"auto\",\n    transform=ccrs.PlateCarree(),\n)\nstep = 1\ncf_q = ax.quiver(\n    plotting_lon_s[::step],\n    plotting_lat_s[::step],\n    u_goodcondition[::step, ::step],\n    v_goodcondition[::step, ::step],\n    scale=1000,\n    width=0.004,\n    color=\"k\",\n    transform=ccrs.PlateCarree(),\n)\n\ngl = ax.gridlines(\n    crs=ccrs.PlateCarree(),\n    draw_labels=True,\n    linewidth=2,\n    color=\"gray\",\n    alpha=0.5,\n    linestyle=\"--\",\n)\ngl.top_labels = False\ngl.right_labels = False\ngl.xformatter = LONGITUDE_FORMATTER\ngl.yformatter = LATITUDE_FORMATTER\n\ncbar_ax = fig.add_axes([0.95, 0.3, 0.02, 0.4])\ncbar = fig.colorbar(cf1, cax=cbar_ax, fraction=0.04)\ncbar.ax.tick_params(labelsize=14)\ncbar.ax.set_title(\"[dBZ]\", fontsize=14, y=-0.1)\n\n## Set NWS reflectivity colorbar:\nplotting_alt = 2.5  # altitude at 3 km\nplotting_var_s = ds_radar_s.DBZ.sel(altitude=3.5)\nplotting_var_u_s = ds_radar_s.U.sel(altitude=plotting_alt).data\nplotting_var_v_s = ds_radar_s.V.sel(altitude=plotting_alt).data\nplotting_var_w_s = ds_radar_s.W.sel(altitude=plotting_alt).data\nplotting_var_vort_s = ds_radar_s.ABSVORT.sel(altitude=plotting_alt).data\nplotting_var_div_s = ds_radar_s.DIV.sel(altitude=plotting_alt).data\nplotting_lon_s = ds_radar_s.longitude\nplotting_lat_s = ds_radar_s.latitude\n\nfig = plt.figure(figsize=(12, 12))\nax = plt.axes(projection=ccrs.PlateCarree())\n\next = 0.02\nax.set_extent(\n    [\n        np.min(lon_s) + ext,\n        np.max(lon_s) - ext,\n        np.min(lat_s) + ext,\n        np.max(lat_s) - ext,\n    ],\n    crs=ccrs.PlateCarree(),\n)\nlevs_w = np.arange(-15, 15, 0.1)\ncf1 = ax.contourf(\n    plotting_lon_s,\n    plotting_lat_s,\n    plotting_var_w_s,\n    cmap=\"RdBu_r\",\n    levels=levs_w,\n    alpha=0.8,\n    shading=\"auto\",\n    transform=ccrs.PlateCarree(),\n)\n\ncf = ax.contour(\n    plotting_lon_s[::2],\n    plotting_lat_s[::2],\n    vort_goodcondition[::2, ::2],\n    transform=ccrs.PlateCarree(),\n    colors=\"lightgreen\",\n    linewidths=3,\n)\nax.contour(\n    plotting_lon_s,\n    plotting_lat_s,\n    dbz_goodcondition,\n    levels=np.arange(35, 100, 100),\n    colors=\"k\",\n    linewidths=3,\n    transform=ccrs.PlateCarree(),\n)\n\nstep = 1\ncf_q = ax.quiver(\n    plotting_lon_s[::step],\n    plotting_lat_s[::step],\n    u_goodcondition[::step, ::step],\n    v_goodcondition[::step, ::step],\n    scale=1000,\n    width=0.004,\n    color=\"k\",\n    transform=ccrs.PlateCarree(),\n)\n\ngl = ax.gridlines(\n    crs=ccrs.PlateCarree(),\n    draw_labels=True,\n    linewidth=2,\n    color=\"gray\",\n    alpha=0.5,\n    linestyle=\"--\",\n)\ngl.top_labels = False\ngl.right_labels = False\ngl.xformatter = LONGITUDE_FORMATTER\ngl.yformatter = LATITUDE_FORMATTER\n\nax.axhline(plotting_lat_s[31], xmin=0, xmax=1, lw=5, color='cyan', zorder=100)\n\ncbar_ax = fig.add_axes([0.95, 0.3, 0.02, 0.4])\ncbar = fig.colorbar(cf1, cax=cbar_ax, fraction=0.04)\ncbar.ax.tick_params(labelsize=14)\ncbar.ax.set_title(\"Vertical velocity [m/s]\", fontsize=14, y=-0.1)\n\nPlot cross sections of Divergence and Absolute Vorticity Fields along 41.89 latitude\n\nprint(ds_radar_s.latitude[31])\n\nloc = 31\nplotting_var_vort_s_cs = da_s_ABSVORT.sel(latitude=ds_radar_s.latitude[loc])\nplotting_var_CN_s_cs = da_CN[:, loc, :]\nplotting_var_u_s_cs = da_s_U.sel(latitude=ds_radar_s.latitude[loc]).data\nplotting_var_v_s_cs = da_s_V.sel(latitude=ds_radar_s.latitude[loc]).data\nplotting_var_w_s_cs = ds_radar_s[\"W\"].sel(latitude=ds_radar_s.latitude[loc]).data\nplotting_var_div_s_cs = da_s_DIV.sel(latitude=ds_radar_s.latitude[loc]).data\nplotting_alt_s = ds_radar_s.altitude\nu_cs_goodcondition = np.where(\n    plotting_var_CN_s_cs < CN_threshold, plotting_var_u_s_cs, np.nan\n)\nv_cs_goodcondition = np.where(\n    plotting_var_CN_s_cs < CN_threshold, plotting_var_v_s_cs, np.nan\n)\nw_cs_goodcondition = np.where(\n    plotting_var_CN_s_cs < CN_threshold, plotting_var_w_s_cs, np.nan\n)\ndiv_cs_goodcondition = np.where(\n    plotting_var_CN_s_cs < CN_threshold, plotting_var_div_s_cs, np.nan\n)\nvort_cs_goodcondition = np.where(\n    plotting_var_CN_s_cs < CN_threshold, plotting_var_vort_s_cs, np.nan\n)\n\nfig = plt.figure(figsize=(10, 10))\nax = plt.axes()\n\ncf1 = ax.pcolormesh(\n    plotting_lon_s,\n    plotting_alt_s,\n    div_cs_goodcondition / 1e5,\n    cmap=\"Spectral_r\",\n    vmin=-0.005,\n    vmax=0.005,\n    alpha=0.8,\n    shading=\"auto\",\n)\nstep = 2\nstep_k = 1\ncf_q = ax.quiver(\n    plotting_lon_s[::step],\n    plotting_alt_s[::step],\n    u_cs_goodcondition[::step, ::step],\n    w_cs_goodcondition[::step, ::step],\n    scale=600,\n    width=0.004,\n    color=\"k\",\n)\nax.set_title(\"Divergence\")\n\npaired_array = list(zip(terr_lon, terr_height))\nsorted_x = sorted(paired_array, key=lambda x: x[0])\nsorted_height = [x[1] for x in sorted_x]\npaired_array = list(zip(terr_lon, terr_y))\nsorted_x = sorted(paired_array, key=lambda x: x[0])\nsorted_y = [x[1] for x in sorted_x]\nfor i in range(len(sorted_y)):\n    if sorted_y[i] == ds_radar_s.y[loc]:\n        plt.plot(sorted_x[i][0], sorted_height[i]/1000, \".-\", color=\"k\")\n\n\ncbar_ax = fig.add_axes([0.95, 0.3, 0.02, 0.4])\ncbar = fig.colorbar(cf1, cax=cbar_ax, fraction=0.04)\ncbar.ax.tick_params(labelsize=14)\ncbar.ax.set_title(\"[1/s]\", fontsize=14, y=-0.1)\n\nax.set_xlabel(\"Longitude\")\nax.set_ylabel(\"Altitude\")\n\nfig = plt.figure(figsize=(10, 10))\nax = plt.axes()\n\ncf1 = ax.pcolormesh(\n    plotting_lon_s,\n    plotting_alt_s,\n    vort_cs_goodcondition / 1e5,\n    cmap=\"Spectral_r\",\n    vmin=-0.005,\n    vmax=0.005,\n    alpha=0.8,\n    shading=\"auto\",\n)\nstep = 2\ncf_q = ax.quiver(\n    plotting_lon_s[::step],\n    plotting_alt_s[::step],\n    u_cs_goodcondition[::step, ::step],\n    w_cs_goodcondition[::step, ::step],\n    scale=600,\n    width=0.004,\n    color=\"k\",\n)\nax.set_title(\"Absolute Vorticity\")\n\nfor i in range(len(sorted_y)):\n    if sorted_y[i] == ds_radar_s.y[loc]:\n        plt.plot(sorted_x[i][0], sorted_height[i]/1000, \".-\", color=\"k\")\n        \ncbar_ax = fig.add_axes([0.95, 0.3, 0.02, 0.4])\ncbar = fig.colorbar(cf1, cax=cbar_ax, fraction=0.04)\ncbar.ax.tick_params(labelsize=14)\ncbar.ax.set_title(\"[1/s]\", fontsize=14, y=-0.1)\n\n# ax.set_xlim([-87.3, -86.4])\n# ax.set_ylim([0, 14.5])\nax.set_xlabel(\"Longitude\")\nax.set_ylabel(\"Altitude\")\n\n","type":"content","url":"/lrose-erad-fractl-samurai#id-9-apply-fractl-condition-number","position":53},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"Congratulations! You have successfully completed the LROSE Wind tutorial. There are other options to set in both FRACTL and SAMURAI, but the steps and parameters in this tutorial can produce a good quality wind field in many cases. Be critical with your own analysis and feel free to reach out to the LROSE team for questions as you analyze your own data.","lvl3":"Tutorial Overview"},"type":"lvl4","url":"/lrose-erad-fractl-samurai#congratulations-you-have-successfully-completed-the-lrose-wind-tutorial-there-are-other-options-to-set-in-both-fractl-and-samurai-but-the-steps-and-parameters-in-this-tutorial-can-produce-a-good-quality-wind-field-in-many-cases-be-critical-with-your-own-analysis-and-feel-free-to-reach-out-to-the-lrose-team-for-questions-as-you-analyze-your-own-data","position":54},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl4":"Congratulations! You have successfully completed the LROSE Wind tutorial. There are other options to set in both FRACTL and SAMURAI, but the steps and parameters in this tutorial can produce a good quality wind field in many cases. Be critical with your own analysis and feel free to reach out to the LROSE team for questions as you analyze your own data.","lvl3":"Tutorial Overview"},"content":"\n\n\n\n","type":"content","url":"/lrose-erad-fractl-samurai#congratulations-you-have-successfully-completed-the-lrose-wind-tutorial-there-are-other-options-to-set-in-both-fractl-and-samurai-but-the-steps-and-parameters-in-this-tutorial-can-produce-a-good-quality-wind-field-in-many-cases-be-critical-with-your-own-analysis-and-feel-free-to-reach-out-to-the-lrose-team-for-questions-as-you-analyze-your-own-data","position":55},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl2":"Appendix - additional SAMURAI parameters"},"type":"lvl2","url":"/lrose-erad-fractl-samurai#appendix-additional-samurai-parameters","position":56},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl2":"Appendix - additional SAMURAI parameters"},"content":"","type":"content","url":"/lrose-erad-fractl-samurai#appendix-additional-samurai-parameters","position":57},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl3":"The following are optional parameters:","lvl2":"Appendix - additional SAMURAI parameters"},"type":"lvl3","url":"/lrose-erad-fractl-samurai#the-following-are-optional-parameters","position":58},{"hierarchy":{"lvl1":"LROSE Wind Tutorial","lvl3":"The following are optional parameters:","lvl2":"Appendix - additional SAMURAI parameters"},"content":"BACKGROUND SECTION\n\nload_background [line 107]\n\nTRUE: A first guess of the analysis stored in the samurai_Background.in will be loaded. This can come from a model, sounding, or other data source if available. Most of the time it is not available so it should be set to FALSE.\n\nFALSE (default setting)\n\nadjust_background [line 132]\n\nTRUE: the background will be adjusted to satisfy the mass continuity and match the supplied data using a variational adjustment. Without this, it is just interpolated simply to the grid.\n\nOPERATION SECTION\n\nmode [line 170]: The default mode is MODE_XYZ, which is Cartesian grid. You can run in cylindrical mode with MODE_RTZ. Stay tuned for more radar centric RTZ mode in the near future!\n\npreprocess_obs [line 219]\n\nTRUE: the raw data files will be preprocessed according to their file suffixes, and a samurai_Observations.in file will be generated.\n\nFALSE: SAMURAI will load the observations from the samurai_Observations.in file located in the data_directory. This is useful for generating fake data, or for saving some time if you already ran the preprocessing of lots of files.\n\nnum_iterations [line 232]: SAMURAI has the ability to take the output analysis and use it as a first guess for another analysis. This can be useful to create a ‘coarse’ analysis, followed by a ‘fine’ analysis. It is very important to set the observation and background errors appropriately if you choose this option.\n\nBACKGROUND SECTION\n\nref_state [line 380]: a sounding file to define the hydrostatic reference state used in the analysis. The default is the Dunion (2011) moist tropical sounding file. The analysis is generally not sensitive to this sounding, as it is just used to provide a reference density field and fall speed relationships in most cases. If you are analyzing thermodynamic information or have a very different freezing level it may be useful to provide a more appropriate sounding. The file format is similar to that of WRF or CM1 idealized soundings.\n\ni_background_roi [line 402], j_background_roi [line 412]: These set the background radius of influence when loading a background field.\n\nRADAR SECTION\n\nqr_variable [line 452]: In the default ‘dbz’ mode, the reflectivity is just interpolated and not included in the cost function minimization. If this is set to ‘qr’, then reflectivity is converted to liquid water using Z-M relationships defined in Gamache et al. (1993) and used as an additional variable in the cost function minimization. This is useful if you have other liquid water measurements to assimilate. Since this is a relatively simple Z-M it should be used with caution.\n\ndbz_pseudow_weight [line 516]: SAMURAI has the ability to set a ‘soft’ w=0 boundary condition at echo top, and setting this weight will determine how soft or hard that constraint is enforced. Usually a hard w=0 is enforced via the spline boundary conditions at the bottom and top of the domain, so this is optional. It can be useful if the vertical velocities are believed to be too strong at the top of the cloud.\n\nmelting_zone_width [line 532], mixed_phase_dbz [line 540], rain_dbz [line 548]: SAMURAI has some basic terminal fall speed corrections that use reflectivity and Z-VT relationships. These parameters control which relationships are used depending on dbz and the height of the zero C level (which is determined from the reference sounding).\n\nBOUNDARY CONDITIONS SECTION\n\nAvailable options are R0, R1T0, R1T1, R1T2, R2T10, R2T20, R3, and PERIODIC following Ooyama (2002). The default “non”- boundary condition (R0) adds a buffer set of gridpoints that are used to calculate the solution but are discarded for output. Different boundary conditions can be set on the left (L) or right (R) side of the domain for each variable and dimension. The most common option other than R0 would be R1T0 for vertical velocity (rhow = 0) at the surface and/or domain top. Periodic domains are only valid for the i and j dimension, but are available in both the XYZ and RTZ mode. Improved boundary conditions are currently in development.\n\nOBSERVATION ERRORS SECTION\n\nSpecified error is given in terms of a standard deviation, and is fixed for all observations from a particular instrument except radar. In the radar case, the spectrum width and elevation angle (proportional to terminal fall speed contribution) are used to define the error for each radar gate. A minimum error (radar_min_error) is also enforced.\n\nITERATION DEPENDENT SECTION\n\nmc_weight [line 1450]: specify the weight given to the mass continuity constraint. Default is set to 1, and is generally not recommended to change unless you have a good reason.\n\ni_filter_length [line 1546], j_filter_length [line 1558], k_filter_length [line 1570]\n\nGaussian recursive filter is a low-pass filter. Smaller filter lengths retain more detail, and larger filter lengths smooth more. The general recommendation is 4, 4, 2, which removes features less than approximately 4dx, 4dy, and 2dz from the analysis.\n\ni_spline_cutoff [line 1582], j_spline_cutoff [line 1594], k_spline_cutoff [line 1606]\n\nSpline cutoff is implemented as a third derivative constraint on the cubic B-spline basis during the spline transform. It is a sharper filter than the Gaussian, roughly equivalent to a sixth order filter.\n\ni_max_wavenumber [line 1618], j_max_wavenumber [line 1630], k_max_wavenumber [line 1642]\n\nThe Fourier spectral filter is the sharpest filter. It can be used for desired effects, such as explicitly removing high-wavenumber features in the spectral domain (usually for RTZ analysis), or for producing a ‘mean’ field by restricting to wavenumber zero.","type":"content","url":"/lrose-erad-fractl-samurai#the-following-are-optional-parameters","position":59},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/stress-testing","position":0},{"hierarchy":{"lvl1":""},"content":"# grab data\n\nimport os\nimport fsspec\n\n#### Need to modify later\nos.environ[\"LROSE_DIR\"] = \"/usr/local/lrose/bin\"\n\n# Set the URL and path to access the data on the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = f\"pythia/radar/erad2024\"\n\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=URL))\n\nfs.glob(f\"{path}/lrose/*/*.nc\")\n\nfiles = fs.glob(f\"{path}/lrose/*/*.nc\")  # paths .../lrose/CDV_0042, .../lrose/PBE_004\nlocal_files = [\n    fsspec.open_local(\n        f\"simplecache::{URL}{i}\", s3={\"anon\": True}, filecache={\"cache_storage\": \".\"}\n    )\n    for i in files\n]\n\n# make subdirectory for fractl input (samurai already exists with center and terrain files)\n#!mkdir -p ./fractl_input\n\n# create SAMURAI output directory\n!mkdir -p ./output_sam\n\n# create FRACTL output directory\n#!mkdir -p ./output_frac\n\n# create links to cfradial files for fractl and rsync for SAMURAI (having issues with links)\nfor i in range(len(local_files)):\n#    os.system('ln -sf '+local_files[i]+' ./fractl_input/'+files[i].split('/')[-1])\n    os.system('rsync -av '+local_files[i]+' ./samurai_input/'+files[i].split('/')[-1])\n\n\n\n# run fractl if desired\n#!${LROSE_DIR}/fractl -params ./lrose_params/fractl_params\n\n# run samurai\n!${LROSE_DIR}/samurai -params ./lrose_params/samurai_params","type":"content","url":"/stress-testing","position":1},{"hierarchy":{"lvl1":"Pyrad QPE Exercise"},"type":"lvl1","url":"/description-pyrad-tutorial","position":0},{"hierarchy":{"lvl1":"Pyrad QPE Exercise"},"content":"An overview of pyrad is provided \n\nhere.\n\nPyrad documentation can be found \n\nhere.\n\nCode is available at the \n\ngithub repository.\n\n","type":"content","url":"/description-pyrad-tutorial","position":1},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl2":"QPE Exercise"},"type":"lvl2","url":"/description-pyrad-tutorial#qpe-exercise","position":2},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl2":"QPE Exercise"},"content":"We are going to practice with the Pyrad config files to create a QPE processing data chain. The following data will be used:\n\nRain gauge data from ARPA Lombardia.\n\nX-band radar data provided by ARPA Lombardia.\n\nRadar data from the MeteoSwiss radar at Monte Lema.\n\nRain gauge data from MeteoSwiss\n\nWe have prepared for you a stub of the 3 config files to process the X-band radar data. Have a look at them here:\n\nmain config file\n\nloc config file\n\nprod config file\n\nIf you execute pyrad using this config file you will get a projection on a map of the reflectivity of the 2nd elevation. Let’s try that:\n\nOpen the terminal\n\nGo to erad2024/pyrad/config\n\nexecute: main_process_data.py qpe.txt --starttime 20240522160000 --endtime 20240522160000 --cfgpath ./\n\nThe created image is stored in the directory erad2024/pyrad/pyrad_outputs/QPE_ARPA2/2024-05-22/dBZ/EL1.3/","type":"content","url":"/description-pyrad-tutorial#qpe-exercise","position":3},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 1: Exploring the raw data","lvl2":"QPE Exercise"},"type":"lvl3","url":"/description-pyrad-tutorial#exercise-1-exploring-the-raw-data","position":4},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 1: Exploring the raw data","lvl2":"QPE Exercise"},"content":"Can you generate similar maps for ZDR, RhoHV, KDP and PhiDP?\n\nHave a look at other elevations as well.\n\nCould you generate a pseudo-RHI for an azimuth of interest? (hint: a pseudo-ppi map is generated using the PSEUDORHI_IMAGE product)","type":"content","url":"/description-pyrad-tutorial#exercise-1-exploring-the-raw-data","position":5},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 2: Clutter filtering","lvl2":"QPE Exercise"},"type":"lvl3","url":"/description-pyrad-tutorial#exercise-2-clutter-filtering","position":6},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 2: Clutter filtering","lvl2":"QPE Exercise"},"content":"Generate an echoID dataset using the sanity check SAN process and filter all the data using the ECHO_FILTER dataset generator.","type":"content","url":"/description-pyrad-tutorial#exercise-2-clutter-filtering","position":7},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 3: Attenuation correction","lvl2":"QPE Exercise"},"type":"lvl3","url":"/description-pyrad-tutorial#exercise-3-attenuation-correction","position":8},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 3: Attenuation correction","lvl2":"QPE Exercise"},"content":"Correct the reflectivity and the differential reflectivity using the ATTENUATION process.","type":"content","url":"/description-pyrad-tutorial#exercise-3-attenuation-correction","position":9},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 4: Hydrometeor classification","lvl2":"QPE Exercise"},"type":"lvl3","url":"/description-pyrad-tutorial#exercise-4-hydrometeor-classification","position":10},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 4: Hydrometeor classification","lvl2":"QPE Exercise"},"content":"Use the semi-supervised hydrometeor classification in the HYDROCLASS process to obtain an hydro dataset","type":"content","url":"/description-pyrad-tutorial#exercise-4-hydrometeor-classification","position":11},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 5: Rainfall rate estimation","lvl2":"QPE Exercise"},"type":"lvl3","url":"/description-pyrad-tutorial#exercise-5-rainfall-rate-estimation","position":12},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 5: Rainfall rate estimation","lvl2":"QPE Exercise"},"content":"Use the hydro method in the RAINRATE process to get the rainfall rate","type":"content","url":"/description-pyrad-tutorial#exercise-5-rainfall-rate-estimation","position":13},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 6: Comparing radar rainfall rate with rain gauge measurements","lvl2":"QPE Exercise"},"type":"lvl3","url":"/description-pyrad-tutorial#exercise-6-comparing-radar-rainfall-rate-with-rain-gauge-measurements","position":14},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 6: Comparing radar rainfall rate with rain gauge measurements","lvl2":"QPE Exercise"},"content":"Extract data at a point using the POINT_MEASUREMENT process and generate rain gauge-radar comparisons using TIME_SERIES products. The following rain gauges are available:\n\n45.8500,8.0000 COL (Coldrerio)\n\n45.843, 8.932 SBO (Stabio)\n\n45.843, 8.932 GEN (Monte Generoso)\n\n45.8333, 8.8167 IYVAV (Masnago)\n\n45.8167,9.0667 IYCOV (Como)\n\n45.6833,9.1833 IYMAR (Mariano Comense)\n\n45.6833,9.1833 IYVAP (Varallo)\n\n45.6833,9.1833 IYVEM (Vertemate)","type":"content","url":"/description-pyrad-tutorial#exercise-6-comparing-radar-rainfall-rate-with-rain-gauge-measurements","position":15},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 7: Projection into regular grid","lvl2":"QPE Exercise"},"type":"lvl3","url":"/description-pyrad-tutorial#exercise-7-projection-into-regular-grid","position":16},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Exercise 7: Projection into regular grid","lvl2":"QPE Exercise"},"content":"Project the rainfall rate estimation into a regular grid using the GRID process. Plot the rainfall rate at several elevations.","type":"content","url":"/description-pyrad-tutorial#exercise-7-projection-into-regular-grid","position":17},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Bonus questions:","lvl2":"QPE Exercise"},"type":"lvl3","url":"/description-pyrad-tutorial#bonus-questions","position":18},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl3":"Bonus questions:","lvl2":"QPE Exercise"},"content":"Use other rainfall rate estimators available on Pyrad\n\nUse alternative KDP processing methods\n\nCreate config files to process Monte Lema radar data\n\n","type":"content","url":"/description-pyrad-tutorial#bonus-questions","position":19},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl2":"Beyond QPE"},"type":"lvl2","url":"/description-pyrad-tutorial#beyond-qpe","position":20},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl2":"Beyond QPE"},"content":"Pyrad has much more features available than just QPE. Have a look at the two config file sets that covers other projects discussed in this course:\n\nDual-Doppler analysis using PyDDA\n\nQuasi-Vertical profiles\n\nThere are many more examples of config files available in the \n\nPyrad examples repository.","type":"content","url":"/description-pyrad-tutorial#beyond-qpe","position":21},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl2":"Thank You for your participation in the course!"},"type":"lvl2","url":"/description-pyrad-tutorial#thank-you-for-your-participation-in-the-course","position":22},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl2":"Thank You for your participation in the course!"},"content":"If you have further questions, or you encounter bugs, or the documentation is not clear do not hesitate to \n\nopen an issue.","type":"content","url":"/description-pyrad-tutorial#thank-you-for-your-participation-in-the-course","position":23},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl2":"Contributions are very welcomed!!!"},"type":"lvl2","url":"/description-pyrad-tutorial#contributions-are-very-welcomed","position":24},{"hierarchy":{"lvl1":"Pyrad QPE Exercise","lvl2":"Contributions are very welcomed!!!"},"content":"Open an issue so that we can discuss your contribution and make sure together that if fits into the software","type":"content","url":"/description-pyrad-tutorial#contributions-are-very-welcomed","position":25},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage"},"type":"lvl1","url":"/wradlib-clutter-beamblockage","position":0},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage"},"content":"\n\n","type":"content","url":"/wradlib-clutter-beamblockage","position":1},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage"},"type":"lvl1","url":"/wradlib-clutter-beamblockage#wradlib-clutter-and-beamblockage","position":2},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage"},"content":"\n\n\n\n","type":"content","url":"/wradlib-clutter-beamblockage#wradlib-clutter-and-beamblockage","position":3},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage","lvl2":"Overview"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#overview","position":4},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage","lvl2":"Overview"},"content":"Within this notebook, we will cover:\n\nReading data using xradar\n\nClutter detection\n\nBeam Blockage calculation\n\n","type":"content","url":"/wradlib-clutter-beamblockage#overview","position":5},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage","lvl2":"Prerequisites"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#prerequisites","position":6},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nXarray Basics\n\nHelpful\n\nBasic Dataset/DataArray\n\nMatplotlib Basics\n\nHelpful\n\nBasic Plotting\n\nIntro to Cartopy\n\nHelpful\n\nProjections\n\nTime to learn: 10 minutes\n\n\n\n","type":"content","url":"/wradlib-clutter-beamblockage#prerequisites","position":7},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage","lvl2":"Imports"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#imports","position":8},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage","lvl2":"Imports"},"content":"\n\nimport numpy as np\nimport wradlib as wrl\nimport matplotlib.pyplot as plt\nimport xarray as xr\nimport cartopy\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nimport xradar as xd\nimport hvplot\nimport hvplot.xarray\n\n","type":"content","url":"/wradlib-clutter-beamblockage#imports","position":9},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage","lvl2":"retrieve data from s3 bucket"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#retrieve-data-from-s3-bucket","position":10},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage","lvl2":"retrieve data from s3 bucket"},"content":"\n\nimport os\nimport urllib.request\nfrom pathlib import Path\n\n# Set the URL for the cloud\nURL = \"https://js2.jetstream-cloud.org:8001/\"\npath = \"pythia/radar/erad2024\"\n!mkdir -p data\nfiles = [\n    \"20240522_MeteoSwiss_ARPA_Lombardia/Data/Xband/DES_VOL_RAW_20240522_1600.nc\",\n    \"wradlib/desio_dem.tif\",\n]\nfor file in files:\n    file_remote = os.path.join(path, file)\n    file_local = os.path.join(\"data\", Path(file).name)\n    if not os.path.exists(file_local):\n        print(f\"downloading, {file_local}\")\n        urllib.request.urlretrieve(f\"{URL}{file_remote}\", file_local)\n\n","type":"content","url":"/wradlib-clutter-beamblockage#retrieve-data-from-s3-bucket","position":11},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage","lvl2":"Open CfRadial1 Volume"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#open-cfradial1-volume","position":12},{"hierarchy":{"lvl1":"wradlib - clutter and beamblockage","lvl2":"Open CfRadial1 Volume"},"content":"\n\nreindex = dict(angle_res=1, direction=1, start_angle=0, stop_angle=360)\ndtree = xd.io.open_cfradial1_datatree(\"data/DES_VOL_RAW_20240522_1600.nc\")\ndisplay(dtree.load())\n\n","type":"content","url":"/wradlib-clutter-beamblockage#open-cfradial1-volume","position":13},{"hierarchy":{"lvl1":"Get first sweep"},"type":"lvl1","url":"/wradlib-clutter-beamblockage#get-first-sweep","position":14},{"hierarchy":{"lvl1":"Get first sweep"},"content":"\n\nswp = (\n    dtree[\"sweep_0\"]\n    .to_dataset()\n    .wrl.georef.georeference(crs=wrl.georef.get_earth_projection())\n    .set_coords(\"sweep_mode\")\n)\nswp.x.attrs = xd.model.get_longitude_attrs()\nswp.y.attrs = xd.model.get_latitude_attrs()\n\ndisplay(swp)\n\n","type":"content","url":"/wradlib-clutter-beamblockage#get-first-sweep","position":15},{"hierarchy":{"lvl1":"Get first sweep","lvl2":"Get Digital Elevation Map (DEM)"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#get-digital-elevation-map-dem","position":16},{"hierarchy":{"lvl1":"Get first sweep","lvl2":"Get Digital Elevation Map (DEM)"},"content":"If we have access to the NASA EarthData GESDISC, we can use the BearerToken to retrieve SRTM data corresponding to the actual radar domain. Or we can choose the precompiled GeoTiff.\n\n# extent = [swp.x.min().values, swp.x.max().values, swp.y.min().values, swp.y.max().values]\n# import os\n# os.environ[\"WRADLIB_EARTHDATA_BEARER_TOKEN\"] = \"\"\n# dem = wrl.io.get_srtm(extent)\n# wrl.io.write_raster_dataset(\"desio_dem.tif\", dem)\n\ndem = (\n    xr.open_dataset(\"data/desio_dem.tif\", engine=\"rasterio\")\n    .isel(band=0)\n    .rename(band_data=\"DEM\")\n    .reset_coords(\"band\", drop=True)\n)\ndisplay(dem)\n\n","type":"content","url":"/wradlib-clutter-beamblockage#get-digital-elevation-map-dem","position":17},{"hierarchy":{"lvl1":"Extract radar parameters"},"type":"lvl1","url":"/wradlib-clutter-beamblockage#extract-radar-parameters","position":18},{"hierarchy":{"lvl1":"Extract radar parameters"},"content":"\n\nradar_parameters = dtree[\"radar_parameters\"]\n\nbw = radar_parameters[\"radar_beam_width_h\"]\nbw\n\n","type":"content","url":"/wradlib-clutter-beamblockage#extract-radar-parameters","position":19},{"hierarchy":{"lvl1":"Extract radar parameters","lvl2":"Prepare DEM for Polar Processing"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#prepare-dem-for-polar-processing","position":20},{"hierarchy":{"lvl1":"Extract radar parameters","lvl2":"Prepare DEM for Polar Processing"},"content":"Here the power of \n\nxr.apply_ufunc is shown, a wrapper to xarray-ify numpy functions.\n\ndef interpolate_dem(obj, dem, **kwargs):\n    dim0 = obj.wrl.util.dim0()\n\n    def wrapper(sx, sy, dx, dy, dem, *args, **kwargs):\n        y, x = np.meshgrid(dy, dx)\n        rastercoords = np.dstack([x, y])\n        polcoords = np.dstack([sx, sy])\n        return wrl.ipol.cart_to_irregular_spline(rastercoords, dem, polcoords, **kwargs)\n\n    out = xr.apply_ufunc(\n        wrapper,\n        obj.x,\n        obj.y,\n        dem.x,\n        dem.y,\n        dem,\n        input_core_dims=[[dim0, \"range\"], [dim0, \"range\"], [\"x\"], [\"y\"], [\"y\", \"x\"]],\n        output_core_dims=[[dim0, \"range\"]],\n        dask=\"parallelized\",\n        vectorize=True,\n        kwargs=kwargs,\n        dask_gufunc_kwargs=dict(allow_rechunk=True),\n    )\n    out.name = \"DEM\"\n    return obj.assign(DEM=out)\n\nswp = interpolate_dem(swp, dem.DEM, order=3, prefilter=False)\n\nswp.DEM.wrl.vis.plot(cmap=\"terrain\", vmin=0)\n\n","type":"content","url":"/wradlib-clutter-beamblockage#prepare-dem-for-polar-processing","position":21},{"hierarchy":{"lvl1":"Extract radar parameters","lvl2":"Plot scan strategy"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#plot-scan-strategy","position":22},{"hierarchy":{"lvl1":"Extract radar parameters","lvl2":"Plot scan strategy"},"content":"\n\nnrays = swp.azimuth.size\nnbins = swp.range.size\nrange_res = 300.0\nranges = np.arange(nbins) * range_res\nelevs = dtree.root.sweep_fixed_angle.values\nsitecoords = (\n    dtree.root.longitude.values.item(),\n    dtree.root.latitude.values.item(),\n    dtree.root.altitude.values.item(),\n)\n\nax = wrl.vis.plot_scan_strategy(\n    ranges,\n    elevs,\n    sitecoords,\n    beamwidth=radar_parameters[\"radar_beam_width_h\"].values,\n    terrain=None,\n)\n\nUse terrain=swp.DEM.sel(azimuth=0, method=\"nearest\") to get some arbitrary ray.\n\nax = wrl.vis.plot_scan_strategy(\n    ranges,\n    elevs,\n    sitecoords,\n    beamwidth=radar_parameters[\"radar_beam_width_h\"].values,\n    terrain=swp.DEM.sel(azimuth=0, method=\"nearest\"),\n)\n\n","type":"content","url":"/wradlib-clutter-beamblockage#plot-scan-strategy","position":23},{"hierarchy":{"lvl1":"Extract radar parameters","lvl2":"Calculate clutter map"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#calculate-clutter-map","position":24},{"hierarchy":{"lvl1":"Extract radar parameters","lvl2":"Calculate clutter map"},"content":"\n\nclmap = swp.DBZ_TOT.wrl.classify.filter_gabella(\n    wsize=5,\n    thrsnorain=0.0,\n    tr1=21.0,  # 21.,\n    n_p=23.0,  # 23,\n    tr2=1.3,\n    rm_nans=False,\n)\nswp = swp.assign({\"CMAP\": clmap})\n\n","type":"content","url":"/wradlib-clutter-beamblockage#calculate-clutter-map","position":25},{"hierarchy":{"lvl1":"Extract radar parameters","lvl2":"Plot Reflectivities, Clutter and Cluttermap"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#plot-reflectivities-clutter-and-cluttermap","position":26},{"hierarchy":{"lvl1":"Extract radar parameters","lvl2":"Plot Reflectivities, Clutter and Cluttermap"},"content":"\n\nfig = plt.figure(figsize=(15, 12))\nax1 = fig.add_subplot(221)\nfrom osgeo import osr\n\nwgs84 = osr.SpatialReference()\nwgs84.ImportFromEPSG(4326)\n# swp = swp.sel(range=slice(0, 100000)).set_coords(\"sweep_mode\").wrl.georef.georeference(crs=wgs84)\nswp.DBZ_TOT.plot(x=\"x\", y=\"y\", ax=ax1, vmin=0, vmax=60)\nax1.set_title(\"Reflectivity raw\")\nax2 = fig.add_subplot(222)\nswp.CMAP.plot(x=\"x\", y=\"y\", ax=ax2)\nax2.set_title(\"Cluttermap\")\nax3 = fig.add_subplot(223)\nswp.DBZ_TOT.where(swp.CMAP == 1).plot(x=\"x\", y=\"y\", ax=ax3, vmin=0, vmax=60)\nax3.set_title(\"Clutter\")\nax4 = fig.add_subplot(224)\nswp.DBZ_TOT.where(swp.CMAP < 1).plot(x=\"x\", y=\"y\", ax=ax4, vmin=0, vmax=60)\nax4.set_title(\"Reflectivity clutter removed\")\n\n","type":"content","url":"/wradlib-clutter-beamblockage#plot-reflectivities-clutter-and-cluttermap","position":27},{"hierarchy":{"lvl1":"Compare with corrected reflectivity from signal processor"},"type":"lvl1","url":"/wradlib-clutter-beamblockage#compare-with-corrected-reflectivity-from-signal-processor","position":28},{"hierarchy":{"lvl1":"Compare with corrected reflectivity from signal processor"},"content":"plus additional simple RHOHV filter\n\nfig = plt.figure(figsize=(15, 6))\nax1 = fig.add_subplot(121)\nswp.DBZ.plot(x=\"x\", y=\"y\", ax=ax1, vmin=0, vmax=60)\nax1.set_title(\"Reflectivity corr\")\nax2 = fig.add_subplot(122)\nswp.DBZ_TOT.where((swp.CMAP < 1) & (swp.RHOHV >= 0.8)).plot(\n    x=\"x\", y=\"y\", ax=ax2, vmin=0, vmax=60\n)\nax2.set_title(\"Reflectivity clutter removed\")\n\nfig = plt.figure(figsize=(8, 5))\nax1 = fig.add_subplot(111)\nswp.CMAP.where(swp.CMAP == 1).plot(x=\"x\", y=\"y\", vmin=0, vmax=1, cmap=\"turbo\")\nax1.set_title(\"Reflectivity corr\")\ndem.DEM.plot(ax=ax1, zorder=-2, cmap=\"terrain\", vmin=0)\n\n","type":"content","url":"/wradlib-clutter-beamblockage#compare-with-corrected-reflectivity-from-signal-processor","position":29},{"hierarchy":{"lvl1":"Use hvplot for zooming and panning"},"type":"lvl1","url":"/wradlib-clutter-beamblockage#use-hvplot-for-zooming-and-panning","position":30},{"hierarchy":{"lvl1":"Use hvplot for zooming and panning"},"content":"\n\nWe need to rechunk the coordinates as hvplot needs chunked variables and coords.\n\ncl = (\n    swp.CMAP.where(swp.CMAP == 1)\n    .chunk(chunks={})\n    .hvplot.quadmesh(\n        x=\"x\", y=\"y\", cmap=\"turbo\", width=600, height=500, clim=(0, 1), rasterize=True\n    )\n)\ndm = dem.DEM.chunk(chunks={}).hvplot(\n    x=\"x\", y=\"y\", cmap=\"terrain\", width=600, height=500, rasterize=True\n)\ndm * cl\n\n","type":"content","url":"/wradlib-clutter-beamblockage#use-hvplot-for-zooming-and-panning","position":31},{"hierarchy":{"lvl1":"Use hvplot for zooming and panning","lvl2":"BeamBlockage Calculation"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#beamblockage-calculation","position":32},{"hierarchy":{"lvl1":"Use hvplot for zooming and panning","lvl2":"BeamBlockage Calculation"},"content":"Can you xarray-ify the following, too?\n\nbeamradius = wrl.util.half_power_radius(swp.range, bw)\nPBB = wrl.qual.beam_block_frac(swp.DEM.values, swp.z.values, beamradius)\nPBB = np.ma.masked_invalid(PBB)\nCBB = wrl.qual.cum_beam_block_frac(PBB)\n\nswp = swp.assign(\n    CBB=([\"azimuth\", \"range\"], CBB),\n    PBB=([\"azimuth\", \"range\"], PBB),\n)\n\n# just a little helper function to style x and y axes of our maps\ndef annotate_map(ax, cm=None, title=\"\"):\n    # ticks = (ax.get_xticks() / 1000).astype(int)\n    # ax.set_xticklabels(ticks)\n    # ticks = (ax.get_yticks() / 1000).astype(int)\n    # ax.set_yticklabels(ticks)\n    # ax.set_xlabel(\"Kilometers\")\n    # ax.set_ylabel(\"Kilometers\")\n    if not cm is None:\n        plt.colorbar(cm, ax=ax)\n    if not title == \"\":\n        ax.set_title(title)\n    ax.grid()\n\nimport matplotlib as mpl\n\nsitecoords = (swp.longitude.values, swp.latitude.values, swp.altitude.values)\nr = swp.range.values\naz = swp.azimuth.values\n\nalt = swp.z.values\nfig = plt.figure(figsize=(15, 12))\n\n# create subplots\nax1 = plt.subplot2grid((2, 2), (0, 0))\nax2 = plt.subplot2grid((2, 2), (0, 1))\nax3 = plt.subplot2grid((2, 2), (1, 0), colspan=2, rowspan=1)\n\n# azimuth angle\nangle = 0\n\n# Plot terrain (on ax1)\ndem_pm = swp.DEM.wrl.vis.plot(ax=ax1, cmap=mpl.cm.terrain, vmin=0.0, add_colorbar=False)\nswp.sel(azimuth=0, method=\"nearest\").plot.scatter(\n    x=\"x\", y=\"y\", marker=\".\", color=\"r\", alpha=0.2, ax=ax1\n)\nax1.plot(swp.longitude.values, swp.latitude.values, \"ro\")\nannotate_map(\n    ax1,\n    dem_pm,\n    \"Terrain within {0} km range\".format(np.max(swp.range.values / 1000.0) + 0.1),\n)\n\n# Plot CBB (on ax2)\ncbb = swp.CBB.wrl.vis.plot(ax=ax2, cmap=mpl.cm.PuRd, vmin=0, vmax=1, add_colorbar=False)\nannotate_map(ax2, cbb, \"Beam-Blockage Fraction\")\n\n# Plot single ray terrain profile on ax3\n(bc,) = ax3.plot(\n    swp.range / 1000.0, swp.z[angle, :], \"-b\", linewidth=3, label=\"Beam Center\"\n)\n(b3db,) = ax3.plot(\n    swp.range.values / 1000.0,\n    (swp.z[angle, :] + beamradius),\n    \":b\",\n    linewidth=1.5,\n    label=\"3 dB Beam width\",\n)\nax3.plot(swp.range / 1000.0, (swp.z[angle, :] - beamradius), \":b\")\nax3.fill_between(swp.range / 1000.0, 0.0, swp.DEM[angle, :], color=\"0.75\")\nax3.set_xlim(0.0, np.max(swp.range / 1000.0) + 0.1)\nax3.set_ylim(0.0, 3000)\nax3.set_xlabel(\"Range (km)\")\nax3.set_ylabel(\"Altitude (m)\")\nax3.grid()\n\naxb = ax3.twinx()\n(bbf,) = axb.plot(swp.range / 1000.0, swp.CBB[angle, :], \"-k\", label=\"BBF\")\naxb.set_ylabel(\"Beam-blockage fraction\")\naxb.set_ylim(0.0, 1.0)\naxb.set_xlim(0.0, np.max(swp.range / 1000.0) + 0.1)\n\n\nlegend = ax3.legend(\n    (bc, b3db, bbf),\n    (\"Beam Center\", \"3 dB Beam width\", \"BBF\"),\n    loc=\"upper left\",\n    fontsize=10,\n)\n\n","type":"content","url":"/wradlib-clutter-beamblockage#beamblockage-calculation","position":33},{"hierarchy":{"lvl1":"Use hvplot for zooming and panning","lvl2":"Some EyeCandy"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#some-eyecandy","position":34},{"hierarchy":{"lvl1":"Use hvplot for zooming and panning","lvl2":"Some EyeCandy"},"content":"\n\ndef height_formatter(x, pos):\n    x = (x - 6370000) / 1000\n    fmt_str = \"{:g}\".format(x)\n    return fmt_str\n\n\ndef range_formatter(x, pos):\n    x = x / 1000.0\n    fmt_str = \"{:g}\".format(x)\n    return fmt_str\n\nfig = plt.figure(figsize=(10, 6))\n\ncgax, caax, paax = wrl.vis.create_cg(fig=fig, rot=0, scale=1)\n\n# azimuth angle\nangle = 0\n\n# fix grid_helper\ner = 6370000\ngh = cgax.get_grid_helper()\ngh.grid_finder.grid_locator2._nbins = 80\ngh.grid_finder.grid_locator2._steps = [1, 2, 4, 5, 10]\n\n# calculate beam_height and arc_distance for ke=1\n# means line of sight\nbhe = wrl.georef.bin_altitude(r, 0, sitecoords[2], re=er, ke=1.0)\nade = wrl.georef.bin_distance(r, 0, sitecoords[2], re=er, ke=1.0)\nnn0 = np.zeros_like(r)\n# for nice plotting we assume earth_radius = 6370000 m\necp = nn0 + er\n# theta (arc_distance sector angle)\nthetap = -np.degrees(ade / er) + 90.0\n\n# zero degree elevation with standard refraction\nbh0 = wrl.georef.bin_altitude(r, 0, sitecoords[2], re=er)\n\n# plot (ecp is earth surface normal null)\n(bes,) = paax.plot(thetap, ecp, \"-k\", linewidth=3, label=\"Earth Surface NN\")\n(bc,) = paax.plot(thetap, ecp + alt[angle, :], \"-b\", linewidth=3, label=\"Beam Center\")\n(bc0r,) = paax.plot(thetap, ecp + bh0, \"-g\", label=\"0 deg Refraction\")\n(bc0n,) = paax.plot(thetap, ecp + bhe, \"-r\", label=\"0 deg line of sight\")\n(b3db,) = paax.plot(\n    thetap, ecp + alt[angle, :] + beamradius, \":b\", label=\"+3 dB Beam width\"\n)\npaax.plot(thetap, ecp + alt[angle, :] - beamradius, \":b\", label=\"-3 dB Beam width\")\n\n# orography\npaax.fill_between(thetap, ecp, ecp + swp.DEM[angle, :], color=\"0.75\")\n\n# shape axes\ncgax.set_xlim(0, np.max(ade))\ncgax.set_ylim([ecp.min() - 1000, ecp.max() + 2500])\ncaax.grid(True, axis=\"x\")\ncgax.grid(True, axis=\"y\")\ncgax.axis[\"top\"].toggle(all=False)\ncaax.yaxis.set_major_locator(\n    mpl.ticker.MaxNLocator(steps=[1, 2, 4, 5, 10], nbins=20, prune=\"both\")\n)\ncaax.xaxis.set_major_locator(mpl.ticker.MaxNLocator())\ncaax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(height_formatter))\ncaax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(range_formatter))\n\ncaax.set_xlabel(\"Range (km)\")\ncaax.set_ylabel(\"Altitude (km)\")\n\nlegend = paax.legend(\n    (bes, bc0n, bc0r, bc, b3db),\n    (\n        \"Earth Surface NN\",\n        \"0 deg line of sight\",\n        \"0 deg std refraction\",\n        \"Beam Center\",\n        \"3 dB Beam width\",\n    ),\n    loc=\"lower left\",\n    fontsize=10,\n)\n\n\n\n","type":"content","url":"/wradlib-clutter-beamblockage#some-eyecandy","position":35},{"hierarchy":{"lvl1":"Use hvplot for zooming and panning","lvl2":"Summary"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#summary","position":36},{"hierarchy":{"lvl1":"Use hvplot for zooming and panning","lvl2":"Summary"},"content":"We’ve just learned how to use \\omega radlib’s Gabella clutter detection for single sweeps. We’ve looked into digital elevation maps and beam blockage calculations.\n\n","type":"content","url":"/wradlib-clutter-beamblockage#summary","position":37},{"hierarchy":{"lvl1":"Use hvplot for zooming and panning","lvl2":"Resources and references"},"type":"lvl2","url":"/wradlib-clutter-beamblockage#resources-and-references","position":38},{"hierarchy":{"lvl1":"Use hvplot for zooming and panning","lvl2":"Resources and references"},"content":"xarray\n\ndask\n\nGDAL\n\nxradar backends\n\nCfRadial1","type":"content","url":"/wradlib-clutter-beamblockage#resources-and-references","position":39},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar"},"type":"lvl1","url":"/pyart-basics","position":0},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar"},"content":"\n\n","type":"content","url":"/pyart-basics","position":1},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar"},"type":"lvl1","url":"/pyart-basics#py-art-basics-with-xradar","position":2},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar"},"content":"\n\n","type":"content","url":"/pyart-basics#py-art-basics-with-xradar","position":3},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Overview"},"type":"lvl2","url":"/pyart-basics#overview","position":4},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Overview"},"content":"Within this notebook, we will cover:\n\nGeneral overview of Py-ART and its functionality\n\nReading data using Py-ART\n\nAn overview of the pyart.Radar object\n\nCreate a Plot of our Radar Data\n\n","type":"content","url":"/pyart-basics#overview","position":5},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Prerequisites"},"type":"lvl2","url":"/pyart-basics#prerequisites","position":6},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nHelpful\n\nBasic features\n\nMatplotlib Basics\n\nHelpful\n\nBasic plotting\n\nNumPy Basics\n\nHelpful\n\nBasic arrays\n\nTime to learn: 45 minutes\n\n","type":"content","url":"/pyart-basics#prerequisites","position":7},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Imports"},"type":"lvl2","url":"/pyart-basics#imports","position":8},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Imports"},"content":"\n\nimport os\nimport warnings\n\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\n\n\nimport pyart\nfrom pyart.testing import get_test_data\nimport xradar as xd\n\nwarnings.filterwarnings(\"ignore\")\n\n","type":"content","url":"/pyart-basics#imports","position":9},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"An Overview of Py-ART"},"type":"lvl2","url":"/pyart-basics#an-overview-of-py-art","position":10},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"An Overview of Py-ART"},"content":"\n\n","type":"content","url":"/pyart-basics#an-overview-of-py-art","position":11},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"History of the Py-ART","lvl2":"An Overview of Py-ART"},"type":"lvl3","url":"/pyart-basics#history-of-the-py-art","position":12},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"History of the Py-ART","lvl2":"An Overview of Py-ART"},"content":"Development began to address the needs of ARM with the acquisition of a number of\nnew scanning cloud and precipitation radar as part of the American Recovery Act.\n\nThe project has since expanded to work with a variety of weather radars and a wider user\nbase including radar researchers and climate modelers.\n\nThe software has been released on GitHub as open source software under a BSD license.\nRuns on Linux, OS X. It also runs on Windows with more limited functionality.","type":"content","url":"/pyart-basics#history-of-the-py-art","position":13},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"What can PyART Do?","lvl2":"An Overview of Py-ART"},"type":"lvl3","url":"/pyart-basics#what-can-pyart-do","position":14},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"What can PyART Do?","lvl2":"An Overview of Py-ART"},"content":"Py-ART can be used for a variety of tasks from basic plotting to more complex\nprocessing pipelines. Specific uses for Py-ART include:\n\nReading radar data in a variety of file formats.\n\nCreating plots and visualization of radar data.\n\nCorrecting radar moments while in antenna coordinates, such as:\n\nDoppler unfolding/de-aliasing.\n\nAttenuation correction.\n\nPhase processing using a Linear Programming method.\n\nMapping data from one or multiple radars onto a Cartesian grid.\n\nPerforming retrievals.\n\nWriting radial and Cartesian data to NetCDF files.\n\n","type":"content","url":"/pyart-basics#what-can-pyart-do","position":15},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Reading in Data Using Py-ART"},"type":"lvl2","url":"/pyart-basics#reading-in-data-using-py-art","position":16},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Reading in Data Using Py-ART"},"content":"\n\n","type":"content","url":"/pyart-basics#reading-in-data-using-py-art","position":17},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"Reading data in using xradar.io.open_","lvl2":"Reading in Data Using Py-ART"},"type":"lvl3","url":"/pyart-basics#reading-data-in-using-xradar-io-open","position":18},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"Reading data in using xradar.io.open_","lvl2":"Reading in Data Using Py-ART"},"content":"\n\nWhen reading in a radar file, we use the pyart.io.read module.\n\npyart.io.read can read a variety of different radar formats, such as Cf/Radial, ODIM_H5, etc.\nThe documentation on what formats can be read by xradar can be found here:\n\nxradar readers Documentation\n\nLet’s take a look at one of these readers:\n\n?xd.io.open_cfradial1_datatree\n\nLet’s use a sample data file from pyart - which is \n\ncfradial format.\n\nWhen we read this in, we get a \n\npyart.Radar object!\n\nfile = get_test_data(\"swx_20120520_0641.nc\")\ndt = xd.io.open_cfradial1_datatree(file)\ndt\n\n","type":"content","url":"/pyart-basics#reading-data-in-using-xradar-io-open","position":19},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"Investigate the xradar object","lvl2":"Reading in Data Using Py-ART"},"type":"lvl3","url":"/pyart-basics#investigate-the-xradar-object","position":20},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"Investigate the xradar object","lvl2":"Reading in Data Using Py-ART"},"content":"\n\nWithin this \n\nxradar object object are the actual data fields, each stored in a different group, mimicking the FM301/cfradial2 data standard.\n\nThis is where data such as reflectivity and velocity are stored.\n\nTo see what fields are present we can add the fields and keys additions to the variable where the radar object is stored.\n\ndt[\"sweep_0\"]\n\n","type":"content","url":"/pyart-basics#investigate-the-xradar-object","position":21},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl4":"Extract a sample data field","lvl3":"Investigate the xradar object","lvl2":"Reading in Data Using Py-ART"},"type":"lvl4","url":"/pyart-basics#extract-a-sample-data-field","position":22},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl4":"Extract a sample data field","lvl3":"Investigate the xradar object","lvl2":"Reading in Data Using Py-ART"},"content":"\n\nThe fields are stored in a dictionary, each containing coordinates, units and more.\nAll can be accessed by just adding the fields addition to the radar object variable.\n\nFor an individual field, we add a string in brackets after the fields addition to see\nthe contents of that field.\n\nLet’s take a look at 'corrected_reflectivity_horizontal', which is a common field to investigate.\n\nprint(dt[\"sweep_0\"][\"corrected_reflectivity_horizontal\"])\n\nWe can go even further in the dictionary and access the actual reflectivity data.\n\nWe use add .data at the end, which will extract the data array (which is a numpy array) from the dictionary.\n\nreflectivity = dt[\"sweep_0\"][\"corrected_reflectivity_horizontal\"].data\nprint(type(reflectivity), reflectivity)\n\nLets’ check the size of this array...\n\nreflectivity.shape\n\nThis reflectivity data array, numpy array, is a two-dimensional array with dimensions:\n\nRange (distance away from the radar)\n\nAzimuth (direction around the radar)\n\ndt[\"sweep_0\"].dims\n\nIf we wanted to look the 300th ray, at the second gate, we would use something like the following:\n\nprint(reflectivity[300, 2])\n\nWe can also select a specific azimuth if desired, using the xarray syntax:\n\ndt[\"sweep_0\"].sel(azimuth=180, method=\"nearest\")\n\n","type":"content","url":"/pyart-basics#extract-a-sample-data-field","position":23},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Plotting our Radar Data"},"type":"lvl2","url":"/pyart-basics#plotting-our-radar-data","position":24},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Plotting our Radar Data"},"content":"\n\n","type":"content","url":"/pyart-basics#plotting-our-radar-data","position":25},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"An Overview of Py-ART Plotting Utilities","lvl2":"Plotting our Radar Data"},"type":"lvl3","url":"/pyart-basics#an-overview-of-py-art-plotting-utilities","position":26},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"An Overview of Py-ART Plotting Utilities","lvl2":"Plotting our Radar Data"},"content":"Now that we have loaded the data and inspected it, the next logical thing to do is to visualize the data! Py-ART’s visualization functionality is done through the objects in the \n\npyart.graph module.\n\nIn Py-ART there are 4 primary visualization classes in pyart.graph:\n\nRadarDisplay\n\nRadarMapDisplay\n\nAirborneRadarDisplay\n\nPlotting grid data\n\nGridMapDisplay","type":"content","url":"/pyart-basics#an-overview-of-py-art-plotting-utilities","position":27},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"Use the RadarMapDisplay with our data","lvl2":"Plotting our Radar Data"},"type":"lvl3","url":"/pyart-basics#use-the-radarmapdisplay-with-our-data","position":28},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"Use the RadarMapDisplay with our data","lvl2":"Plotting our Radar Data"},"content":"For the this example, we will be using RadarMapDisplay, using Cartopy to deal with geographic coordinates.\n\nWe start by creating a figure first, and adding our traditional radar methods to the xradar object.\n\nfig = plt.figure(figsize=[10, 10])\nradar = pyart.xradar.Xradar(dt)\n\nOnce we have a figure, let’s add our RadarMapDisplay\n\nfig = plt.figure(figsize=[10, 10])\ndisplay = pyart.graph.RadarMapDisplay(radar)\n\nAdding our map display without specifying a field to plot won’t do anything we need to specifically add a field to field using .plot_ppi_map()\n\ndisplay.plot_ppi_map(\"corrected_reflectivity_horizontal\")\n\nBy default, it will plot the elevation scan, the the default colormap from Matplotlib... let’s customize!\n\nWe add the following arguements:\n\nsweep=3 - The fourth elevation scan (since we are using Python indexing)\n\nvmin=-20 - Minimum value for our plotted field/colorbar\n\nvmax=60 - Maximum value for our plotted field/colorbar\n\nprojection=ccrs.PlateCarree() - Cartopy latitude/longitude coordinate system\n\ncmap='pyart_HomeyerRainbow' - Colormap to use, selecting one provided by PyART\n\nfig = plt.figure(figsize=[12, 12])\ndisplay = pyart.graph.RadarMapDisplay(radar)\ndisplay.plot_ppi_map(\n    \"corrected_reflectivity_horizontal\",\n    sweep=3,\n    vmin=-20,\n    vmax=60,\n    projection=ccrs.PlateCarree(),\n    cmap=\"pyart_HomeyerRainbow\",\n)\nplt.show()\n\nYou can change many parameters in the graph by changing the arguments to plot_ppi_map. As you can recall from earlier. simply view these arguments in a Jupyter notebook by typing:\n\n?display.plot_ppi_map\n\nFor example, let’s change the colormap to something different\n\nfig = plt.figure(figsize=[12, 12])\ndisplay = pyart.graph.RadarMapDisplay(radar)\ndisplay.plot_ppi_map(\n    \"corrected_reflectivity_horizontal\",\n    sweep=3,\n    vmin=-20,\n    vmax=60,\n    projection=ccrs.PlateCarree(),\n    cmap=\"pyart_Carbone42\",\n)\nplt.show()\n\nOr, let’s view a different elevation scan! To do this, change the sweep parameter in the plot_ppi_map function.\n\nfig = plt.figure(figsize=[12, 12])\ndisplay = pyart.graph.RadarMapDisplay(radar)\ndisplay.plot_ppi_map(\n    \"corrected_reflectivity_horizontal\",\n    sweep=0,\n    vmin=-20,\n    vmax=60,\n    projection=ccrs.PlateCarree(),\n    cmap=\"pyart_Carbone42\",\n)\nplt.show()\n\nLet’s take a look at a different field - for example, correlation coefficient (corr_coeff)\n\nfig = plt.figure(figsize=[12, 12])\ndisplay = pyart.graph.RadarMapDisplay(radar)\ndisplay.plot_ppi_map(\n    \"copol_coeff\",\n    sweep=0,\n    vmin=0.8,\n    vmax=1.0,\n    projection=ccrs.PlateCarree(),\n    cmap=\"pyart_Carbone42\",\n)\nplt.show()\n\n","type":"content","url":"/pyart-basics#use-the-radarmapdisplay-with-our-data","position":29},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Summary"},"type":"lvl2","url":"/pyart-basics#summary","position":30},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Summary"},"content":"Within this notebook, we covered the basics of working with radar data using pyart, including:\n\nReading in a file using xradar.io\n\nInvestigating the xradar object\n\nVisualizing radar data using the RadarMapDisplay","type":"content","url":"/pyart-basics#summary","position":31},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"What’s Next","lvl2":"Summary"},"type":"lvl3","url":"/pyart-basics#whats-next","position":32},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl3":"What’s Next","lvl2":"Summary"},"content":"In the next few notebooks, we walk through gridding radar data, applying data cleaning methods, and advanced visualization methods!\n\n","type":"content","url":"/pyart-basics#whats-next","position":33},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Resources and References"},"type":"lvl2","url":"/pyart-basics#resources-and-references","position":34},{"hierarchy":{"lvl1":"Py-ART Basics with Xradar","lvl2":"Resources and References"},"content":"Py-ART essentials links:\n\nLanding page\n\nExamples\n\nSource Code\n\nMailing list\n\nIssue Tracker","type":"content","url":"/pyart-basics#resources-and-references","position":35},{"hierarchy":{"lvl1":"Xradar Basics"},"type":"lvl1","url":"/xradar-basics","position":0},{"hierarchy":{"lvl1":"Xradar Basics"},"content":"\n\n","type":"content","url":"/xradar-basics","position":1},{"hierarchy":{"lvl1":"Xradar Basics"},"type":"lvl1","url":"/xradar-basics#xradar-basics","position":2},{"hierarchy":{"lvl1":"Xradar Basics"},"content":"\n\n\n\n","type":"content","url":"/xradar-basics#xradar-basics","position":3},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Overview"},"type":"lvl2","url":"/xradar-basics#overview","position":4},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Overview"},"content":"Xradar general overview\n\nRadar data IO\n\nRadar data georeferencing\n\nData visualization\n\n","type":"content","url":"/xradar-basics#overview","position":5},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Prerequisites"},"type":"lvl2","url":"/xradar-basics#prerequisites","position":6},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Xarray\n\nNecessary\n\nBasic features\n\nRadar Cookbook\n\nNecessary\n\nRadar basics\n\nMatplotlib\n\nNecessary\n\nPlotting basic features\n\nTime to learn: 30 minutes\n\n","type":"content","url":"/xradar-basics#prerequisites","position":7},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Imports"},"type":"lvl2","url":"/xradar-basics#imports","position":8},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Imports"},"content":"\n\nimport xradar as xd\nimport pyart\nimport wradlib as wrl\n\nimport fsspec\nimport numpy as np\nfrom xarray.backends.api import open_datatree\n\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\n\n","type":"content","url":"/xradar-basics#imports","position":9},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Xradar"},"type":"lvl2","url":"/xradar-basics#xradar","position":10},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Xradar"},"content":"\n\nXradar is a Python package developed to streamline the reading and writing of radar data across various formats, with exports aligned to standards like ODIM_H5 and CfRadial. Born from the Open Radar Science Community’s collaboration at ERAD2022, Xradar uses an xarray-based data model, compatible with the upcoming CfRadial2.1/FM301 standard. This ensures seamless integration with other xarray-based software and existing open-source radar processing tools.\n\n","type":"content","url":"/xradar-basics#xradar","position":11},{"hierarchy":{"lvl1":"Xradar Basics","lvl3":"Xradar data model","lvl2":"Xradar"},"type":"lvl3","url":"/xradar-basics#xradar-data-model","position":12},{"hierarchy":{"lvl1":"Xradar Basics","lvl3":"Xradar data model","lvl2":"Xradar"},"content":"Xradar leverages the upcoming FM301 standard, a subset of CfRadial2.0, using Xarray to efficiently manage radar data.\n\n","type":"content","url":"/xradar-basics#xradar-data-model","position":13},{"hierarchy":{"lvl1":"Xradar Basics","lvl4":"DataTree Structure (CfRadial2.1/FM301 standard)","lvl3":"Xradar data model","lvl2":"Xradar"},"type":"lvl4","url":"/xradar-basics#datatree-structure-cfradial2-1-fm301-standard","position":14},{"hierarchy":{"lvl1":"Xradar Basics","lvl4":"DataTree Structure (CfRadial2.1/FM301 standard)","lvl3":"Xradar data model","lvl2":"Xradar"},"content":"Xradar employs xarray.DataTree objects to organize radar sweeps within a single structure, where each sweep is an xarray.Dataset containing relevant metadata and variables.\n\n\n\n","type":"content","url":"/xradar-basics#datatree-structure-cfradial2-1-fm301-standard","position":15},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Xradar importers"},"type":"lvl2","url":"/xradar-basics#xradar-importers","position":16},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Xradar importers"},"content":"\n\nXradar supports several importers to handle different radar data formats. These importers typically include:\n\nODIM_H5: For reading radar data in the ODIM_H5 format, which is widely used in Europe and supported by the EUMETNET OPERA program.\n\nCfRadial: For importing data in the CfRadial format, which is commonly used in the atmospheric sciences community.\n\nSIGMET/IRIS: For ingesting radar data from SIGMET/IRIS formats, which are used by various weather radar systems globally.\n\nGAMIC: For reading data from GAMIC radars, which use their proprietary format.\n\nFor more importers check \n\nhere\n\nLet’s find some Italian radar data located at the Erad 2024 Bucket\n\n# Set the URL and path for the cloud\nURL = 'https://js2.jetstream-cloud.org:8001/'\npath = f'pythia/radar/erad2024'\n\nfs = fsspec.filesystem(\"s3\", anon=True, client_kwargs=dict(endpoint_url=URL))\n\nfs.glob(f\"{path}/*\")\n\nfiles = fs.glob(\"pythia/radar/erad2024/20240522_MeteoSwiss_ARPA_Lombardia/Data/Cband/*.nc\")\nfiles[:3]\n\nradar_files = [f\"s3://{i}\" for i in files]\nradar_files[:3]\n\nlocal_files = [\n    fsspec.open_local(\n        f\"simplecache::{URL}{i}\", s3={\"anon\": True}, filecache={\"cache_storage\": \".\"}\n    )\n    for i in files[:5]\n]\n\nWe can open one of this nc files using xradar.io.open_cfradial1_datree method\n\ndt = xd.io.open_cfradial1_datatree(local_files[0])\ndisplay(dt)\n\nIn this Xarray.Datatree object, the first two nodes contains radar metadata and the others contains Xarray.Datasets for each sweeps.\n\nfor sweep in dt.children:\n    try:\n        print(f\"{sweep} - elevation {np.round(dt[sweep]['sweep_fixed_angle'].values[...], 1)}\")\n    except KeyError:\n        print (sweep)\n\nLet’s explore the 1.0 degrees elevation (‘sweep_2’)\n\nds_sw2 = dt[\"sweep_2\"].ds\ndisplay(ds_sw2)\n\n","type":"content","url":"/xradar-basics#xradar-importers","position":17},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Xradar visualization"},"type":"lvl2","url":"/xradar-basics#xradar-visualization","position":18},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Xradar visualization"},"content":"We can make a plot using \n\nxarray.plot functionality.\n\nds_sw2.reflectivity.plot(\n    cmap=\"ChaseSpectral\",\n    vmax=60,\n    vmin=-10, \n)\n\nThe radar data in the Xarray.Dataset object includes range and azimuth as coordinates. To create a radial plot, apply the \n\nxradar.georeference method. This method will generate x, y, and z coordinates for the plot.\n\nds_sw2 = ds_sw2.xradar.georeference()\ndisplay(ds_sw2)\n\nWe can now create a radial plot passing x and y coordinates\n\nds_sw2.reflectivity.plot(\n    x=\"x\", \n    y= \"y\",\n    cmap=\"ChaseSpectral\",\n    vmax=60,\n    vmin=-10, \n)\n\n","type":"content","url":"/xradar-basics#xradar-visualization","position":19},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Data slicing"},"type":"lvl2","url":"/xradar-basics#data-slicing","position":20},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Data slicing"},"content":"We can use the power of Xarray to acces data within the first 50 kilometers by \n\nslicing along coordinates.\n\nds_sw2.sel(range=slice(0, 5e4)).reflectivity.plot(\n    x=\"x\", \n    y= \"y\",\n    cmap=\"ChaseSpectral\",\n    vmax=60,\n    vmin=-10, \n)\n\nLet’s suposse we want to subset between 90 and 180 degrees angle in azumith\n\nds_sw2.sel(azimuth=slice(90, 180), range=slice(0, 5e4)).reflectivity.plot(\n    x=\"x\", \n    y= \"y\",\n    cmap=\"ChaseSpectral\",\n    vmax=60,\n    vmin=-10, \n)\n\nPerhaps, we just what to see radar reflectivity along the 100 degrees angle in azimuth\n\nds_sw2.sel(azimuth=100, method=\"nearest\").reflectivity.plot()\n\n","type":"content","url":"/xradar-basics#data-slicing","position":21},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Xradar integration"},"type":"lvl2","url":"/xradar-basics#xradar-integration","position":22},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Xradar integration"},"content":"","type":"content","url":"/xradar-basics#xradar-integration","position":23},{"hierarchy":{"lvl1":"Xradar Basics","lvl3":"Py-Art","lvl2":"Xradar integration"},"type":"lvl3","url":"/xradar-basics#py-art","position":24},{"hierarchy":{"lvl1":"Xradar Basics","lvl3":"Py-Art","lvl2":"Xradar integration"},"content":"Xradar datatree objects can be ported to Py-ART radar objects using the pyart.xradar.Xradar method.\n\nradar = pyart.xradar.Xradar(dt)\nfig = plt.figure(figsize=[10, 8])\ndisplay = pyart.graph.RadarMapDisplay(radar)\ndisplay.plot_ppi_map('reflectivity', sweep=0)\n\ndel display\n\n","type":"content","url":"/xradar-basics#py-art","position":25},{"hierarchy":{"lvl1":"Xradar Basics","lvl3":"Wradlib","lvl2":"Xradar integration"},"type":"lvl3","url":"/xradar-basics#wradlib","position":26},{"hierarchy":{"lvl1":"Xradar Basics","lvl3":"Wradlib","lvl2":"Xradar integration"},"content":"Wradlib functionality can also be applied to Xarray.Datatree objects. For example, the \n\nwradlib.georef module can be used to enrich data by adding geographical coordinates.\n\nfor key in list(dt.children):\n    if \"sweep\" in key:\n        dt[key].ds = dt[key].ds.wrl.georef.georeference(\n            crs=wrl.georef.get_default_projection()\n        )\n\ndt[\"sweep_0\"].ds.reflectivity.sel(range=slice(0, 5e4)).plot(\n    x=\"x\", \n    y= \"y\",\n    cmap=\"ChaseSpectral\",\n    vmax=60,\n    vmin=-10, \n)\n\n","type":"content","url":"/xradar-basics#wradlib","position":27},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Xradar exporters"},"type":"lvl2","url":"/xradar-basics#xradar-exporters","position":28},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Xradar exporters"},"content":"\n\nIn xradar, exporters convert radar data into various formats for analysis or integration. Exporting is supported for recognized standards, including:\n\nCfRadial1\n\nCfRadial2\n\nODIM\n\nZarr\n\nAlthough \n\nZarr is not a traditional standard format, it provides an analysis-ready, cloud-optimized format that enhances data accessibility and performance.\n\ndt.to_zarr(\"tree.zarr\", consolidated=True, mode=\"w\")\n\ndt_back = open_datatree(\"tree.zarr\", engine=\"zarr\",chunks={})\n\ndisplay(dt_back)\n\n\n\n","type":"content","url":"/xradar-basics#xradar-exporters","position":29},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Summary"},"type":"lvl2","url":"/xradar-basics#summary","position":30},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Summary"},"content":"Xradar is a Python library designed for working with radar data. It extends xarray to include radar-specific functionality, such as purpose-based accessors and georeferencing methods. It supports exporting data in various formats, including CfRadial1, CfRadial2, ODIM, and Zarr. xradar facilitates the analysis, visualization, and integration of radar data with other tools and systems.\n\n","type":"content","url":"/xradar-basics#summary","position":31},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Resources and references"},"type":"lvl2","url":"/xradar-basics#resources-and-references","position":32},{"hierarchy":{"lvl1":"Xradar Basics","lvl2":"Resources and references"},"content":"Xradar\n\nRadar cookbook\n\nPy-Art landing page\n\nWradlib landing page","type":"content","url":"/xradar-basics#resources-and-references","position":33},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science"},"type":"lvl1","url":"/intro-to-open-radar-science","position":0},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science"},"content":"","type":"content","url":"/intro-to-open-radar-science","position":1},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl2":"What is Open Science?"},"type":"lvl2","url":"/intro-to-open-radar-science#what-is-open-science","position":2},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl2":"What is Open Science?"},"content":"\n\nImage based on \n\nRamachandran et al. 2021\n\n","type":"content","url":"/intro-to-open-radar-science#what-is-open-science","position":3},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"What Does this look like in the Weather Radar Community?","lvl2":"What is Open Science?"},"type":"lvl3","url":"/intro-to-open-radar-science#what-does-this-look-like-in-the-weather-radar-community","position":4},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"What Does this look like in the Weather Radar Community?","lvl2":"What is Open Science?"},"content":"Since the late 2000s (and even before) there has been a number of major open source projects released (see e.g. \n\nhttps://​openradarscience​.org).\n\nSome of them are in a mature stage and are widely used in an academic (mostly) but also operational environment\n\nMost make use of modern tools (e.g. github, conda, docker) and practices (e.g. Continuous Integration, automatic tests) that make them easy to evolve and deploy\n\nMost are backed by major weather services or academic institutions\nProjects are not competing among them but collaborating : Best practices and inter-operability are discussed regularly and joint open source courses have been organized for years at major radar conferences (AMS, ERAD)\n\n","type":"content","url":"/intro-to-open-radar-science#what-does-this-look-like-in-the-weather-radar-community","position":5},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl2":"The Conceptual Idea of the Open Radar Stack"},"type":"lvl2","url":"/intro-to-open-radar-science#the-conceptual-idea-of-the-open-radar-stack","position":6},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl2":"The Conceptual Idea of the Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#the-conceptual-idea-of-the-open-radar-stack","position":7},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"Common weather radar processing workflows","lvl2":"The Conceptual Idea of the Open Radar Stack"},"type":"lvl3","url":"/intro-to-open-radar-science#common-weather-radar-processing-workflows","position":8},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"Common weather radar processing workflows","lvl2":"The Conceptual Idea of the Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#common-weather-radar-processing-workflows","position":9},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"The Open Radar Tools","lvl2":"The Conceptual Idea of the Open Radar Stack"},"type":"lvl3","url":"/intro-to-open-radar-science#the-open-radar-tools","position":10},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"The Open Radar Tools","lvl2":"The Conceptual Idea of the Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#the-open-radar-tools","position":11},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Additional Tools that Can be used with/for Weather Radar Data","lvl3":"The Open Radar Tools","lvl2":"The Conceptual Idea of the Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#additional-tools-that-can-be-used-with-for-weather-radar-data","position":12},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Additional Tools that Can be used with/for Weather Radar Data","lvl3":"The Open Radar Tools","lvl2":"The Conceptual Idea of the Open Radar Stack"},"content":"MetPy\n\na collection of tools in Python for reading, visualizing, and performing calculations with weather data\n\ntobac\n\na Python package for rapidly identify, track and analyze clouds in different types of gridded datasets, such as 3D model output from cloud-resolving model simulations or 2D data from satellite retrievals.\n\n","type":"content","url":"/intro-to-open-radar-science#additional-tools-that-can-be-used-with-for-weather-radar-data","position":13},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl2","url":"/intro-to-open-radar-science#introductions-of-the-core-open-radar-stack","position":14},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#introductions-of-the-core-open-radar-stack","position":15},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"Wradlib (Keep the magic to the minimum (let the user decide))","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl3","url":"/intro-to-open-radar-science#wradlib-keep-the-magic-to-the-minimum-let-the-user-decide","position":16},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"Wradlib (Keep the magic to the minimum (let the user decide))","lvl2":"Introductions of the Core Open Radar Stack"},"content":"https://wradlib.org\n\nOne of the oldest packages (2011)\n\nOpen platform for collaborative development of algorithms\n\nPython-based\n\nLinux/Windows/Mac\n\nFlat data model that allows maximum flexibility to interact with the data.\n\nxarray readers available (now in xradar as of 2.0)\n\nComprehensively addresses the full radar processing chain\n\nMainly geared to interactive use in research but used in operations too\n\nEasy to install (PyPI, conda, Docker Hub)\n\n","type":"content","url":"/intro-to-open-radar-science#wradlib-keep-the-magic-to-the-minimum-let-the-user-decide","position":17},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Functionality","lvl3":"Wradlib (Keep the magic to the minimum (let the user decide))","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#functionality","position":18},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Functionality","lvl3":"Wradlib (Keep the magic to the minimum (let the user decide))","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#functionality","position":19},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Sample Image","lvl3":"Wradlib (Keep the magic to the minimum (let the user decide))","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#sample-image","position":20},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Sample Image","lvl3":"Wradlib (Keep the magic to the minimum (let the user decide))","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#sample-image","position":21},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"Py-ART (It’s all about the data model)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl3","url":"/intro-to-open-radar-science#py-art-its-all-about-the-data-model","position":22},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"Py-ART (It’s all about the data model)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"https://​arm​-doe​.github​.io​/pyart/\n\nCreated in the context of the ARM program (2013)\n\nOpen platform for collaborative development of algorithms\n\nMostly Python-based (some modules in C, Cython and FORTRAN)\n\nLinux/Windows/Mac\n\nCore : Radar object that structures the radar data and metadata mirroring the C/F Radial standard\n\nLimited scope. Base block to built upon\n\nRich ecosystem of packages: ART-VIEW, PyTDA, PyDDA, TINT, Pyrad...\n\nEasy to install (PyPI, conda)\n\n","type":"content","url":"/intro-to-open-radar-science#py-art-its-all-about-the-data-model","position":23},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Functionality","lvl3":"Py-ART (It’s all about the data model)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#functionality-1","position":24},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Functionality","lvl3":"Py-ART (It’s all about the data model)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#functionality-1","position":25},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Sample Image","lvl3":"Py-ART (It’s all about the data model)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#sample-image-1","position":26},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Sample Image","lvl3":"Py-ART (It’s all about the data model)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#sample-image-1","position":27},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"Pyrad (Flexible and replicable data processing chains with no programming)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl3","url":"/intro-to-open-radar-science#pyrad-flexible-and-replicable-data-processing-chains-with-no-programming","position":28},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"Pyrad (Flexible and replicable data processing chains with no programming)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"https://​github​.com​/MeteoSwiss​/pyrad\n\nInitially developed at MeteoSwiss. Now shared development between MeteoSwiss and Météo-France\n\nPython-based weather radar data processing framework capable of operating in real time or off-line\n\nCore based on ARM-DOE Py-ART (Pyrad major contributor)\n\nEasy to install (PyPI, conda)\n\n","type":"content","url":"/intro-to-open-radar-science#pyrad-flexible-and-replicable-data-processing-chains-with-no-programming","position":29},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Functionality","lvl3":"Pyrad (Flexible and replicable data processing chains with no programming)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#functionality-2","position":30},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Functionality","lvl3":"Pyrad (Flexible and replicable data processing chains with no programming)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#functionality-2","position":31},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Sample Image","lvl3":"Pyrad (Flexible and replicable data processing chains with no programming)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#sample-image-2","position":32},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Sample Image","lvl3":"Pyrad (Flexible and replicable data processing chains with no programming)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#sample-image-2","position":33},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"LROSE (High quality building blocks forcomplex workflows)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl3","url":"/intro-to-open-radar-science#lrose-high-quality-building-blocks-forcomplex-workflows","position":34},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"LROSE (High quality building blocks forcomplex workflows)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"http://lrose.net/\n\nBased on legacy of NCAR and CSU tools\n\nFast native cross-platform applications\n\nMostly C++\n\nLinux/Mac/partially Windows\n\nMany stand-alone tools\n\nStores data in CF/Radial\n\n","type":"content","url":"/intro-to-open-radar-science#lrose-high-quality-building-blocks-forcomplex-workflows","position":35},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Functionality","lvl3":"LROSE (High quality building blocks forcomplex workflows)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#functionality-3","position":36},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Functionality","lvl3":"LROSE (High quality building blocks forcomplex workflows)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#functionality-3","position":37},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Sample Image","lvl3":"LROSE (High quality building blocks forcomplex workflows)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#sample-image-3","position":38},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Sample Image","lvl3":"LROSE (High quality building blocks forcomplex workflows)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#sample-image-3","position":39},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"BALTRAD (Advanced Weather Radar Network)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl3","url":"/intro-to-open-radar-science#baltrad-advanced-weather-radar-network","position":40},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"BALTRAD (Advanced Weather Radar Network)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"Heritage from the Nordic Network NORDRAD. Partly funded by the EU. BALTRAD and BALTRAD+ projects (2009-2014). 13 partners in 10 countries\n\nReal-time data exchange and data processing\n\nSub-packages written in different languages\n\nData exchange: JAVA\n\nData processing: C and Python\n\nLinux/Mac\n\nDistributed networking, partners exchange polar data and process them using a common toolbox\n\nUses ODIM-H5\n\nDocumentation: \n\nhttps://​baltrad​.github​.io/\n\nCode: \n\nhttps://​github​.com​/baltrad\n\n","type":"content","url":"/intro-to-open-radar-science#baltrad-advanced-weather-radar-network","position":41},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Functionality","lvl3":"BALTRAD (Advanced Weather Radar Network)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#functionality-4","position":42},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Functionality","lvl3":"BALTRAD (Advanced Weather Radar Network)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#functionality-4","position":43},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Sample Image","lvl3":"BALTRAD (Advanced Weather Radar Network)","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl4","url":"/intro-to-open-radar-science#sample-image-4","position":44},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Sample Image","lvl3":"BALTRAD (Advanced Weather Radar Network)","lvl2":"Introductions of the Core Open Radar Stack"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#sample-image-4","position":45},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"Conclusions on the Open Radar Stack","lvl2":"Introductions of the Core Open Radar Stack"},"type":"lvl3","url":"/intro-to-open-radar-science#conclusions-on-the-open-radar-stack","position":46},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"Conclusions on the Open Radar Stack","lvl2":"Introductions of the Core Open Radar Stack"},"content":"Acknowledge software when you use it – treat it like a paper\n\nMost projects have Digital Object Identifiers (DOIs)\n\nContribute back to projects\n\nReport bugs, suggest enhancements, share feedback!\n\nDo not be afraid to contribute\n\nWe all started somewhere – your code will be reviewed + tests ensure things do not break\n\nOpen Source does not end at making things open\n\nSupport, documentation, consistency, etc. are required\n\nTake a look at existing projects to see if you can collaborate/coordinate!\n\n","type":"content","url":"/intro-to-open-radar-science#conclusions-on-the-open-radar-stack","position":47},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl2":"The Open Radar Community"},"type":"lvl2","url":"/intro-to-open-radar-science#the-open-radar-community","position":48},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl2":"The Open Radar Community"},"content":"\n\n","type":"content","url":"/intro-to-open-radar-science#the-open-radar-community","position":49},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"More on Open Science: Beyond the Tools","lvl2":"The Open Radar Community"},"type":"lvl3","url":"/intro-to-open-radar-science#more-on-open-science-beyond-the-tools","position":50},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"More on Open Science: Beyond the Tools","lvl2":"The Open Radar Community"},"content":"\n\nOpen Science = Open Data + Open Algorithms + Open Software + Open Peer Review + Open Access Publication\n\nThereby, science process and outputs can be:\n\n✅ Transparent\n\n✅ Reproducible\n\n✅ Transferrable\n\n✅ Collaborative\n\n✅ Credible!\n\n✅ Durable, sustainable\n\nImportantNo conflict between Intellectual Property Rights (IPR) and licensing.\n\n","type":"content","url":"/intro-to-open-radar-science#more-on-open-science-beyond-the-tools","position":51},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Recommendations for Open Scientists","lvl3":"More on Open Science: Beyond the Tools","lvl2":"The Open Radar Community"},"type":"lvl4","url":"/intro-to-open-radar-science#recommendations-for-open-scientists","position":52},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl4":"Recommendations for Open Scientists","lvl3":"More on Open Science: Beyond the Tools","lvl2":"The Open Radar Community"},"content":"Use Git for collaborative change/version code management\n\nGitHub: \n\ngithub.com\n\nGitLab: \n\ngitlab.com\n\nLinux virtual machine on your local computer\n\nCost-effective near-replication of official environments\n\nGood for development, even while traveling\n\nVM is the starting point, a vehicle, for creating transferrable computational environments\n\nToday’s cloud instance is an “elaborated” VM (Jupyterhub/Binderhub)\n\nIf you have a choice, use an open programming language\n\nAvoid proprietary algorithms like Numerical Recipes\n\nPublish code\n\nPublish data\n\nPublish code & data associated with a study/paper\n\nPublish in Open Access journals\n\n","type":"content","url":"/intro-to-open-radar-science#recommendations-for-open-scientists","position":53},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"The Open Radar Forum - Establishing a Community of Practice","lvl2":"The Open Radar Community"},"type":"lvl3","url":"/intro-to-open-radar-science#the-open-radar-forum-establishing-a-community-of-practice","position":54},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl3":"The Open Radar Forum - Establishing a Community of Practice","lvl2":"The Open Radar Community"},"content":"https://​openradar​.discourse​.group/\n\n\n\n","type":"content","url":"/intro-to-open-radar-science#the-open-radar-forum-establishing-a-community-of-practice","position":55},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl2":"Conclusions"},"type":"lvl2","url":"/intro-to-open-radar-science#conclusions","position":56},{"hierarchy":{"lvl1":"An Introduction to Open Radar Science","lvl2":"Conclusions"},"content":"https://​openradarscience​.org\n\n\n\nThere is no “silver bullet” for open science\n\nTry to use open languages where possible\n\nShare your work!\n\nJoin the conversation on the forum\n\nYou can find more posts relevant to the Open Radar Community on our website (at the top) and on the forum\n\nWe have monthly meetings! Join!","type":"content","url":"/intro-to-open-radar-science#conclusions","position":57},{"hierarchy":{"lvl1":"Projects Overview"},"type":"lvl1","url":"/projects","position":0},{"hierarchy":{"lvl1":"Projects Overview"},"content":"","type":"content","url":"/projects","position":1},{"hierarchy":{"lvl1":"Projects Overview","lvl2":"Wind Retrievals over Complex Terrain with LROSE and PyDDA"},"type":"lvl2","url":"/projects#wind-retrievals-over-complex-terrain-with-lrose-and-pydda","position":2},{"hierarchy":{"lvl1":"Projects Overview","lvl2":"Wind Retrievals over Complex Terrain with LROSE and PyDDA"},"content":"Within this project, students will use LROSE wind tools and PyDDA to derive 3-dimensional wind retrievals over complex terrain across Europe and beyond.","type":"content","url":"/projects#wind-retrievals-over-complex-terrain-with-lrose-and-pydda","position":3},{"hierarchy":{"lvl1":"Projects Overview","lvl2":"Spaceborne / Ground Radar Comparison with GPM-API, xradar and wradlib"},"type":"lvl2","url":"/projects#spaceborne-ground-radar-comparison-with-gpm-api-xradar-and-wradlib","position":4},{"hierarchy":{"lvl1":"Projects Overview","lvl2":"Spaceborne / Ground Radar Comparison with GPM-API, xradar and wradlib"},"content":"Students will compare spaceborne radar data, from the Global Preciptiation Measurement (GPM) suite of instruments, to ground radar across Italy. They will use a suite of openradar tools to complete this comparison.","type":"content","url":"/projects#spaceborne-ground-radar-comparison-with-gpm-api-xradar-and-wradlib","position":5},{"hierarchy":{"lvl1":"Projects Overview","lvl2":"Creating analysis-ready data with xradar with Quasi-Vertical Profiles (QVPs)"},"type":"lvl2","url":"/projects#creating-analysis-ready-data-with-xradar-with-quasi-vertical-profiles-qvps","position":6},{"hierarchy":{"lvl1":"Projects Overview","lvl2":"Creating analysis-ready data with xradar with Quasi-Vertical Profiles (QVPs)"},"content":"In this project, students will demonstrate how utilizing radar data in the Analysis-Ready Cloud-Optimized (ARCO) format enables efficient computation of Quantitative Precipitation Estimates (QPE) and Quasi-Vertical Profiles (QVP). The ARCO format ensures that radar data is pre-processed, clean, and well-organized, significantly reducing the time spent on data preparation and cleaning.","type":"content","url":"/projects#creating-analysis-ready-data-with-xradar-with-quasi-vertical-profiles-qvps","position":7},{"hierarchy":{"lvl1":"Projects Overview","lvl2":"Quantative Precipitation Estimation (QPE) in Northern Italy"},"type":"lvl2","url":"/projects#quantative-precipitation-estimation-qpe-in-northern-italy","position":8},{"hierarchy":{"lvl1":"Projects Overview","lvl2":"Quantative Precipitation Estimation (QPE) in Northern Italy"},"content":"In this project we will learn how to setup a data processing chain for radar rainfall rate retrieval. The project will show the main steps involved between reading raw polarimetric moments to comparing rainfall rate retrievals with rain gauges, including clutter filtering, PhiDP estimation, KDP retrieval, etc. During the course, the processing chain implementation will be performed with \n\nPyrad. Examples of how to implement a processing chain using other available software packages will be provided as post-course material.","type":"content","url":"/projects#quantative-precipitation-estimation-qpe-in-northern-italy","position":9},{"hierarchy":{"lvl1":"Schedule"},"type":"lvl1","url":"/schedule","position":0},{"hierarchy":{"lvl1":"Schedule"},"content":"Time\n\nTopic\n\nPresenter\n\n09:00 AM - 09:15 AM\n\nWelcome/Introduction\n\nMax Grover\n\n09:15 AM - 09:30 AM\n\nOpen Radar Science\n\nMax Grover\n\n09:30 AM - 10:00 AM\n\nxradar Introduction\n\nAlfonso Ladino\n\n10:00 AM - 10:30 AM\n\nCoffee break\n\n\n\n10:30 AM - 11:00 AM\n\nPy-ART/wradlib\n\nKai Mühlbauer + Bobby Jackson\n\n11:00 AM - 11:30 AM\n\nPyrad Introduction\n\nJordi Figueras i Ventura + Daniel Wolfensberger\n\n12:00 PM - 12:30 PM\n\nLROSE Introduction\n\nBrenda Javornik + Jen DeHart\n\n12:30 PM - 01:30 PM\n\nLunch\n\n\n\n01:30 PM - 02:00 PM\n\nBALTRAD\n\nDaniel Michelson\n\n02:00 PM - 02:15 PM\n\nGPM-API\n\nGionata Ghiggi\n\n02:15 PM - 02:30 PM\n\nProject Pitches\n\nAll\n\n02:30 PM - 03:00 PM\n\nCoffee Break\n\n\n\n03:00 PM - 04:30 PM\n\nGroup Work\n\nAll\n\n04:30 PM - 05:00 PM\n\nOpen slot, discussion, evaluation\n\nAll","type":"content","url":"/schedule","position":1}]}